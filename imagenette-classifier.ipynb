{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "tf.__version__\n",
    "tf.executing_eagerly()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = tfds.load(name=\"imagenette\", with_info=True, split=[\"train\",\"validation\"])\n",
    "ds_train=ds[0][0]\n",
    "ds_test=ds[0][1]\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "\n",
    "def normalize(x):\n",
    "    y = {'image': tf.image.convert_image_dtype(x['image'], tf.float32), 'label': x['label']}\n",
    "    y = (tf.image.resize(y['image'], (224,224)), y['label'])\n",
    "    return y\n",
    "    \n",
    "ds_train = ds_train.map(lambda x: normalize(x))\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(100)\n",
    "ds_train = ds_train.batch(32)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(32)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"keras_learning_phase:0\", shape=(), dtype=bool)\n",
      "Epoch 1/15\n",
      "True\n",
      "True\n",
      "    250/Unknown - 95s 379ms/step - loss: 2.4189 - accuracy: 0.1800False\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 2.4189 - accuracy: 0.1800 - val_loss: 2.2808 - val_accuracy: 0.2800\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 2.2275 - accuracy: 0.2190 - val_loss: 2.1355 - val_accuracy: 0.2300\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 79s 315ms/step - loss: 2.1158 - accuracy: 0.2500 - val_loss: 1.9986 - val_accuracy: 0.3400\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 79s 317ms/step - loss: 2.0837 - accuracy: 0.2820 - val_loss: 1.8596 - val_accuracy: 0.3300\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 81s 325ms/step - loss: 2.0066 - accuracy: 0.3200 - val_loss: 1.9556 - val_accuracy: 0.2700\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 75s 301ms/step - loss: 2.0198 - accuracy: 0.2910 - val_loss: 2.3515 - val_accuracy: 0.2500\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 86s 345ms/step - loss: 1.9053 - accuracy: 0.3440 - val_loss: 2.0816 - val_accuracy: 0.3300\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 1.8903 - accuracy: 0.3550 - val_loss: 2.6329 - val_accuracy: 0.2200\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 77s 308ms/step - loss: 1.7917 - accuracy: 0.3970 - val_loss: 3.6005 - val_accuracy: 0.2100\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 1.7847 - accuracy: 0.3870 - val_loss: 2.8142 - val_accuracy: 0.1500\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 82s 327ms/step - loss: 1.7169 - accuracy: 0.4320 - val_loss: 2.9207 - val_accuracy: 0.2400\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 88s 354ms/step - loss: 1.7030 - accuracy: 0.4140 - val_loss: 3.6857 - val_accuracy: 0.1900\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 85s 341ms/step - loss: 1.6812 - accuracy: 0.4330 - val_loss: 4.3899 - val_accuracy: 0.2200\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 78s 312ms/step - loss: 1.6253 - accuracy: 0.4520 - val_loss: 6.6474 - val_accuracy: 0.2700\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 72s 289ms/step - loss: 1.5253 - accuracy: 0.4820 - val_loss: 5.8462 - val_accuracy: 0.1900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x153b7fe50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layer1 = layers.Dense(512, activation='relu')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.layer2 = layers.Dense(128, activation='relu')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.layer3 = layers.Dense(10, activation='softmax')\n",
    "    def call(self,inputs, training=True):\n",
    "        \n",
    "        x = layers.Flatten()(inputs)\n",
    "        #print(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.bn1(x, training = training)\n",
    "        x = self.layer2(x)\n",
    "        x = self.bn2(x, training = training)\n",
    "        return self.layer3(x)\n",
    "        self.conv1 = CustomConvLayer(masks['mask_conv_1'], masks['mask_conv_1'], biases['bias_conv_1'], 1)\n",
    "        self.pool1 = CustomPoolLayer()\n",
    "        self.conv2 = CustomConvLayer(masks['mask_conv_2'], masks['mask_conv_2'], biases['bias_conv_2'], 1)\n",
    "        self.pool2 = CustomPoolLayer()\n",
    "        self.conv3 = CustomConvLayer(masks['mask_conv_3'], masks['mask_conv_3'], biases['bias_conv_3'], 1)\n",
    "        self.pool3 = CustomPoolLayer()\n",
    "        self.conv4 = CustomConvLayer(masks['mask_conv_4'], masks['mask_conv_4'], biases['bias_conv_4'], 1)\n",
    "        self.pool4 = CustomPoolLayer()\n",
    "        self.dense1 = layers.Dense(1024, activation='relu')\n",
    "        self.dense2 = layers.Dense(512, activation='relu')\n",
    "        self.dense3 = layers.Dense(10, activation='softmax')\n",
    "    def call(self,inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        print(x)\n",
    "        x = self.pool1(x)\n",
    "        print(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool4(x)\n",
    "        print(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        #print(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "model = CustomModel()\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.00001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=ds_train,\n",
    "    #steps_per_epoch=1,\n",
    "    epochs=15,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for example in ds_train.take(1):  # Only take a single example\n",
    "    print(example['image'].shape)\n",
    "    image, label = example[\"image\"], example[\"label\"]\n",
    "    plt.imshow(image.numpy()[:, :, 0].astype(np.float32), cmap=plt.get_cmap(\"gray\"))\n",
    "    print(\"Label: %d\" % label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.repeat().shuffle(1024).batch(32)\n",
    "\n",
    "# prefetch will enable the input pipeline to asynchronously fetch batches while\n",
    "# your model is training.\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.show_examples(ds_train[1] ,ds_train[0]['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "custom_conv_layer_20 (Custom multiple                  448       \n",
      "_________________________________________________________________\n",
      "custom_pool_layer_20 (Custom multiple                  0         \n",
      "_________________________________________________________________\n",
      "custom_conv_layer_21 (Custom multiple                  4640      \n",
      "_________________________________________________________________\n",
      "custom_pool_layer_21 (Custom multiple                  0         \n",
      "_________________________________________________________________\n",
      "custom_conv_layer_22 (Custom multiple                  18496     \n",
      "_________________________________________________________________\n",
      "custom_pool_layer_22 (Custom multiple                  0         \n",
      "_________________________________________________________________\n",
      "custom_conv_layer_23 (Custom multiple                  73856     \n",
      "_________________________________________________________________\n",
      "custom_pool_layer_23 (Custom multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             multiple                  25691136  \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             multiple                  524800    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             multiple                  5130      \n",
      "=================================================================\n",
      "Total params: 26,318,506\n",
      "Trainable params: 26,221,066\n",
      "Non-trainable params: 97,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"custom_model_5/custom_conv_layer_20/Relu:0\", shape=(32, 224, 224, 16), dtype=float32)\n",
      "Tensor(\"custom_model_5/custom_pool_layer_20/MaxPool2d:0\", shape=(32, 112, 112, 16), dtype=float32)\n",
      "Tensor(\"custom_model_5/custom_pool_layer_23/MaxPool2d:0\", shape=(32, 14, 14, 128), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_on_batch(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'weights_conv_1': tf.Variable(tf.random.normal([3, 3, 3, 16])),\n",
    "    'weights_conv_2': tf.Variable(tf.random.normal([3, 3, 16, 32])),\n",
    "    'weights_conv_3': tf.Variable(tf.random.normal([3, 3, 32, 64])),\n",
    "    'weights_conv_4': tf.Variable(tf.random.normal([3, 3, 64, 128])),\n",
    "    'weights_conv_5': tf.Variable(tf.random.normal([3, 3, 12, 24])),\n",
    "    'weights_conv_6': tf.Variable(tf.random.normal([3, 3, 24, 24])),\n",
    "    'weights_conv_7': tf.Variable(tf.random.normal([3, 3, 24, 24])),\n",
    "    'weights_conv_8': tf.Variable(tf.random.normal([3, 3, 24, 48])),\n",
    "    'weights_conv_9': tf.Variable(tf.random.normal([3, 3, 48, 48])),\n",
    "    'weights_conv_10': tf.Variable(tf.random.normal([3, 3, 48, 48])),\n",
    "    'weights_conv_11': tf.Variable(tf.random.normal([3, 3, 48, 48])),\n",
    "    'weights_conv_12': tf.Variable(tf.random.normal([3, 3, 48, 48])),\n",
    "    'weights_conv_13': tf.Variable(tf.random.normal([3, 3, 48, 48])),\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "masks = {\n",
    "    \n",
    "    'mask_conv_1': tf.Variable(tf.ones([3, 3, 3, 16]), trainable=False),\n",
    "    'mask_conv_2': tf.Variable(tf.ones([3, 3, 16, 32]), trainable=False),\n",
    "    'mask_conv_3': tf.Variable(tf.ones([3, 3, 32, 64]), trainable=False),\n",
    "    'mask_conv_4': tf.Variable(tf.ones([3, 3, 64, 128]), trainable=False),\n",
    "    'mask_conv_5': tf.Variable(tf.ones([3, 3, 12, 24]), trainable=False),\n",
    "    'mask_conv_6': tf.Variable(tf.ones([3, 3, 24, 24]), trainable=False),\n",
    "    'mask_conv_7': tf.Variable(tf.ones([3, 3, 24, 24]), trainable=False),\n",
    "    'mask_conv_8': tf.Variable(tf.ones([3, 3, 24, 48]), trainable=False),\n",
    "    'mask_conv_9': tf.Variable(tf.ones([3, 3, 48, 48]), trainable=False),\n",
    "    'mask_conv_10': tf.Variable(tf.ones([3, 3, 48, 48]), trainable=False),\n",
    "    'mask_conv_11': tf.Variable(tf.ones([3, 3, 48, 48]), trainable=False),\n",
    "    'mask_conv_12': tf.Variable(tf.ones([3, 3, 48, 48]), trainable=False),\n",
    "    'mask_conv_13': tf.Variable(tf.ones([3, 3, 48, 48]), trainable=False),\n",
    "    # 224x224 input --> 5 maxpool layers --> \n",
    "\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    #output depth\n",
    "    'bias_conv_1': tf.Variable(tf.zeros([16]), trainable=False),\n",
    "    'bias_conv_2': tf.Variable(tf.zeros([32]), trainable=False),\n",
    "    'bias_conv_3': tf.Variable(tf.zeros([64]), trainable=False),\n",
    "    'bias_conv_4': tf.Variable(tf.zeros([128]), trainable=False),\n",
    "    'bias_conv_5': tf.Variable(tf.zeros([24]), trainable=False),\n",
    "    'bias_conv_6': tf.Variable(tf.zeros([24]), trainable=False),\n",
    "    'bias_conv_7': tf.Variable(tf.zeros([24]), trainable=False),\n",
    "    'bias_conv_8': tf.Variable(tf.zeros([48]), trainable=False),\n",
    "    'bias_conv_9': tf.Variable(tf.zeros([48]), trainable=False),\n",
    "    'bias_conv_10': tf.Variable(tf.zeros([48]), trainable=False),\n",
    "    'bias_conv_11': tf.Variable(tf.zeros([48]), trainable=False),\n",
    "    'bias_conv_12': tf.Variable(tf.zeros([48]), trainable=False),\n",
    "    'bias_conv_13': tf.Variable(tf.zeros([48]), trainable=False),\n",
    "    \n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p)\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        return tf.nn.relu(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='SAME'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.max_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p)\n",
    "    \n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, weights, mask, bias, activation = 'relu'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        self.a = activation\n",
    "        self.m = mask\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print('dense w',self.w)\n",
    "        #print('dense i',inputs)\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        #print('dense x',x)\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'relu':\n",
    "            return tf.nn.relu(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        if self.a == 'sigmoid':\n",
    "            return tf.nn.sigmoid(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
