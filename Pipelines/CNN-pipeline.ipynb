{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianmerkle/dev/foolbox/foolbox/attacks/brendel_bethge.py:781: NumbaDeprecationWarning: The 'numba.jitclass' decorator has moved to 'numba.experimental.jitclass' to better reflect the experimental nature of the functionality. Please update your imports to accommodate this change and see http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#change-of-jitclass-location for the time frame.\n",
      "  @jitclass(spec=[])\n",
      "/Users/florianmerkle/dev/foolbox/foolbox/attacks/brendel_bethge.py:1364: NumbaDeprecationWarning: The 'numba.jitclass' decorator has moved to 'numba.experimental.jitclass' to better reflect the experimental nature of the functionality. Please update your imports to accommodate this change and see http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#change-of-jitclass-location for the time frame.\n",
      "  @jitclass(spec=spec)\n",
      "/Users/florianmerkle/dev/foolbox/foolbox/attacks/brendel_bethge.py:1560: NumbaDeprecationWarning: The 'numba.jitclass' decorator has moved to 'numba.experimental.jitclass' to better reflect the experimental nature of the functionality. Please update your imports to accommodate this change and see http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#change-of-jitclass-location for the time frame.\n",
      "  @jitclass(spec=spec)\n",
      "/Users/florianmerkle/dev/foolbox/foolbox/attacks/brendel_bethge.py:1712: NumbaDeprecationWarning: The 'numba.jitclass' decorator has moved to 'numba.experimental.jitclass' to better reflect the experimental nature of the functionality. Please update your imports to accommodate this change and see http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#change-of-jitclass-location for the time frame.\n",
      "  @jitclass(spec=spec)\n",
      "/Users/florianmerkle/dev/foolbox/foolbox/attacks/brendel_bethge.py:1906: NumbaDeprecationWarning: The 'numba.jitclass' decorator has moved to 'numba.experimental.jitclass' to better reflect the experimental nature of the functionality. Please update your imports to accommodate this change and see http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#change-of-jitclass-location for the time frame.\n",
      "  @jitclass(spec=spec)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import foolbox as fb\n",
    "\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune, Train Attack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7972 - accuracy: 0.6616 - val_loss: 1.7988 - val_accuracy: 0.6601\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7360 - accuracy: 0.7240 - val_loss: 1.7116 - val_accuracy: 0.7490\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7112 - accuracy: 0.7491 - val_loss: 1.7039 - val_accuracy: 0.7560\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7054 - accuracy: 0.7545 - val_loss: 1.7008 - val_accuracy: 0.7583\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7041 - accuracy: 0.7552 - val_loss: 1.7033 - val_accuracy: 0.7562\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7018 - accuracy: 0.7581 - val_loss: 1.6958 - val_accuracy: 0.7638\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6977 - accuracy: 0.7624 - val_loss: 1.6959 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6979 - accuracy: 0.7620 - val_loss: 1.6922 - val_accuracy: 0.7672\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6956 - accuracy: 0.7638 - val_loss: 1.6963 - val_accuracy: 0.7638\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6932 - accuracy: 0.7666 - val_loss: 1.6936 - val_accuracy: 0.7653\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6927 - accuracy: 0.7667 - val_loss: 1.6955 - val_accuracy: 0.7629\n",
      "WARNING:tensorflow:From /Users/florianmerkle/dev/foolbox/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [03:06, 186.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7445 - accuracy: 0.7161 - val_loss: 1.6726 - val_accuracy: 0.7897\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6612 - accuracy: 0.8000 - val_loss: 1.6432 - val_accuracy: 0.8177\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6459 - accuracy: 0.8155 - val_loss: 1.6336 - val_accuracy: 0.8271\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6371 - accuracy: 0.8238 - val_loss: 1.6369 - val_accuracy: 0.8249\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6311 - accuracy: 0.8299 - val_loss: 1.6339 - val_accuracy: 0.8266\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6265 - accuracy: 0.8343 - val_loss: 1.6271 - val_accuracy: 0.8343\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6244 - accuracy: 0.8364 - val_loss: 1.6175 - val_accuracy: 0.8431\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6196 - accuracy: 0.8413 - val_loss: 1.6123 - val_accuracy: 0.8481\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6183 - accuracy: 0.8423 - val_loss: 1.6136 - val_accuracy: 0.8469\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6181 - accuracy: 0.8427 - val_loss: 1.6138 - val_accuracy: 0.8466\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6154 - accuracy: 0.8450 - val_loss: 1.6119 - val_accuracy: 0.8491\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6141 - accuracy: 0.8463 - val_loss: 1.6068 - val_accuracy: 0.8542\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6105 - accuracy: 0.8498 - val_loss: 1.6128 - val_accuracy: 0.8480\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6105 - accuracy: 0.8501 - val_loss: 1.6096 - val_accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6095 - accuracy: 0.8510 - val_loss: 1.6059 - val_accuracy: 0.8540\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6079 - accuracy: 0.8523 - val_loss: 1.6060 - val_accuracy: 0.8539\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6093 - accuracy: 0.8511 - val_loss: 1.6058 - val_accuracy: 0.8553\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6060 - accuracy: 0.8543 - val_loss: 1.6001 - val_accuracy: 0.8588\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6052 - accuracy: 0.8551 - val_loss: 1.6034 - val_accuracy: 0.8565\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6041 - accuracy: 0.8559 - val_loss: 1.6009 - val_accuracy: 0.8585\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6032 - accuracy: 0.8568 - val_loss: 1.6016 - val_accuracy: 0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [08:54, 235.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8127 - accuracy: 0.6460 - val_loss: 1.7991 - val_accuracy: 0.6591\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7134 - accuracy: 0.7481 - val_loss: 1.6627 - val_accuracy: 0.7991\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6637 - accuracy: 0.7976 - val_loss: 1.6484 - val_accuracy: 0.8124\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6480 - accuracy: 0.8131 - val_loss: 1.6398 - val_accuracy: 0.8206\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6410 - accuracy: 0.8206 - val_loss: 1.6309 - val_accuracy: 0.8293\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6341 - accuracy: 0.8266 - val_loss: 1.6312 - val_accuracy: 0.8298\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6271 - accuracy: 0.8336 - val_loss: 1.6262 - val_accuracy: 0.8337\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6288 - accuracy: 0.8322 - val_loss: 1.6219 - val_accuracy: 0.8386\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6244 - accuracy: 0.8362 - val_loss: 1.6165 - val_accuracy: 0.8437\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.6231 - accuracy: 0.8373 - val_loss: 1.6163 - val_accuracy: 0.8442\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6225 - accuracy: 0.8385 - val_loss: 1.6143 - val_accuracy: 0.8462\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6171 - accuracy: 0.8440 - val_loss: 1.6162 - val_accuracy: 0.8449\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6165 - accuracy: 0.8438 - val_loss: 1.6179 - val_accuracy: 0.8430\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6148 - accuracy: 0.8458 - val_loss: 1.6099 - val_accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6128 - accuracy: 0.8479 - val_loss: 1.6059 - val_accuracy: 0.8542\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6110 - accuracy: 0.8493 - val_loss: 1.6073 - val_accuracy: 0.8528\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6095 - accuracy: 0.8510 - val_loss: 1.6049 - val_accuracy: 0.8557\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6092 - accuracy: 0.8512 - val_loss: 1.6060 - val_accuracy: 0.8532\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6067 - accuracy: 0.8536 - val_loss: 1.6026 - val_accuracy: 0.8582\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6062 - accuracy: 0.8541 - val_loss: 1.6008 - val_accuracy: 0.8598\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6043 - accuracy: 0.8561 - val_loss: 1.6068 - val_accuracy: 0.8541\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6047 - accuracy: 0.8558 - val_loss: 1.5992 - val_accuracy: 0.8610\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6046 - accuracy: 0.8561 - val_loss: 1.5989 - val_accuracy: 0.8616\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6042 - accuracy: 0.8561 - val_loss: 1.6092 - val_accuracy: 0.8506\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6014 - accuracy: 0.8583 - val_loss: 1.5987 - val_accuracy: 0.8608\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6003 - accuracy: 0.8596 - val_loss: 1.5984 - val_accuracy: 0.8622\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5990 - accuracy: 0.8610 - val_loss: 1.5964 - val_accuracy: 0.8636\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5998 - accuracy: 0.8601 - val_loss: 1.5995 - val_accuracy: 0.8606\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6010 - accuracy: 0.8591 - val_loss: 1.5977 - val_accuracy: 0.8631\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.5981 - accuracy: 0.8620 - val_loss: 1.5973 - val_accuracy: 0.8624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [16:51, 307.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8352 - accuracy: 0.6269 - val_loss: 1.7653 - val_accuracy: 0.6964\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7541 - accuracy: 0.7078 - val_loss: 1.7399 - val_accuracy: 0.7209\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7386 - accuracy: 0.7223 - val_loss: 1.7216 - val_accuracy: 0.7397\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7256 - accuracy: 0.7348 - val_loss: 1.7190 - val_accuracy: 0.7415\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7193 - accuracy: 0.7410 - val_loss: 1.7182 - val_accuracy: 0.7409\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7144 - accuracy: 0.7456 - val_loss: 1.6688 - val_accuracy: 0.7913\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6610 - accuracy: 0.8009 - val_loss: 1.6414 - val_accuracy: 0.8203\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6477 - accuracy: 0.8138 - val_loss: 1.6382 - val_accuracy: 0.8226\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6399 - accuracy: 0.8212 - val_loss: 1.6322 - val_accuracy: 0.8282\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6357 - accuracy: 0.8255 - val_loss: 1.6274 - val_accuracy: 0.8336\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6371 - accuracy: 0.8247 - val_loss: 1.6288 - val_accuracy: 0.8322\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6293 - accuracy: 0.8317 - val_loss: 1.6187 - val_accuracy: 0.8423\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6256 - accuracy: 0.8354 - val_loss: 1.6181 - val_accuracy: 0.8433\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6219 - accuracy: 0.8390 - val_loss: 1.6186 - val_accuracy: 0.8418\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6221 - accuracy: 0.8384 - val_loss: 1.6182 - val_accuracy: 0.8423\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6318 - accuracy: 0.8314 - val_loss: 1.6260 - val_accuracy: 0.8359\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6215 - accuracy: 0.8405 - val_loss: 1.6146 - val_accuracy: 0.8473\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.6173 - accuracy: 0.8442 - val_loss: 1.6170 - val_accuracy: 0.8440\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6153 - accuracy: 0.8459 - val_loss: 1.6145 - val_accuracy: 0.8466\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6128 - accuracy: 0.8486 - val_loss: 1.6104 - val_accuracy: 0.8517\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6107 - accuracy: 0.8500 - val_loss: 1.6071 - val_accuracy: 0.8528\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6091 - accuracy: 0.8518 - val_loss: 1.6053 - val_accuracy: 0.8553\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6086 - accuracy: 0.8517 - val_loss: 1.6027 - val_accuracy: 0.8573\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6075 - accuracy: 0.8530 - val_loss: 1.6040 - val_accuracy: 0.8562\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6065 - accuracy: 0.8540 - val_loss: 1.6050 - val_accuracy: 0.8546\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6045 - accuracy: 0.8558 - val_loss: 1.6020 - val_accuracy: 0.8580\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6036 - accuracy: 0.8565 - val_loss: 1.6032 - val_accuracy: 0.8573\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.6033 - accuracy: 0.8571 - val_loss: 1.6017 - val_accuracy: 0.8579\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6020 - accuracy: 0.8582 - val_loss: 1.6032 - val_accuracy: 0.8570\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6005 - accuracy: 0.8594 - val_loss: 1.6013 - val_accuracy: 0.8581\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5998 - accuracy: 0.8601 - val_loss: 1.6012 - val_accuracy: 0.8574\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6018 - accuracy: 0.8582 - val_loss: 1.6000 - val_accuracy: 0.8597\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5994 - accuracy: 0.8602 - val_loss: 1.5991 - val_accuracy: 0.8601\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5985 - accuracy: 0.8609 - val_loss: 1.5967 - val_accuracy: 0.8628\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5973 - accuracy: 0.8619 - val_loss: 1.5998 - val_accuracy: 0.8585\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5971 - accuracy: 0.8622 - val_loss: 1.5972 - val_accuracy: 0.8614\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.5962 - accuracy: 0.8626 - val_loss: 1.5982 - val_accuracy: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [26:34, 390.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.9336 - accuracy: 0.5246 - val_loss: 1.8559 - val_accuracy: 0.6027\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8380 - accuracy: 0.6214 - val_loss: 1.8290 - val_accuracy: 0.6307\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8234 - accuracy: 0.6353 - val_loss: 1.8156 - val_accuracy: 0.6427\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7794 - accuracy: 0.6804 - val_loss: 1.7346 - val_accuracy: 0.7263\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7312 - accuracy: 0.7294 - val_loss: 1.7310 - val_accuracy: 0.7297\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7347 - accuracy: 0.7263 - val_loss: 1.7218 - val_accuracy: 0.7388\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7197 - accuracy: 0.7404 - val_loss: 1.7166 - val_accuracy: 0.7427\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7160 - accuracy: 0.7441 - val_loss: 1.7144 - val_accuracy: 0.7466\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7129 - accuracy: 0.7472 - val_loss: 1.7120 - val_accuracy: 0.7479\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7106 - accuracy: 0.7496 - val_loss: 1.7100 - val_accuracy: 0.7502\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7101 - accuracy: 0.7504 - val_loss: 1.7025 - val_accuracy: 0.7583\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7057 - accuracy: 0.7546 - val_loss: 1.7071 - val_accuracy: 0.7524\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7022 - accuracy: 0.7579 - val_loss: 1.7010 - val_accuracy: 0.7592\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7023 - accuracy: 0.7577 - val_loss: 1.7014 - val_accuracy: 0.7585\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7007 - accuracy: 0.7595 - val_loss: 1.7003 - val_accuracy: 0.7596\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7081 - accuracy: 0.7527 - val_loss: 1.7031 - val_accuracy: 0.7575\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6998 - accuracy: 0.7605 - val_loss: 1.6987 - val_accuracy: 0.7622\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6976 - accuracy: 0.7624 - val_loss: 1.6963 - val_accuracy: 0.7643\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6962 - accuracy: 0.7638 - val_loss: 1.6954 - val_accuracy: 0.7651\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6952 - accuracy: 0.7646 - val_loss: 1.6959 - val_accuracy: 0.7642\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6638 - accuracy: 0.7998 - val_loss: 1.6351 - val_accuracy: 0.8268\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6312 - accuracy: 0.8309 - val_loss: 1.6215 - val_accuracy: 0.8408\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6240 - accuracy: 0.8384 - val_loss: 1.6170 - val_accuracy: 0.8459\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.6189 - accuracy: 0.8431 - val_loss: 1.6166 - val_accuracy: 0.8456\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6155 - accuracy: 0.8465 - val_loss: 1.6144 - val_accuracy: 0.8473\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6134 - accuracy: 0.8485 - val_loss: 1.6132 - val_accuracy: 0.8480\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6103 - accuracy: 0.8511 - val_loss: 1.6104 - val_accuracy: 0.8504\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6090 - accuracy: 0.8522 - val_loss: 1.6095 - val_accuracy: 0.8522\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6085 - accuracy: 0.8525 - val_loss: 1.6059 - val_accuracy: 0.8541\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.6057 - accuracy: 0.8553 - val_loss: 1.6070 - val_accuracy: 0.8541\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6049 - accuracy: 0.8561 - val_loss: 1.6088 - val_accuracy: 0.8516\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6037 - accuracy: 0.8576 - val_loss: 1.6023 - val_accuracy: 0.8583\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6030 - accuracy: 0.8582 - val_loss: 1.6047 - val_accuracy: 0.8561\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6012 - accuracy: 0.8596 - val_loss: 1.6009 - val_accuracy: 0.8598\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6001 - accuracy: 0.8605 - val_loss: 1.6014 - val_accuracy: 0.8603\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6009 - accuracy: 0.8606 - val_loss: 1.6020 - val_accuracy: 0.8594\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5995 - accuracy: 0.8613 - val_loss: 1.6002 - val_accuracy: 0.8602\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5984 - accuracy: 0.8621 - val_loss: 1.5991 - val_accuracy: 0.8613\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5965 - accuracy: 0.8644 - val_loss: 1.6005 - val_accuracy: 0.8595\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5956 - accuracy: 0.8647 - val_loss: 1.5989 - val_accuracy: 0.8614\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5968 - accuracy: 0.8638 - val_loss: 1.5997 - val_accuracy: 0.8602\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5955 - accuracy: 0.8649 - val_loss: 1.5969 - val_accuracy: 0.8637\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5972 - accuracy: 0.8629 - val_loss: 1.5947 - val_accuracy: 0.8640\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5928 - accuracy: 0.8672 - val_loss: 1.5948 - val_accuracy: 0.8655\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5921 - accuracy: 0.8679 - val_loss: 1.5952 - val_accuracy: 0.8648\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5931 - accuracy: 0.8669 - val_loss: 1.5932 - val_accuracy: 0.8668\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5909 - accuracy: 0.8689 - val_loss: 1.5928 - val_accuracy: 0.8666\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5920 - accuracy: 0.8679 - val_loss: 1.5932 - val_accuracy: 0.8671\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5918 - accuracy: 0.8679 - val_loss: 1.5964 - val_accuracy: 0.8632\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5907 - accuracy: 0.8693 - val_loss: 1.5942 - val_accuracy: 0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [39:47, 511.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.9094 - accuracy: 0.5496 - val_loss: 1.8354 - val_accuracy: 0.6250\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7955 - accuracy: 0.6650 - val_loss: 1.7670 - val_accuracy: 0.6944\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7478 - accuracy: 0.7137 - val_loss: 1.6904 - val_accuracy: 0.7719\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6733 - accuracy: 0.7885 - val_loss: 1.6621 - val_accuracy: 0.7999\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6575 - accuracy: 0.8038 - val_loss: 1.6480 - val_accuracy: 0.8153\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6767 - accuracy: 0.7854 - val_loss: 1.6560 - val_accuracy: 0.8055\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6496 - accuracy: 0.8117 - val_loss: 1.6444 - val_accuracy: 0.8166\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6408 - accuracy: 0.8205 - val_loss: 1.6373 - val_accuracy: 0.8239\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6346 - accuracy: 0.8265 - val_loss: 1.6333 - val_accuracy: 0.8279\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6323 - accuracy: 0.8288 - val_loss: 1.6301 - val_accuracy: 0.8316\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6418 - accuracy: 0.8193 - val_loss: 1.6319 - val_accuracy: 0.8308\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6315 - accuracy: 0.8300 - val_loss: 1.6247 - val_accuracy: 0.8361\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.6270 - accuracy: 0.8338 - val_loss: 1.6250 - val_accuracy: 0.8362\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6216 - accuracy: 0.8396 - val_loss: 1.6163 - val_accuracy: 0.8448\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6219 - accuracy: 0.8395 - val_loss: 1.6198 - val_accuracy: 0.8419\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6384 - accuracy: 0.8243 - val_loss: 1.6259 - val_accuracy: 0.8358\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6248 - accuracy: 0.8371 - val_loss: 1.6206 - val_accuracy: 0.8405\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6207 - accuracy: 0.8414 - val_loss: 1.6187 - val_accuracy: 0.8421\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6195 - accuracy: 0.8418 - val_loss: 1.6216 - val_accuracy: 0.8413\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6167 - accuracy: 0.8449 - val_loss: 1.6244 - val_accuracy: 0.8376\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6418 - accuracy: 0.8223 - val_loss: 1.6252 - val_accuracy: 0.8359\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6212 - accuracy: 0.8417 - val_loss: 1.6183 - val_accuracy: 0.8438\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6166 - accuracy: 0.8455 - val_loss: 1.6154 - val_accuracy: 0.8471\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6155 - accuracy: 0.8466 - val_loss: 1.6126 - val_accuracy: 0.8494\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6121 - accuracy: 0.8501 - val_loss: 1.6092 - val_accuracy: 0.8516\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6479 - accuracy: 0.8199 - val_loss: 1.6275 - val_accuracy: 0.8390\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6242 - accuracy: 0.8414 - val_loss: 1.6206 - val_accuracy: 0.8429\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6200 - accuracy: 0.8448 - val_loss: 1.6195 - val_accuracy: 0.8446\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6170 - accuracy: 0.8469 - val_loss: 1.6182 - val_accuracy: 0.8452\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6149 - accuracy: 0.8487 - val_loss: 1.6215 - val_accuracy: 0.8411\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6132 - accuracy: 0.8502 - val_loss: 1.6131 - val_accuracy: 0.8501\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6102 - accuracy: 0.8530 - val_loss: 1.6113 - val_accuracy: 0.8515\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6102 - accuracy: 0.8528 - val_loss: 1.6076 - val_accuracy: 0.8555\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6084 - accuracy: 0.8547 - val_loss: 1.6097 - val_accuracy: 0.8521\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6064 - accuracy: 0.8565 - val_loss: 1.6047 - val_accuracy: 0.8578\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6058 - accuracy: 0.8565 - val_loss: 1.6079 - val_accuracy: 0.8552\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6061 - accuracy: 0.8560 - val_loss: 1.6074 - val_accuracy: 0.8551\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6027 - accuracy: 0.8596 - val_loss: 1.6025 - val_accuracy: 0.8590\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6031 - accuracy: 0.8591 - val_loss: 1.6047 - val_accuracy: 0.8569\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6012 - accuracy: 0.8610 - val_loss: 1.6021 - val_accuracy: 0.8601\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6009 - accuracy: 0.8607 - val_loss: 1.6024 - val_accuracy: 0.8588\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6006 - accuracy: 0.8613 - val_loss: 1.6053 - val_accuracy: 0.8558\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5991 - accuracy: 0.8625 - val_loss: 1.6003 - val_accuracy: 0.8609\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5997 - accuracy: 0.8620 - val_loss: 1.6015 - val_accuracy: 0.8604\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5713 - accuracy: 0.8930 - val_loss: 1.5456 - val_accuracy: 0.9190\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5395 - accuracy: 0.9254 - val_loss: 1.5347 - val_accuracy: 0.9289\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5342 - accuracy: 0.9295 - val_loss: 1.5427 - val_accuracy: 0.9207\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5323 - accuracy: 0.9316 - val_loss: 1.5284 - val_accuracy: 0.9350\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5286 - accuracy: 0.9347 - val_loss: 1.5289 - val_accuracy: 0.9344\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5255 - accuracy: 0.9378 - val_loss: 1.5244 - val_accuracy: 0.9387\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5230 - accuracy: 0.9403 - val_loss: 1.5252 - val_accuracy: 0.9378\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5248 - accuracy: 0.9379 - val_loss: 1.5337 - val_accuracy: 0.9283\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5222 - accuracy: 0.9408 - val_loss: 1.5204 - val_accuracy: 0.9428\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5212 - accuracy: 0.9416 - val_loss: 1.5241 - val_accuracy: 0.9385\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5203 - accuracy: 0.9425 - val_loss: 1.5180 - val_accuracy: 0.9446\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5194 - accuracy: 0.9432 - val_loss: 1.5145 - val_accuracy: 0.9482\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5184 - accuracy: 0.9444 - val_loss: 1.5203 - val_accuracy: 0.9431\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5179 - accuracy: 0.9448 - val_loss: 1.5177 - val_accuracy: 0.9436\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5187 - accuracy: 0.9440 - val_loss: 1.5170 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [55:22, 638.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.9963 - accuracy: 0.4616 - val_loss: 1.9299 - val_accuracy: 0.5280\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8911 - accuracy: 0.5684 - val_loss: 1.8004 - val_accuracy: 0.6610\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7865 - accuracy: 0.6744 - val_loss: 1.7605 - val_accuracy: 0.7004\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7584 - accuracy: 0.7017 - val_loss: 1.7429 - val_accuracy: 0.7182\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7475 - accuracy: 0.7131 - val_loss: 1.7370 - val_accuracy: 0.7242\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7559 - accuracy: 0.7048 - val_loss: 1.7399 - val_accuracy: 0.7193\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7382 - accuracy: 0.7224 - val_loss: 1.7332 - val_accuracy: 0.7276\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7314 - accuracy: 0.7291 - val_loss: 1.7247 - val_accuracy: 0.7355\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7286 - accuracy: 0.7320 - val_loss: 1.7253 - val_accuracy: 0.7352\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7263 - accuracy: 0.7339 - val_loss: 1.7205 - val_accuracy: 0.7393\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7652 - accuracy: 0.6962 - val_loss: 1.7413 - val_accuracy: 0.7204\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7384 - accuracy: 0.7226 - val_loss: 1.7245 - val_accuracy: 0.7368\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7310 - accuracy: 0.7297 - val_loss: 1.7213 - val_accuracy: 0.7387\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7252 - accuracy: 0.7349 - val_loss: 1.7178 - val_accuracy: 0.7434\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7190 - accuracy: 0.7410 - val_loss: 1.7174 - val_accuracy: 0.7420\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7324 - accuracy: 0.7290 - val_loss: 1.7182 - val_accuracy: 0.7419\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7193 - accuracy: 0.7407 - val_loss: 1.7151 - val_accuracy: 0.7444\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7166 - accuracy: 0.7438 - val_loss: 1.7125 - val_accuracy: 0.7473\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6713 - accuracy: 0.7903 - val_loss: 1.6316 - val_accuracy: 0.8310\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6317 - accuracy: 0.8304 - val_loss: 1.6374 - val_accuracy: 0.8246\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6586 - accuracy: 0.8071 - val_loss: 1.6357 - val_accuracy: 0.8284\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6322 - accuracy: 0.8309 - val_loss: 1.6330 - val_accuracy: 0.8289\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6279 - accuracy: 0.8347 - val_loss: 1.6229 - val_accuracy: 0.8383\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6257 - accuracy: 0.8367 - val_loss: 1.6305 - val_accuracy: 0.8325\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6228 - accuracy: 0.8393 - val_loss: 1.6228 - val_accuracy: 0.8388\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7066 - accuracy: 0.7601 - val_loss: 1.6410 - val_accuracy: 0.8222\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6366 - accuracy: 0.8282 - val_loss: 1.6295 - val_accuracy: 0.8347\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6301 - accuracy: 0.8332 - val_loss: 1.6253 - val_accuracy: 0.8378\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6251 - accuracy: 0.8385 - val_loss: 1.6230 - val_accuracy: 0.8395\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6222 - accuracy: 0.8407 - val_loss: 1.6251 - val_accuracy: 0.8384\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8588 - accuracy: 0.6057 - val_loss: 1.8077 - val_accuracy: 0.6527\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8041 - accuracy: 0.6529 - val_loss: 1.7940 - val_accuracy: 0.6616\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7964 - accuracy: 0.6561 - val_loss: 1.7902 - val_accuracy: 0.6630\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7748 - accuracy: 0.6815 - val_loss: 1.7263 - val_accuracy: 0.7448\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7257 - accuracy: 0.7425 - val_loss: 1.7190 - val_accuracy: 0.7475\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7208 - accuracy: 0.7454 - val_loss: 1.7181 - val_accuracy: 0.7476\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7183 - accuracy: 0.7465 - val_loss: 1.7115 - val_accuracy: 0.7520\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7154 - accuracy: 0.7484 - val_loss: 1.7103 - val_accuracy: 0.7531\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7129 - accuracy: 0.7500 - val_loss: 1.7096 - val_accuracy: 0.7520\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7142 - accuracy: 0.7482 - val_loss: 1.7093 - val_accuracy: 0.7531\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7122 - accuracy: 0.7502 - val_loss: 1.7105 - val_accuracy: 0.7526\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7107 - accuracy: 0.7516 - val_loss: 1.7091 - val_accuracy: 0.7525\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7097 - accuracy: 0.7521 - val_loss: 1.7079 - val_accuracy: 0.7529\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7084 - accuracy: 0.7529 - val_loss: 1.7041 - val_accuracy: 0.7571\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7076 - accuracy: 0.7536 - val_loss: 1.7034 - val_accuracy: 0.7565\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7068 - accuracy: 0.7540 - val_loss: 1.7074 - val_accuracy: 0.7532\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7064 - accuracy: 0.7545 - val_loss: 1.7038 - val_accuracy: 0.7574\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7053 - accuracy: 0.7554 - val_loss: 1.7019 - val_accuracy: 0.7586\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7052 - accuracy: 0.7552 - val_loss: 1.6995 - val_accuracy: 0.7606\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7041 - accuracy: 0.7557 - val_loss: 1.7013 - val_accuracy: 0.7587\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7032 - accuracy: 0.7569 - val_loss: 1.6991 - val_accuracy: 0.7615\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7036 - accuracy: 0.7569 - val_loss: 1.6971 - val_accuracy: 0.7633\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7034 - accuracy: 0.7565 - val_loss: 1.7040 - val_accuracy: 0.7559\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7023 - accuracy: 0.7571 - val_loss: 1.6977 - val_accuracy: 0.7625\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7020 - accuracy: 0.7579 - val_loss: 1.6987 - val_accuracy: 0.7614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [1:10:03, 600.54s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [1:10:03<1:10:03, 4203.77s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7530 - accuracy: 0.7068 - val_loss: 1.7190 - val_accuracy: 0.7421\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6698 - accuracy: 0.7917 - val_loss: 1.6503 - val_accuracy: 0.8115\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6454 - accuracy: 0.8161 - val_loss: 1.6359 - val_accuracy: 0.8258\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6348 - accuracy: 0.8260 - val_loss: 1.6252 - val_accuracy: 0.8353\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6313 - accuracy: 0.8296 - val_loss: 1.6227 - val_accuracy: 0.8383\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6273 - accuracy: 0.8333 - val_loss: 1.6222 - val_accuracy: 0.8399\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6237 - accuracy: 0.8371 - val_loss: 1.6157 - val_accuracy: 0.8444\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6216 - accuracy: 0.8394 - val_loss: 1.6158 - val_accuracy: 0.8442\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6170 - accuracy: 0.8437 - val_loss: 1.6102 - val_accuracy: 0.8498\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6178 - accuracy: 0.8432 - val_loss: 1.6123 - val_accuracy: 0.8484\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.6137 - accuracy: 0.8468 - val_loss: 1.6110 - val_accuracy: 0.8498\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6119 - accuracy: 0.8485 - val_loss: 1.6075 - val_accuracy: 0.8534\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6123 - accuracy: 0.8479 - val_loss: 1.6097 - val_accuracy: 0.8505\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6104 - accuracy: 0.8498 - val_loss: 1.6048 - val_accuracy: 0.8553\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6069 - accuracy: 0.8531 - val_loss: 1.6138 - val_accuracy: 0.8459\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6074 - accuracy: 0.8527 - val_loss: 1.6016 - val_accuracy: 0.8586\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6054 - accuracy: 0.8550 - val_loss: 1.6017 - val_accuracy: 0.8587\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6049 - accuracy: 0.8555 - val_loss: 1.5969 - val_accuracy: 0.8632\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6059 - accuracy: 0.8543 - val_loss: 1.6025 - val_accuracy: 0.8578\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6028 - accuracy: 0.8571 - val_loss: 1.5988 - val_accuracy: 0.8611\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6023 - accuracy: 0.8577 - val_loss: 1.5950 - val_accuracy: 0.8647\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6033 - accuracy: 0.8566 - val_loss: 1.6029 - val_accuracy: 0.8567\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6014 - accuracy: 0.8586 - val_loss: 1.5955 - val_accuracy: 0.8638\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5997 - accuracy: 0.8605 - val_loss: 1.5937 - val_accuracy: 0.8663\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5984 - accuracy: 0.8616 - val_loss: 1.5955 - val_accuracy: 0.8644\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5972 - accuracy: 0.8626 - val_loss: 1.5957 - val_accuracy: 0.8639\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5953 - accuracy: 0.8647 - val_loss: 1.5892 - val_accuracy: 0.8710\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5952 - accuracy: 0.8648 - val_loss: 1.5902 - val_accuracy: 0.8695\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5952 - accuracy: 0.8644 - val_loss: 1.5881 - val_accuracy: 0.8717\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5942 - accuracy: 0.8654 - val_loss: 1.5937 - val_accuracy: 0.8658\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5950 - accuracy: 0.8645 - val_loss: 1.6025 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5949 - accuracy: 0.8647 - val_loss: 1.5981 - val_accuracy: 0.8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [08:34, 514.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7546 - accuracy: 0.7049 - val_loss: 1.7172 - val_accuracy: 0.7423\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7173 - accuracy: 0.7428 - val_loss: 1.7087 - val_accuracy: 0.7510\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7106 - accuracy: 0.7497 - val_loss: 1.7075 - val_accuracy: 0.7521\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6651 - accuracy: 0.7970 - val_loss: 1.6380 - val_accuracy: 0.8243\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6378 - accuracy: 0.8237 - val_loss: 1.6308 - val_accuracy: 0.8298\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6332 - accuracy: 0.8278 - val_loss: 1.6235 - val_accuracy: 0.8373\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6258 - accuracy: 0.8352 - val_loss: 1.6190 - val_accuracy: 0.8419\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6250 - accuracy: 0.8357 - val_loss: 1.6204 - val_accuracy: 0.8403\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6199 - accuracy: 0.8405 - val_loss: 1.6160 - val_accuracy: 0.8453\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6197 - accuracy: 0.8408 - val_loss: 1.6073 - val_accuracy: 0.8531\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6160 - accuracy: 0.8445 - val_loss: 1.6148 - val_accuracy: 0.8467\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6143 - accuracy: 0.8461 - val_loss: 1.6067 - val_accuracy: 0.8542\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6123 - accuracy: 0.8481 - val_loss: 1.6091 - val_accuracy: 0.8506\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6104 - accuracy: 0.8497 - val_loss: 1.6071 - val_accuracy: 0.8529\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6084 - accuracy: 0.8523 - val_loss: 1.6042 - val_accuracy: 0.8563\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6079 - accuracy: 0.8525 - val_loss: 1.6053 - val_accuracy: 0.8543\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6093 - accuracy: 0.8509 - val_loss: 1.6052 - val_accuracy: 0.8546\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6061 - accuracy: 0.8537 - val_loss: 1.6040 - val_accuracy: 0.8557\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6042 - accuracy: 0.8554 - val_loss: 1.6007 - val_accuracy: 0.8582\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6049 - accuracy: 0.8545 - val_loss: 1.5969 - val_accuracy: 0.8618\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6030 - accuracy: 0.8565 - val_loss: 1.5981 - val_accuracy: 0.8604\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6024 - accuracy: 0.8565 - val_loss: 1.5970 - val_accuracy: 0.8620\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6027 - accuracy: 0.8564 - val_loss: 1.5986 - val_accuracy: 0.8616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [14:48, 472.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7912 - accuracy: 0.6679 - val_loss: 1.7263 - val_accuracy: 0.7342\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7256 - accuracy: 0.7347 - val_loss: 1.7177 - val_accuracy: 0.7423\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7184 - accuracy: 0.7419 - val_loss: 1.7084 - val_accuracy: 0.7517\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7128 - accuracy: 0.7471 - val_loss: 1.7073 - val_accuracy: 0.7525\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6695 - accuracy: 0.7911 - val_loss: 1.6476 - val_accuracy: 0.8142\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6475 - accuracy: 0.8138 - val_loss: 1.6335 - val_accuracy: 0.8272\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6376 - accuracy: 0.8238 - val_loss: 1.6306 - val_accuracy: 0.8315\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6329 - accuracy: 0.8281 - val_loss: 1.6252 - val_accuracy: 0.8368\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6332 - accuracy: 0.8275 - val_loss: 1.6255 - val_accuracy: 0.8358\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6256 - accuracy: 0.8349 - val_loss: 1.6209 - val_accuracy: 0.8394\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6253 - accuracy: 0.8357 - val_loss: 1.6154 - val_accuracy: 0.8460\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6199 - accuracy: 0.8405 - val_loss: 1.6176 - val_accuracy: 0.8434\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6186 - accuracy: 0.8418 - val_loss: 1.6131 - val_accuracy: 0.8478\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6161 - accuracy: 0.8448 - val_loss: 1.6114 - val_accuracy: 0.8482\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6153 - accuracy: 0.8453 - val_loss: 1.6097 - val_accuracy: 0.8514\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6118 - accuracy: 0.8487 - val_loss: 1.6097 - val_accuracy: 0.8513\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6104 - accuracy: 0.8504 - val_loss: 1.6099 - val_accuracy: 0.8503\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6112 - accuracy: 0.8494 - val_loss: 1.6056 - val_accuracy: 0.8549\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6087 - accuracy: 0.8521 - val_loss: 1.6089 - val_accuracy: 0.8512\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6096 - accuracy: 0.8512 - val_loss: 1.6091 - val_accuracy: 0.8519\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6100 - accuracy: 0.8508 - val_loss: 1.6078 - val_accuracy: 0.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [20:29, 432.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8397 - accuracy: 0.6239 - val_loss: 1.7647 - val_accuracy: 0.6965\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7597 - accuracy: 0.7023 - val_loss: 1.7417 - val_accuracy: 0.7211\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7404 - accuracy: 0.7204 - val_loss: 1.7398 - val_accuracy: 0.7206\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7302 - accuracy: 0.7305 - val_loss: 1.7196 - val_accuracy: 0.7411\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7252 - accuracy: 0.7349 - val_loss: 1.7191 - val_accuracy: 0.7420\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7227 - accuracy: 0.7375 - val_loss: 1.7210 - val_accuracy: 0.7399\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7153 - accuracy: 0.7445 - val_loss: 1.7165 - val_accuracy: 0.7437\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7129 - accuracy: 0.7471 - val_loss: 1.7077 - val_accuracy: 0.7523\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7095 - accuracy: 0.7508 - val_loss: 1.7061 - val_accuracy: 0.7538\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7080 - accuracy: 0.7518 - val_loss: 1.7012 - val_accuracy: 0.7583\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7078 - accuracy: 0.7527 - val_loss: 1.7084 - val_accuracy: 0.7520\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7033 - accuracy: 0.7563 - val_loss: 1.7031 - val_accuracy: 0.7565\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7014 - accuracy: 0.7586 - val_loss: 1.7026 - val_accuracy: 0.7568\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7007 - accuracy: 0.7590 - val_loss: 1.6997 - val_accuracy: 0.7599\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7003 - accuracy: 0.7593 - val_loss: 1.6954 - val_accuracy: 0.7646\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6688 - accuracy: 0.7932 - val_loss: 1.6263 - val_accuracy: 0.8360\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6224 - accuracy: 0.8397 - val_loss: 1.6172 - val_accuracy: 0.8432\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6164 - accuracy: 0.8454 - val_loss: 1.6119 - val_accuracy: 0.8489\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6136 - accuracy: 0.8472 - val_loss: 1.6102 - val_accuracy: 0.8519\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6009 - accuracy: 0.8609 - val_loss: 1.5678 - val_accuracy: 0.8956\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5490 - accuracy: 0.9144 - val_loss: 1.5356 - val_accuracy: 0.9274\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5393 - accuracy: 0.9234 - val_loss: 1.5295 - val_accuracy: 0.9329\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5372 - accuracy: 0.9253 - val_loss: 1.5275 - val_accuracy: 0.9349\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5340 - accuracy: 0.9283 - val_loss: 1.5301 - val_accuracy: 0.9323\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5295 - accuracy: 0.9328 - val_loss: 1.5206 - val_accuracy: 0.9419\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5274 - accuracy: 0.9350 - val_loss: 1.5215 - val_accuracy: 0.9405\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5263 - accuracy: 0.9357 - val_loss: 1.5210 - val_accuracy: 0.9404\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5248 - accuracy: 0.9370 - val_loss: 1.5194 - val_accuracy: 0.9427\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5224 - accuracy: 0.9398 - val_loss: 1.5191 - val_accuracy: 0.9425\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5212 - accuracy: 0.9406 - val_loss: 1.5199 - val_accuracy: 0.9414\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5209 - accuracy: 0.9412 - val_loss: 1.5191 - val_accuracy: 0.9428\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5201 - accuracy: 0.9416 - val_loss: 1.5163 - val_accuracy: 0.9447\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5176 - accuracy: 0.9443 - val_loss: 1.5145 - val_accuracy: 0.9464\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.5178 - accuracy: 0.9438 - val_loss: 1.5170 - val_accuracy: 0.9442\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5153 - accuracy: 0.9467 - val_loss: 1.5115 - val_accuracy: 0.9497\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5141 - accuracy: 0.9479 - val_loss: 1.5169 - val_accuracy: 0.9444\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5138 - accuracy: 0.9481 - val_loss: 1.5156 - val_accuracy: 0.9460\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5130 - accuracy: 0.9485 - val_loss: 1.5177 - val_accuracy: 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [30:43, 487.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.9254 - accuracy: 0.5330 - val_loss: 1.8422 - val_accuracy: 0.6173\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.7885 - accuracy: 0.6723 - val_loss: 1.7533 - val_accuracy: 0.7080\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7444 - accuracy: 0.7164 - val_loss: 1.7425 - val_accuracy: 0.7185\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7330 - accuracy: 0.7273 - val_loss: 1.7256 - val_accuracy: 0.7342\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7247 - accuracy: 0.7358 - val_loss: 1.7205 - val_accuracy: 0.7397\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7314 - accuracy: 0.7288 - val_loss: 1.7152 - val_accuracy: 0.7460\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7190 - accuracy: 0.7411 - val_loss: 1.7179 - val_accuracy: 0.7419\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7152 - accuracy: 0.7448 - val_loss: 1.7103 - val_accuracy: 0.7505\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7110 - accuracy: 0.7490 - val_loss: 1.7106 - val_accuracy: 0.7482\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.7097 - accuracy: 0.7505 - val_loss: 1.7141 - val_accuracy: 0.7452\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7147 - accuracy: 0.7457 - val_loss: 1.7104 - val_accuracy: 0.7502\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7087 - accuracy: 0.7517 - val_loss: 1.7085 - val_accuracy: 0.7516\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7050 - accuracy: 0.7550 - val_loss: 1.7037 - val_accuracy: 0.7568\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7045 - accuracy: 0.7557 - val_loss: 1.7039 - val_accuracy: 0.7559\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7043 - accuracy: 0.7556 - val_loss: 1.7052 - val_accuracy: 0.7544\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7115 - accuracy: 0.7495 - val_loss: 1.7078 - val_accuracy: 0.7529\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7029 - accuracy: 0.7572 - val_loss: 1.7009 - val_accuracy: 0.7590\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7005 - accuracy: 0.7597 - val_loss: 1.7002 - val_accuracy: 0.7598\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6998 - accuracy: 0.7600 - val_loss: 1.6997 - val_accuracy: 0.7608\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6975 - accuracy: 0.7626 - val_loss: 1.6961 - val_accuracy: 0.7641\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6826 - accuracy: 0.7795 - val_loss: 1.6374 - val_accuracy: 0.8258\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6326 - accuracy: 0.8303 - val_loss: 1.6274 - val_accuracy: 0.8342\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6262 - accuracy: 0.8360 - val_loss: 1.6215 - val_accuracy: 0.8404\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6223 - accuracy: 0.8396 - val_loss: 1.6243 - val_accuracy: 0.8364\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6187 - accuracy: 0.8429 - val_loss: 1.6149 - val_accuracy: 0.8465\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6153 - accuracy: 0.8460 - val_loss: 1.6131 - val_accuracy: 0.8483\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6138 - accuracy: 0.8476 - val_loss: 1.6143 - val_accuracy: 0.8480\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6130 - accuracy: 0.8484 - val_loss: 1.6111 - val_accuracy: 0.8504\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6107 - accuracy: 0.8501 - val_loss: 1.6073 - val_accuracy: 0.8532\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6109 - accuracy: 0.8502 - val_loss: 1.6120 - val_accuracy: 0.8496\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6092 - accuracy: 0.8516 - val_loss: 1.6061 - val_accuracy: 0.8544\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6072 - accuracy: 0.8533 - val_loss: 1.6072 - val_accuracy: 0.8540\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6040 - accuracy: 0.8566 - val_loss: 1.6039 - val_accuracy: 0.8573\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.6041 - accuracy: 0.8566 - val_loss: 1.6079 - val_accuracy: 0.8523\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6049 - accuracy: 0.8558 - val_loss: 1.6019 - val_accuracy: 0.8587\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6028 - accuracy: 0.8578 - val_loss: 1.6053 - val_accuracy: 0.8551\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6021 - accuracy: 0.8581 - val_loss: 1.6020 - val_accuracy: 0.8579\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6010 - accuracy: 0.8592 - val_loss: 1.5989 - val_accuracy: 0.8607\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6001 - accuracy: 0.8608 - val_loss: 1.6033 - val_accuracy: 0.8566\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6017 - accuracy: 0.8589 - val_loss: 1.6001 - val_accuracy: 0.8597\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5989 - accuracy: 0.8618 - val_loss: 1.5993 - val_accuracy: 0.8612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [41:36, 536.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.9092 - accuracy: 0.5505 - val_loss: 1.8592 - val_accuracy: 0.5998\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8253 - accuracy: 0.6342 - val_loss: 1.7713 - val_accuracy: 0.6882\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7600 - accuracy: 0.7006 - val_loss: 1.7530 - val_accuracy: 0.7075\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7447 - accuracy: 0.7153 - val_loss: 1.7356 - val_accuracy: 0.7237\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6918 - accuracy: 0.7695 - val_loss: 1.6583 - val_accuracy: 0.8042\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6894 - accuracy: 0.7725 - val_loss: 1.6602 - val_accuracy: 0.8023\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6587 - accuracy: 0.8028 - val_loss: 1.6505 - val_accuracy: 0.8105\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6469 - accuracy: 0.8154 - val_loss: 1.6396 - val_accuracy: 0.8218\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6407 - accuracy: 0.8207 - val_loss: 1.6331 - val_accuracy: 0.8282\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6342 - accuracy: 0.8272 - val_loss: 1.6362 - val_accuracy: 0.8251\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6392 - accuracy: 0.8223 - val_loss: 1.6281 - val_accuracy: 0.8329\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6291 - accuracy: 0.8324 - val_loss: 1.6296 - val_accuracy: 0.8311\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6246 - accuracy: 0.8367 - val_loss: 1.6227 - val_accuracy: 0.8392\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6233 - accuracy: 0.8377 - val_loss: 1.6222 - val_accuracy: 0.8389\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6195 - accuracy: 0.8416 - val_loss: 1.6183 - val_accuracy: 0.8430\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.6405 - accuracy: 0.8219 - val_loss: 1.6304 - val_accuracy: 0.8308\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6259 - accuracy: 0.8361 - val_loss: 1.6237 - val_accuracy: 0.8373\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6213 - accuracy: 0.8402 - val_loss: 1.6199 - val_accuracy: 0.8418\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6209 - accuracy: 0.8404 - val_loss: 1.6208 - val_accuracy: 0.8416\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6179 - accuracy: 0.8439 - val_loss: 1.6194 - val_accuracy: 0.8428\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6611 - accuracy: 0.8024 - val_loss: 1.6276 - val_accuracy: 0.8346\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6276 - accuracy: 0.8347 - val_loss: 1.6235 - val_accuracy: 0.8386\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6212 - accuracy: 0.8408 - val_loss: 1.6188 - val_accuracy: 0.8419\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6168 - accuracy: 0.8448 - val_loss: 1.6152 - val_accuracy: 0.8461\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6145 - accuracy: 0.8472 - val_loss: 1.6148 - val_accuracy: 0.8468\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6574 - accuracy: 0.8094 - val_loss: 1.5979 - val_accuracy: 0.8737\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5843 - accuracy: 0.8844 - val_loss: 1.5684 - val_accuracy: 0.9017\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5661 - accuracy: 0.9014 - val_loss: 1.5518 - val_accuracy: 0.9154\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5562 - accuracy: 0.9109 - val_loss: 1.5473 - val_accuracy: 0.9173\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5513 - accuracy: 0.9146 - val_loss: 1.5463 - val_accuracy: 0.9182\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5467 - accuracy: 0.9183 - val_loss: 1.5422 - val_accuracy: 0.9229\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5423 - accuracy: 0.9225 - val_loss: 1.5346 - val_accuracy: 0.9303\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5388 - accuracy: 0.9255 - val_loss: 1.5342 - val_accuracy: 0.9303\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5369 - accuracy: 0.9273 - val_loss: 1.5353 - val_accuracy: 0.9279\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5353 - accuracy: 0.9288 - val_loss: 1.5316 - val_accuracy: 0.9316\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5327 - accuracy: 0.9313 - val_loss: 1.5289 - val_accuracy: 0.9362\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5314 - accuracy: 0.9327 - val_loss: 1.5322 - val_accuracy: 0.9320\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5291 - accuracy: 0.9343 - val_loss: 1.5294 - val_accuracy: 0.9332\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5269 - accuracy: 0.9365 - val_loss: 1.5328 - val_accuracy: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [52:05, 564.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 2.0111 - accuracy: 0.4465 - val_loss: 1.8924 - val_accuracy: 0.5682\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8629 - accuracy: 0.5975 - val_loss: 1.8128 - val_accuracy: 0.6491\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7894 - accuracy: 0.6721 - val_loss: 1.7885 - val_accuracy: 0.6722\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7654 - accuracy: 0.6956 - val_loss: 1.7557 - val_accuracy: 0.7069\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7521 - accuracy: 0.7085 - val_loss: 1.7471 - val_accuracy: 0.7126\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7928 - accuracy: 0.6684 - val_loss: 1.7585 - val_accuracy: 0.7009\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7505 - accuracy: 0.7103 - val_loss: 1.7459 - val_accuracy: 0.7158\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7400 - accuracy: 0.7203 - val_loss: 1.7303 - val_accuracy: 0.7296\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7319 - accuracy: 0.7284 - val_loss: 1.7320 - val_accuracy: 0.7275\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7276 - accuracy: 0.7329 - val_loss: 1.7241 - val_accuracy: 0.7372\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7374 - accuracy: 0.7229 - val_loss: 1.7248 - val_accuracy: 0.7360\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7245 - accuracy: 0.7355 - val_loss: 1.7219 - val_accuracy: 0.7379\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7205 - accuracy: 0.7398 - val_loss: 1.7138 - val_accuracy: 0.7458\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7179 - accuracy: 0.7427 - val_loss: 1.7165 - val_accuracy: 0.7432\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7155 - accuracy: 0.7446 - val_loss: 1.7106 - val_accuracy: 0.7497\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7396 - accuracy: 0.7215 - val_loss: 1.7252 - val_accuracy: 0.7353\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7205 - accuracy: 0.7405 - val_loss: 1.7156 - val_accuracy: 0.7449\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7150 - accuracy: 0.7453 - val_loss: 1.7179 - val_accuracy: 0.7424\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7123 - accuracy: 0.7482 - val_loss: 1.7086 - val_accuracy: 0.7515\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7108 - accuracy: 0.7496 - val_loss: 1.7092 - val_accuracy: 0.7502\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7519 - accuracy: 0.7108 - val_loss: 1.7223 - val_accuracy: 0.7386\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7215 - accuracy: 0.7404 - val_loss: 1.7124 - val_accuracy: 0.7487\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7149 - accuracy: 0.7459 - val_loss: 1.7111 - val_accuracy: 0.7493\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6938 - accuracy: 0.7681 - val_loss: 1.6536 - val_accuracy: 0.8094\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6537 - accuracy: 0.8077 - val_loss: 1.6443 - val_accuracy: 0.8172\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7673 - accuracy: 0.7042 - val_loss: 1.6702 - val_accuracy: 0.8011\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6688 - accuracy: 0.7990 - val_loss: 1.6605 - val_accuracy: 0.8054\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6572 - accuracy: 0.8066 - val_loss: 1.6501 - val_accuracy: 0.8148\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6180 - accuracy: 0.8488 - val_loss: 1.5685 - val_accuracy: 0.8990\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5667 - accuracy: 0.9013 - val_loss: 1.5620 - val_accuracy: 0.9040\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.8664 - accuracy: 0.6014 - val_loss: 1.8115 - val_accuracy: 0.6424\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7455 - accuracy: 0.7233 - val_loss: 1.7286 - val_accuracy: 0.7380\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7236 - accuracy: 0.7409 - val_loss: 1.7220 - val_accuracy: 0.7438\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.7175 - accuracy: 0.7462 - val_loss: 1.7145 - val_accuracy: 0.7489\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7131 - accuracy: 0.7491 - val_loss: 1.7131 - val_accuracy: 0.7490\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7106 - accuracy: 0.7511 - val_loss: 1.7097 - val_accuracy: 0.7487\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.6439 - accuracy: 0.8220 - val_loss: 1.6368 - val_accuracy: 0.8275\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6329 - accuracy: 0.8314 - val_loss: 1.6356 - val_accuracy: 0.8261\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6305 - accuracy: 0.8328 - val_loss: 1.6313 - val_accuracy: 0.8321\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6258 - accuracy: 0.8373 - val_loss: 1.6192 - val_accuracy: 0.8361\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5585 - accuracy: 0.9093 - val_loss: 1.5584 - val_accuracy: 0.9081\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5525 - accuracy: 0.9143 - val_loss: 1.5506 - val_accuracy: 0.9135\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5491 - accuracy: 0.9162 - val_loss: 1.5555 - val_accuracy: 0.9100\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5474 - accuracy: 0.9182 - val_loss: 1.5471 - val_accuracy: 0.9179\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5449 - accuracy: 0.9204 - val_loss: 1.5391 - val_accuracy: 0.9263\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5419 - accuracy: 0.9229 - val_loss: 1.5452 - val_accuracy: 0.9188\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5404 - accuracy: 0.9240 - val_loss: 1.5366 - val_accuracy: 0.9269\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5389 - accuracy: 0.9258 - val_loss: 1.5356 - val_accuracy: 0.9290\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5377 - accuracy: 0.9262 - val_loss: 1.5350 - val_accuracy: 0.9291\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5359 - accuracy: 0.9279 - val_loss: 1.5448 - val_accuracy: 0.9187\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5361 - accuracy: 0.9277 - val_loss: 1.5337 - val_accuracy: 0.9295\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5343 - accuracy: 0.9292 - val_loss: 1.5399 - val_accuracy: 0.9235\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5328 - accuracy: 0.9310 - val_loss: 1.5366 - val_accuracy: 0.9269\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5308 - accuracy: 0.9326 - val_loss: 1.5336 - val_accuracy: 0.9285\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5300 - accuracy: 0.9336 - val_loss: 1.5327 - val_accuracy: 0.9303\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5297 - accuracy: 0.9337 - val_loss: 1.5281 - val_accuracy: 0.9350\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5282 - accuracy: 0.9351 - val_loss: 1.5272 - val_accuracy: 0.9359\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.5289 - accuracy: 0.9344 - val_loss: 1.5340 - val_accuracy: 0.9284\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5288 - accuracy: 0.9341 - val_loss: 1.5302 - val_accuracy: 0.9322\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5259 - accuracy: 0.9371 - val_loss: 1.5250 - val_accuracy: 0.9370\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5246 - accuracy: 0.9385 - val_loss: 1.5323 - val_accuracy: 0.9306\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5260 - accuracy: 0.9364 - val_loss: 1.5271 - val_accuracy: 0.9350\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.5267 - accuracy: 0.9359 - val_loss: 1.5234 - val_accuracy: 0.9386\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5245 - accuracy: 0.9381 - val_loss: 1.5265 - val_accuracy: 0.9359\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5242 - accuracy: 0.9385 - val_loss: 1.5249 - val_accuracy: 0.9374\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5234 - accuracy: 0.9392 - val_loss: 1.5229 - val_accuracy: 0.9387\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5226 - accuracy: 0.9401 - val_loss: 1.5257 - val_accuracy: 0.9374\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5223 - accuracy: 0.9401 - val_loss: 1.5212 - val_accuracy: 0.9417\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5220 - accuracy: 0.9403 - val_loss: 1.5222 - val_accuracy: 0.9400\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5212 - accuracy: 0.9415 - val_loss: 1.5249 - val_accuracy: 0.9372\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5200 - accuracy: 0.9426 - val_loss: 1.5231 - val_accuracy: 0.9397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [1:11:00, 608.64s/it]\u001b[A\n",
      "100%|██████████| 2/2 [2:21:04<00:00, 4232.14s/it]  \n"
     ]
    }
   ],
   "source": [
    "pgd_success_rates = []\n",
    "cw_success_rates = []\n",
    "all_accuracies = []\n",
    "ITERATIONS = 2\n",
    "pruning_ratios = [.0, .3, .5, .7, .8, .9, .95, .97, .98, .99]\n",
    "for j in tqdm(range(ITERATIONS)):\n",
    "    accuracies = []\n",
    "    pgd_success_rate = []\n",
    "    cw_success_rate = []\n",
    "    for index, pruning_ratio in tqdm(enumerate(pruning_ratios)):\n",
    "        model = tf.keras.models.load_model('./saved-models/mini-pipeline-CNN-baseline-model')\n",
    "        for i in range(index + 1):\n",
    "            if i != index:\n",
    "                pruned_weights = prune_weights(model, pruning_ratios[i])\n",
    "                model.set_weights(pruned_weights)\n",
    "                pruned_weights = prune_conv_layers(pruning_ratio)\n",
    "                model.set_weights(pruned_weights)\n",
    "                model = train_model(model, to_convergence=False)\n",
    "            if i == index:\n",
    "                print('final pruning and eval')\n",
    "                pruned_weights = prune_weights(model, pruning_ratios[i])\n",
    "                model.set_weights(pruned_weights)\n",
    "                model = train_model(model, to_convergence=True)\n",
    "                accuracies.append(model.evaluate(x_test, y_test, verbose=0))\n",
    "                pgd_success_rate.append(pgd_attack(model))\n",
    "                #cw_success_rate.append(cw2_attack(model))\n",
    "                \n",
    "    all_accuracies.append(accuracies)\n",
    "    pgd_success_rates.append(pgd_success_rate)\n",
    "    cw_success_rates.append(cw_success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_success_rates = get_average_success_rates(pgd_success_rates)\n",
    "avg_accuracies = get_average_accuracies(all_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(pruning_ratios, avg_success_rates)\n",
    "plt.axis([0,1,0,1])\n",
    "#plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=100,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=5,\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def prune_weights(model, pruning_ratio):\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        \n",
    "        if (index == 9) or (index == 12) :\n",
    "            #print(weight.shape)\n",
    "            #print(index)\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index+2].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            flat_weights_to_prune_df = pd.DataFrame(flat_weights_to_prune)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            #print(len(flat_weights))\n",
    "            #print('no of weights',no_of_weights_to_prune)\n",
    "            #print('weights to prune shape', flat_weights_to_prune.shape)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+2].shape\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            weights_to_prune[index+2] = weights_reshaped\n",
    "    #print(weights_to_prune)\n",
    "    return weights_to_prune\n",
    "\n",
    "def pgd_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.LinfProjectedGradientDescentAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[25/255]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/500\n",
    "\n",
    "def cw2_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        #epsilons=[.5]\n",
    "        epsilons=None\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/len(y)\n",
    "\n",
    "def prune_conv_layers(pruning_ratio):\n",
    "    layer_to_prune = [0, 3]\n",
    "    pruned_weights = model.get_weights()\n",
    "    \n",
    "    for layer in layer_to_prune:\n",
    "        converted_weights = convert_from_hwio_to_iohw(model.get_weights()[layer])\n",
    "        converted_mask = convert_from_hwio_to_iohw(model.get_weights()[layer + 2]).numpy()\n",
    "        for input_index, input_layer in enumerate(converted_weights):\n",
    "\n",
    "            for kernel_index, kernel in enumerate(input_layer):\n",
    "                dims = kernel.shape\n",
    "                flat_weights = kernel.numpy().flatten()\n",
    "                flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "                #print(no_of_weights_to_prune)\n",
    "                indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    flat_masks[idx_to_delete] = 0\n",
    "\n",
    "                converted_mask[input_index][kernel_index] = flat_masks.reshape(dims)\n",
    "        back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "        pruned_weights[layer+2] = back_converted_mask\n",
    "    \n",
    "    return pruned_weights\n",
    "\n",
    "def convert_from_hwio_to_iohw(weights_nchw):\n",
    "    return tf.transpose(weights_nchw, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def convert_from_iohw_to_hwio(weights_nhwc):\n",
    "    return tf.transpose(weights_nhwc, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "def get_average_accuracies(all_accuracies):\n",
    "    acc_per_pruning_rate=[]\n",
    "    for i in range(len(all_accuracies)):\n",
    "        for j in range(len(all_accuracies[i])):\n",
    "\n",
    "            try:\n",
    "                acc_per_pruning_rate[j].append(all_accuracies[i][j][1])\n",
    "            except:\n",
    "                acc_per_pruning_rate.append([])\n",
    "                acc_per_pruning_rate[j].append(all_accuracies[i][j][1])\n",
    "    avg_acc_per_pruning_rate = [sum(x)/len(x) for x in acc_per_pruning_rate]; avg_acc_per_pruning_rate\n",
    "    return avg_acc_per_pruning_rate\n",
    "\n",
    "def get_average_success_rates(all_success_rates):\n",
    "    success_per_pruning_rate=[]\n",
    "    for i in range(len(all_success_rates)):\n",
    "        for j in range(len(all_success_rates[i])):\n",
    "\n",
    "            try:\n",
    "                success_per_pruning_rate[j].append(all_success_rates[i][j])\n",
    "            except:\n",
    "                success_per_pruning_rate.append([])\n",
    "                success_per_pruning_rate[j].append(all_success_rates[i][j])\n",
    "    avg_success_per_pruning_rate = [sum(x)/len(x) for x in success_per_pruning_rate];avg_success_per_pruning_rate\n",
    "    return avg_success_per_pruning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x = tf.convert_to_tensor(x_train[:500].reshape(500,28*28))\n",
    "y = tf.convert_to_tensor([y_train[:500]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'weights_conv_1': tf.Variable(tf.random.normal([5, 5, 1, 6])),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'weights_conv_2': tf.Variable(tf.random.normal([5, 5, 6, 16])),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'weights_conv_3': tf.Variable(tf.random.normal([1, 1, 16, 120])),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'weights_dense_1': tf.Variable(tf.random.normal([5*5*16, 120])),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'weights_dense_2': tf.Variable(tf.random.normal([120, 84])),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'weights_dense_3': tf.Variable(tf.random.normal([84, 10])),\n",
    "}\n",
    "\n",
    "masks = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'mask_conv_1': tf.Variable(tf.ones([5, 5, 1, 6]), trainable=False),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'mask_conv_2': tf.Variable(tf.ones([5, 5, 6, 16]), trainable=False),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'mask_conv_3': tf.Variable(tf.ones([1, 1, 16, 120]), trainable=False),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'mask_dense_1': tf.Variable(tf.ones([5*5*16, 120]), trainable=False),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'mask_dense_2': tf.Variable(tf.ones([120, 84]), trainable=False),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'mask_dense_3': tf.Variable(tf.ones([84, 10]), trainable=False),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    #output depth\n",
    "    'bias_conv_1': tf.Variable(tf.random.normal([6])),\n",
    "    'bias_conv_2': tf.Variable(tf.random.normal([16])),\n",
    "    'bias_dense_1': tf.Variable(tf.random.normal([120])),\n",
    "    'bias_dense_2': tf.Variable(tf.random.normal([84])),\n",
    "    'bias_dense_3': tf.Variable(tf.random.normal([10])),\n",
    "}\n",
    "\n",
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print('inputs',inputs)\n",
    "        #print('weights', self.w)\n",
    "        #print('masks', self.m)\n",
    "        #print('weights * masks',tf.multiply(self.w, self.m))\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        #print('x', x)\n",
    "        #print('bias', self.b)\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        #print('x', x)\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='valid'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "#        return tf.keras.layers.AveragePooling2D(pool_size=(self.k, self.k), strides=None, padding=self.p, data_format='channels_first')(inputs)\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p,)# data_format='NCHW')\n",
    "    \n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, weights, mask, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        self.a = activation\n",
    "        self.m = mask\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print('dense w',self.w)\n",
    "        #print('dense i',inputs)\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        #print('bias ',self.b)\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        \n",
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(weights['weights_conv_1'], masks['mask_conv_1'], biases['bias_conv_1'], 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(weights['weights_conv_2'], masks['mask_conv_2'], biases['bias_conv_2'], 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "        #self.conv3 = CustomConvLayer(weights['weights_conv_3'], masks['mask_conv_3'], biases['bias_dense_1'], 1, 'VALID')\n",
    "        self.dense1 = CustomDenseLayer(weights['weights_dense_1'], masks['mask_dense_1'], biases['bias_dense_1'], 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(weights['weights_dense_2'], masks['mask_dense_2'], biases['bias_dense_2'], 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(weights['weights_dense_3'], masks['mask_dense_3'], biases['bias_dense_3'], 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print('input shape', inputs.shape)\n",
    "        x = tf.reshape(inputs, shape=[-1,28, 28, 1])\n",
    "        #print('after reshape',x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print('after conv1', x.shape)\n",
    "        x = self.maxpool1(x)\n",
    "        #print('after pool1',x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print('after conv2',x.shape)\n",
    "        x = self.maxpool2(x)\n",
    "        #print('yo',x.shape)\n",
    "        #x = layers.Flatten()(x)\n",
    "        #print('after pool2',x.shape)\n",
    "        #x = self.conv3(x)\n",
    "        \n",
    "        #print('after conv3',x.shape)\n",
    "        x = layers.Flatten()(x)\n",
    "        #print('after flatten',x.shape)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        #print(x.shape)\n",
    "        x =  self.dense3(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 2.0808 - accuracy: 0.3752 - val_loss: 2.0057 - val_accuracy: 0.4492\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.9756 - accuracy: 0.4816 - val_loss: 1.9314 - val_accuracy: 0.5259\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.9202 - accuracy: 0.5379 - val_loss: 1.9108 - val_accuracy: 0.5460\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.9043 - accuracy: 0.5538 - val_loss: 1.9009 - val_accuracy: 0.5576\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.8713 - accuracy: 0.5866 - val_loss: 1.8345 - val_accuracy: 0.6240\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.8198 - accuracy: 0.6389 - val_loss: 1.8146 - val_accuracy: 0.6440\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 1.8079 - accuracy: 0.6508 - val_loss: 1.8064 - val_accuracy: 0.6518\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.8034 - accuracy: 0.6553 - val_loss: 1.8001 - val_accuracy: 0.6586\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8029 - accuracy: 0.6556 - val_loss: 1.7953 - val_accuracy: 0.6631\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7991 - accuracy: 0.6590 - val_loss: 1.7989 - val_accuracy: 0.6600\n",
      "WARNING:tensorflow:From /Users/florianmerkle/anaconda3/envs/master-thesis/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./saved-models/mini-pipeline-CNN-baseline-model/assets\n"
     ]
    }
   ],
   "source": [
    "model = CustomConvModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "              \n",
    "             )\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(x_test, y_test),\n",
    "         )\n",
    "model.save('./saved-models/mini-pipeline-CNN-baseline-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgd_attack(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
