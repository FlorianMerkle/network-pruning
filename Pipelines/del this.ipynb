{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative pruning pipeline\n",
    "Model: Multi Layer Perceptron\n",
    "\n",
    "*Pruning functions as class methods*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'mlp-global-magnitude-unstruct'\n",
    "ITERATIONS = 3 #should be 10 for final experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import foolbox as fb\n",
    "import random\n",
    "\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune, Train Attack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 4s 4ms/step - loss: 1.5759 - accuracy: 0.8974 - val_loss: 1.5115 - val_accuracy: 0.9531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.5085 - accuracy: 0.9553 - val_loss: 1.5028 - val_accuracy: 0.9600\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4972 - accuracy: 0.9657 - val_loss: 1.4970 - val_accuracy: 0.9652\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4910 - accuracy: 0.9712 - val_loss: 1.4946 - val_accuracy: 0.9673\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4861 - accuracy: 0.9761 - val_loss: 1.4905 - val_accuracy: 0.9712\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4833 - accuracy: 0.9789 - val_loss: 1.4878 - val_accuracy: 0.9736\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 1.4807 - accuracy: 0.9812 - val_loss: 1.4881 - val_accuracy: 0.9733\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4795 - accuracy: 0.9821 - val_loss: 1.4863 - val_accuracy: 0.9753\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4774 - accuracy: 0.9842 - val_loss: 1.4844 - val_accuracy: 0.9769\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4762 - accuracy: 0.9854 - val_loss: 1.4867 - val_accuracy: 0.9747\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4750 - accuracy: 0.9865 - val_loss: 1.4882 - val_accuracy: 0.9730\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 1.4745 - accuracy: 0.9870 - val_loss: 1.4816 - val_accuracy: 0.9792\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4742 - accuracy: 0.9870 - val_loss: 1.4836 - val_accuracy: 0.9774\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 1.4727 - accuracy: 0.9888 - val_loss: 1.4843 - val_accuracy: 0.9775\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4726 - accuracy: 0.9888 - val_loss: 1.4844 - val_accuracy: 0.9768\n",
      "WARNING:tensorflow:From /Users/florianmerkle/dev/foolbox/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:50, 50.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3026 - accuracy: 0.1492 - val_loss: 2.3025 - val_accuracy: 0.1462\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3023 - accuracy: 0.1402 - val_loss: 2.3018 - val_accuracy: 0.1453\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2987 - accuracy: 0.1455 - val_loss: 2.2889 - val_accuracy: 0.1773\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2688 - accuracy: 0.1997 - val_loss: 2.2589 - val_accuracy: 0.2213\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2576 - accuracy: 0.2215 - val_loss: 2.2534 - val_accuracy: 0.2279\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2543 - accuracy: 0.2252 - val_loss: 2.2515 - val_accuracy: 0.2307\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2528 - accuracy: 0.2274 - val_loss: 2.2505 - val_accuracy: 0.2324\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2518 - accuracy: 0.2295 - val_loss: 2.2498 - val_accuracy: 0.2327\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2512 - accuracy: 0.2301 - val_loss: 2.2492 - val_accuracy: 0.2331\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2507 - accuracy: 0.2310 - val_loss: 2.2486 - val_accuracy: 0.2310\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2503 - accuracy: 0.2317 - val_loss: 2.2483 - val_accuracy: 0.2304\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2501 - accuracy: 0.2315 - val_loss: 2.2481 - val_accuracy: 0.2338\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 2.2498 - accuracy: 0.2322 - val_loss: 2.2478 - val_accuracy: 0.2338\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2496 - accuracy: 0.2321 - val_loss: 2.2477 - val_accuracy: 0.2340\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 2.2495 - accuracy: 0.2323 - val_loss: 2.2475 - val_accuracy: 0.2345\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 2.2493 - accuracy: 0.2325 - val_loss: 2.2475 - val_accuracy: 0.2347\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2492 - accuracy: 0.2326 - val_loss: 2.2472 - val_accuracy: 0.2348\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2490 - accuracy: 0.2328 - val_loss: 2.2471 - val_accuracy: 0.2353\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2489 - accuracy: 0.2327 - val_loss: 2.2469 - val_accuracy: 0.2352\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2488 - accuracy: 0.2330 - val_loss: 2.2469 - val_accuracy: 0.2349\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2487 - accuracy: 0.2329 - val_loss: 2.2468 - val_accuracy: 0.2349\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2486 - accuracy: 0.2332 - val_loss: 2.2467 - val_accuracy: 0.2352\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2486 - accuracy: 0.2332 - val_loss: 2.2466 - val_accuracy: 0.2353\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2485 - accuracy: 0.2334 - val_loss: 2.2466 - val_accuracy: 0.2355\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2484 - accuracy: 0.2336 - val_loss: 2.2465 - val_accuracy: 0.2357\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 2.2483 - accuracy: 0.2341 - val_loss: 2.2464 - val_accuracy: 0.2369\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2483 - accuracy: 0.2349 - val_loss: 2.2464 - val_accuracy: 0.2367\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2482 - accuracy: 0.2347 - val_loss: 2.2463 - val_accuracy: 0.2367\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.2481 - accuracy: 0.2348 - val_loss: 2.2463 - val_accuracy: 0.2367\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2481 - accuracy: 0.2348 - val_loss: 2.2462 - val_accuracy: 0.2368\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2480 - accuracy: 0.2348 - val_loss: 2.2462 - val_accuracy: 0.2368\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2480 - accuracy: 0.2349 - val_loss: 2.2461 - val_accuracy: 0.2368\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2480 - accuracy: 0.2345 - val_loss: 2.2462 - val_accuracy: 0.2356\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2479 - accuracy: 0.2345 - val_loss: 2.2461 - val_accuracy: 0.2364\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2479 - accuracy: 0.2345 - val_loss: 2.2460 - val_accuracy: 0.2369\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2479 - accuracy: 0.2349 - val_loss: 2.2460 - val_accuracy: 0.2365\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2478 - accuracy: 0.2351 - val_loss: 2.2461 - val_accuracy: 0.2363\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2478 - accuracy: 0.2345 - val_loss: 2.2460 - val_accuracy: 0.2362\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2478 - accuracy: 0.2345 - val_loss: 2.2460 - val_accuracy: 0.2360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [03:25, 102.61s/it][A\n",
      " 33%|███▎      | 1/3 [03:29<06:59, 209.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 4s 4ms/step - loss: 1.6202 - accuracy: 0.8535 - val_loss: 1.5238 - val_accuracy: 0.9401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.5133 - accuracy: 0.9505 - val_loss: 1.5049 - val_accuracy: 0.9586\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4993 - accuracy: 0.9636 - val_loss: 1.5014 - val_accuracy: 0.9611\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4915 - accuracy: 0.9712 - val_loss: 1.4911 - val_accuracy: 0.9701\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4873 - accuracy: 0.9744 - val_loss: 1.4912 - val_accuracy: 0.9711\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4831 - accuracy: 0.9789 - val_loss: 1.4900 - val_accuracy: 0.9716\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 1.4808 - accuracy: 0.9813 - val_loss: 1.4915 - val_accuracy: 0.9701\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4792 - accuracy: 0.9823 - val_loss: 1.4906 - val_accuracy: 0.9709\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4781 - accuracy: 0.9836 - val_loss: 1.4863 - val_accuracy: 0.9754\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4761 - accuracy: 0.9855 - val_loss: 1.4861 - val_accuracy: 0.9753\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4756 - accuracy: 0.9858 - val_loss: 1.4857 - val_accuracy: 0.9760\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4753 - accuracy: 0.9861 - val_loss: 1.4840 - val_accuracy: 0.9777\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4740 - accuracy: 0.9875 - val_loss: 1.4832 - val_accuracy: 0.9780\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 1.4734 - accuracy: 0.9879 - val_loss: 1.4821 - val_accuracy: 0.9786\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 1.4725 - accuracy: 0.9888 - val_loss: 1.4842 - val_accuracy: 0.9767\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4713 - accuracy: 0.9900 - val_loss: 1.4835 - val_accuracy: 0.9774\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 1.4714 - accuracy: 0.9901 - val_loss: 1.4836 - val_accuracy: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [01:05, 65.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.3008 - accuracy: 0.0987 - val_loss: 2.2978 - val_accuracy: 0.0980\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2860 - accuracy: 0.0987 - val_loss: 2.2499 - val_accuracy: 0.0980\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2424 - accuracy: 0.0987 - val_loss: 2.2400 - val_accuracy: 0.0980\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.2381 - accuracy: 0.0987 - val_loss: 2.2378 - val_accuracy: 0.0980\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2368 - accuracy: 0.0987 - val_loss: 2.2367 - val_accuracy: 0.0980\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2358 - accuracy: 0.0987 - val_loss: 2.2355 - val_accuracy: 0.0980\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2351 - accuracy: 0.0987 - val_loss: 2.2349 - val_accuracy: 0.0980\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2346 - accuracy: 0.0987 - val_loss: 2.2345 - val_accuracy: 0.0980\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2343 - accuracy: 0.0987 - val_loss: 2.2342 - val_accuracy: 0.0980\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2340 - accuracy: 0.0987 - val_loss: 2.2339 - val_accuracy: 0.0980\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2338 - accuracy: 0.0987 - val_loss: 2.2337 - val_accuracy: 0.0980\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2336 - accuracy: 0.0987 - val_loss: 2.2336 - val_accuracy: 0.0980\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2335 - accuracy: 0.0987 - val_loss: 2.2334 - val_accuracy: 0.0980\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2334 - accuracy: 0.0987 - val_loss: 2.2333 - val_accuracy: 0.0980\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2333 - accuracy: 0.0987 - val_loss: 2.2332 - val_accuracy: 0.0980\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2332 - accuracy: 0.0987 - val_loss: 2.2331 - val_accuracy: 0.0980\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2331 - accuracy: 0.0987 - val_loss: 2.2331 - val_accuracy: 0.0980\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2330 - accuracy: 0.0987 - val_loss: 2.2330 - val_accuracy: 0.0980\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 2.2329 - accuracy: 0.0987 - val_loss: 2.2330 - val_accuracy: 0.0980\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2329 - accuracy: 0.0987 - val_loss: 2.2330 - val_accuracy: 0.0980\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.2328 - accuracy: 0.0987 - val_loss: 2.2329 - val_accuracy: 0.0980\n",
      "Epoch 21/100\n",
      " 45/938 [>.............................] - ETA: 3s - loss: 2.2329 - accuracy: 0.1042"
     ]
    }
   ],
   "source": [
    "\n",
    "pgd_success_rates = []\n",
    "cw2_success_rates = []\n",
    "\n",
    "all_accuracies = []\n",
    "for j in tqdm(range(ITERATIONS)):\n",
    "    model = initialize_base_model(j, save_weights=True)\n",
    "\n",
    "    accuracies = []\n",
    "    pgd_success_rate = []\n",
    "    cw2_success_rate = []\n",
    "    compression_rates = [1, 128]\n",
    "    pruning_ratios = [1-1/x for x in compression_rates]\n",
    "    for index, pruning_ratio in tqdm(enumerate(pruning_ratios)):\n",
    "        model.load_weights(f'./saved-weights/{EXPERIMENT_NAME}-{j}')\n",
    "\n",
    "        #iteratively prune and train (only to convergence if the final stage of pruning is reached)\n",
    "        for i in range(index + 1):\n",
    "            if i != index:\n",
    "                #glocbal pruning\n",
    "                model.prune_random_global_unstruct(pruning_ratio)\n",
    "                #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                #              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                #              metrics=['accuracy'],\n",
    "                #             )\n",
    "                             \n",
    "                #finetuning\n",
    "                model = train_model(model, to_convergence=False)\n",
    "            if i == index:\n",
    "                print('final pruning and eval')\n",
    "                model.prune_random_global_unstruct(pruning_ratio)\n",
    "                #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                #              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                #              metrics=['accuracy'],\n",
    "                #             )\n",
    "                #finetuning\n",
    "                model = train_model(model, to_convergence=True)\n",
    "                accuracies.append(model.evaluate(x_test, y_test, verbose=0))\n",
    "                pgd_success_rate.append(pgd_attack(model))\n",
    "                #cw2_success_rate.append(cw2_attack(model))\n",
    "    all_accuracies.append(accuracies)\n",
    "    pgd_success_rates.append(pgd_success_rate)\n",
    "    cw2_success_rates.append(cw2_success_rate)\n",
    "\n",
    "    \n",
    "pd.DataFrame(all_accuracies).to_csv(f'saved-results/{EXPERIMENT_NAME}-accuracies.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-accuracies.json', 'w') as f:\n",
    "    json.dump(all_accuracies, f)\n",
    "    \n",
    "pd.DataFrame(pgd_success_rates).to_csv(f'saved-results/{EXPERIMENT_NAME}-pgd-success.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-pgd-success.json', 'w') as f:\n",
    "    json.dump(pgd_success_rates, f)\n",
    "    \n",
    "pd.DataFrame(cw2_success_rates).to_csv(f'saved-results/{EXPERIMENT_NAME}-cw2-success.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-cw2-success.json', 'w') as f:\n",
    "    json.dump(cw2_success_rates, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=5,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=2,\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def prune_weights(model, pruning_ratio):\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        if (index == 0) or (index == 2) or (index == 4):\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index].flatten()\n",
    "            mask = weights_to_prune[index+1].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            #mask_df = pd.DataFrame(mask)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            #print(no_of_weights_to_prune)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                mask[idx_to_delete] = 0\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+1].shape\n",
    "            mask_reshaped = mask.reshape(dims)\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            weights_to_prune[index+1] = mask_reshaped\n",
    "            weights_to_prune[index] = weights_reshaped\n",
    "    \n",
    "    return weights_to_prune\n",
    "\n",
    "\n",
    "\n",
    "def pgd_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.LinfProjectedGradientDescentAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[15/255]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/len(y)\n",
    "\n",
    "def cw2_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[.5]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/len(y)\n",
    "\n",
    "def initialize_base_model(index, save_weights=False):\n",
    "    model = LeNet300_100()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "                 )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=x_train,\n",
    "              y=y_train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n",
    "    if save_weights == True:\n",
    "        model.save_weights(f'./saved-weights/{EXPERIMENT_NAME}-{index}')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x = tf.convert_to_tensor(x_train[:500].reshape(500,28*28))\n",
    "y = tf.convert_to_tensor([y_train[:500]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, activation='relu'):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #print(input_shape)\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                name='unpruned_weights')\n",
    "        self.mask = self.add_weight(shape=(self.w.shape),\n",
    "                                    initializer='ones',\n",
    "                                    trainable=False,\n",
    "                                   name='pruning_mask')\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #self.mask_2 = tf.multiply(self.mask, self.mask_2)\n",
    "        x = tf.multiply(self.w, self.mask)\n",
    "        #print(self.pruned_w.eval())\n",
    "        x = tf.matmul(inputs, x)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return tf.keras.activations.relu(x)\n",
    "        if self.activation == 'softmax':\n",
    "            return tf.keras.activations.softmax(x)\n",
    "        raise ValueError('Activation function not implemented')\n",
    "\n",
    "class LeNet300_100(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet300_100, self).__init__()\n",
    "        self.dense1 = CustomLayer(300)\n",
    "        self.dense2 = CustomLayer(100)\n",
    "        self.dense3 = CustomLayer(10, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "    \n",
    "    def prune_random_global_unstruct(self, ratio):\n",
    "        weights = self.get_weights()\n",
    "        layers_to_prune = [0, 2, 4]\n",
    "        flat_weights = np.array([])\n",
    "        flat_mask = np.array([])\n",
    "        for x in layers_to_prune:\n",
    "            flat_weights = np.concatenate([flat_weights, weights[x].flatten()])\n",
    "            flat_mask = np.concatenate([flat_mask, weights[x+1].flatten()])\n",
    "        no_of_weights_to_prune = ratio * len(flat_weights)\n",
    "        # find unpruned weights\n",
    "        non_zero_weights = np.nonzero(flat_mask)[0]\n",
    "        # calculate the amount of weights to be pruned this round\n",
    "        no_of_weights_to_prune_left = int(no_of_weights_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "        # shuffle all non-zero weights\n",
    "        random.shuffle(non_zero_weights)\n",
    "        # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "        indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "        for idx_to_delete in indices_to_delete:\n",
    "            flat_mask[idx_to_delete] = 0\n",
    "            flat_weights[idx_to_delete] = 0\n",
    "            \n",
    "        #reshape\n",
    "        z = 0\n",
    "        for x in layers_to_prune:\n",
    "            weights[x] = flat_weights[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            weights[x + 1] = flat_mask[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            z = z + np.prod(weights[x].shape)\n",
    "        self.set_weights(weights)\n",
    "        return True\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    def prune_random_local_unstruct(self, ratio):\n",
    "        layers = self.get_weights()\n",
    "        layers_to_prune = [0, 2, 4]\n",
    "        for index, weights in enumerate(layers):\n",
    "            if index in layers_to_prune:\n",
    "                shape = weights.shape\n",
    "                flat_weights = weights.flatten()\n",
    "                flat_mask = layers[index+1].flatten()\n",
    "                no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                # find unpruned weights\n",
    "                non_zero_weights = np.nonzero(flat_mask)[0]\n",
    "                # calculate the amount of weights to be pruned this round\n",
    "                no_of_weights_to_prune_left = int(no_of_weights_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "                # shuffle all non-zero weights\n",
    "                random.shuffle(non_zero_weights)\n",
    "                # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "                indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    flat_mask[idx_to_delete] = 0\n",
    "                    flat_weights[idx_to_delete] = 0\n",
    "                \n",
    "                mask_reshaped = flat_mask.reshape(shape)\n",
    "                weights_reshaped = flat_weights.reshape(shape)\n",
    "                layers[index+1] = mask_reshaped\n",
    "                layers[index] = weights_reshaped\n",
    "        self.set_weights(layers)\n",
    "        return True\n",
    "        \n",
    "    \n",
    "    def prune_magnitude_global_unstruct(self,ratio):\n",
    "                \n",
    "        shape1 = self.dense1.w.shape\n",
    "        shape2 = self.dense2.w.shape\n",
    "        shape3 = self.dense3.w.shape\n",
    "\n",
    "        flat_weights = np.append(self.dense1.w.numpy().flatten() ,self.dense2.w.numpy().flatten())\n",
    "        flat_weights = np.append(flat_weights ,self.dense3.w.numpy().flatten())\n",
    "        flat_mask = np.append(self.dense1.mask.numpy().flatten(), self.dense2.mask.numpy().flatten())\n",
    "        flat_mask = np.append(flat_mask, self.dense3.mask.numpy().flatten())\n",
    "        \n",
    "        no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "        indices_to_delete = np.abs(flat_weights).argsort()[:no_of_weights_to_prune]\n",
    "        \n",
    "        for idx_to_delete in indices_to_delete:\n",
    "            flat_mask[idx_to_delete] = 0\n",
    "            flat_weights[idx_to_delete] = 0\n",
    "            \n",
    "        w1 = flat_weights[:shape1[0]*shape1[1]].reshape(shape1)\n",
    "        w2 = flat_weights[shape1[0]*shape1[1]:shape1[0]*shape1[1]+shape2[0]*shape2[1]].reshape(shape2)\n",
    "        w3 = flat_weights[-shape3[0]*shape3[1]:].reshape(shape3)\n",
    "        m1 = flat_mask[:shape1[0]*shape1[1]].reshape(shape1)\n",
    "        m2 = flat_mask[shape1[0]*shape1[1]:shape1[0]*shape1[1]+shape2[0]*shape2[1]].reshape(shape2)\n",
    "        m3 = flat_mask[-shape3[0]*shape3[1]:].reshape(shape3)\n",
    "        self.set_weights([w1,m1,w2,m2,w3,m3])\n",
    "        #print(weights)\n",
    "        return True\n",
    "    \n",
    "    def prune_magnitude_local_unstruct(self, ratio):\n",
    "        layers = self.get_weights()\n",
    "        layers_to_prune = [0, 2, 4]\n",
    "        for index, weights in enumerate(layers):\n",
    "            if index in layers_to_prune:\n",
    "                shape = weights.shape\n",
    "                flat_weights = weights.flatten()\n",
    "                mask = layers[index+1].flatten()\n",
    "                \n",
    "                no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                indices_to_delete = np.abs(flat_weights).argsort()[:no_of_weights_to_prune]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    mask[idx_to_delete] = 0\n",
    "                    flat_weights[idx_to_delete] = 0\n",
    "                \n",
    "                mask_reshaped = mask.reshape(shape)\n",
    "                weights_reshaped = flat_weights.reshape(shape)\n",
    "                layers[index+1] = mask_reshaped\n",
    "                layers[index] = weights_reshaped\n",
    "        self.set_weights(layers)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet300_100()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "             )\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(x_test, y_test),\n",
    "         )\n",
    "\n",
    "model.save('./saved-models/mini-pipeline-mlp-baseline-model')\n",
    "model.save_weights('./saved-models/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(list(range(100)));zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_of_weighs_to_prune = rate * len(weights)\n",
    "\n",
    "non_zero_weights = np.nonzero(zz)[0]\n",
    "no_of_weights_to_prune_left = int(no_of_weighs_to_prune - (len(weights) - len(non_zero_weights)) )\n",
    "\n",
    "random.shuffle(non_zero_weights)\n",
    "indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
