{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative pruning pipeline\n",
    "Model: Multi Layer Perceptron\n",
    "\n",
    "*Pruning functions as class methods*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'mlp-global-magnitude-unstruct'\n",
    "ITERATIONS = 3 #should be 10 for final experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import foolbox as fb\n",
    "import random\n",
    "\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune, Train Attack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 6s 6ms/step - loss: 1.6108 - accuracy: 0.8625 - val_loss: 1.5174 - val_accuracy: 0.9477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5105 - accuracy: 0.9532 - val_loss: 1.5050 - val_accuracy: 0.9585\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4975 - accuracy: 0.9655 - val_loss: 1.5037 - val_accuracy: 0.9588\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4903 - accuracy: 0.9722 - val_loss: 1.4926 - val_accuracy: 0.9690\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4865 - accuracy: 0.9757 - val_loss: 1.4911 - val_accuracy: 0.9709\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4825 - accuracy: 0.9794 - val_loss: 1.4894 - val_accuracy: 0.9715\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4804 - accuracy: 0.9817 - val_loss: 1.4898 - val_accuracy: 0.9721\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4791 - accuracy: 0.9827 - val_loss: 1.4857 - val_accuracy: 0.9756\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4777 - accuracy: 0.9839 - val_loss: 1.4844 - val_accuracy: 0.9767\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4773 - accuracy: 0.9841 - val_loss: 1.4833 - val_accuracy: 0.9783\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 1.4755 - accuracy: 0.9860 - val_loss: 1.4844 - val_accuracy: 0.9769\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 1.4746 - accuracy: 0.9868 - val_loss: 1.4845 - val_accuracy: 0.9769\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.4746 - accuracy: 0.9869 - val_loss: 1.4885 - val_accuracy: 0.9725\n",
      "WARNING:tensorflow:From /Users/florianmerkle/dev/foolbox/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [01:14, 74.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5353 - accuracy: 0.9434 - val_loss: 1.5108 - val_accuracy: 0.9546\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5037 - accuracy: 0.9614 - val_loss: 1.4995 - val_accuracy: 0.9653\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.4952 - accuracy: 0.9684 - val_loss: 1.4938 - val_accuracy: 0.9692\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4894 - accuracy: 0.9741 - val_loss: 1.4938 - val_accuracy: 0.9705\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4853 - accuracy: 0.9776 - val_loss: 1.4899 - val_accuracy: 0.9727\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4827 - accuracy: 0.9798 - val_loss: 1.4885 - val_accuracy: 0.9742\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.4804 - accuracy: 0.9825 - val_loss: 1.4897 - val_accuracy: 0.9716\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4783 - accuracy: 0.9838 - val_loss: 1.4856 - val_accuracy: 0.9763\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4766 - accuracy: 0.9855 - val_loss: 1.4866 - val_accuracy: 0.9754\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.4753 - accuracy: 0.9868 - val_loss: 1.4855 - val_accuracy: 0.9771\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4744 - accuracy: 0.9875 - val_loss: 1.4853 - val_accuracy: 0.9763\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4735 - accuracy: 0.9885 - val_loss: 1.4859 - val_accuracy: 0.9759\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4716 - accuracy: 0.9901 - val_loss: 1.4840 - val_accuracy: 0.9775\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4716 - accuracy: 0.9902 - val_loss: 1.4834 - val_accuracy: 0.9781\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4710 - accuracy: 0.9907 - val_loss: 1.4855 - val_accuracy: 0.9755\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4706 - accuracy: 0.9909 - val_loss: 1.4838 - val_accuracy: 0.9771\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4699 - accuracy: 0.9917 - val_loss: 1.4840 - val_accuracy: 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [02:57, 83.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 1.6062 - accuracy: 0.8928 - val_loss: 1.5301 - val_accuracy: 0.9382\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5226 - accuracy: 0.9447 - val_loss: 1.5153 - val_accuracy: 0.9502\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5102 - accuracy: 0.9550 - val_loss: 1.5122 - val_accuracy: 0.9522\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5022 - accuracy: 0.9622 - val_loss: 1.5032 - val_accuracy: 0.9600\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.4963 - accuracy: 0.9680 - val_loss: 1.5004 - val_accuracy: 0.9633\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4915 - accuracy: 0.9725 - val_loss: 1.4963 - val_accuracy: 0.9671\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4883 - accuracy: 0.9753 - val_loss: 1.4939 - val_accuracy: 0.9688\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4853 - accuracy: 0.9781 - val_loss: 1.4925 - val_accuracy: 0.9698\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4831 - accuracy: 0.9803 - val_loss: 1.4933 - val_accuracy: 0.9694\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4811 - accuracy: 0.9818 - val_loss: 1.4910 - val_accuracy: 0.9710\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4794 - accuracy: 0.9834 - val_loss: 1.4898 - val_accuracy: 0.9718\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4782 - accuracy: 0.9845 - val_loss: 1.4899 - val_accuracy: 0.9727\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4775 - accuracy: 0.9850 - val_loss: 1.4885 - val_accuracy: 0.9735\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4758 - accuracy: 0.9865 - val_loss: 1.4886 - val_accuracy: 0.9731\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4750 - accuracy: 0.9871 - val_loss: 1.4875 - val_accuracy: 0.9743\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4741 - accuracy: 0.9881 - val_loss: 1.4866 - val_accuracy: 0.9752\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4731 - accuracy: 0.9890 - val_loss: 1.4884 - val_accuracy: 0.9731\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4725 - accuracy: 0.9895 - val_loss: 1.4854 - val_accuracy: 0.9754\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4723 - accuracy: 0.9898 - val_loss: 1.4848 - val_accuracy: 0.9772\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4718 - accuracy: 0.9902 - val_loss: 1.4836 - val_accuracy: 0.9781\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4711 - accuracy: 0.9906 - val_loss: 1.4837 - val_accuracy: 0.9782\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4706 - accuracy: 0.9911 - val_loss: 1.4857 - val_accuracy: 0.9763\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4703 - accuracy: 0.9914 - val_loss: 1.4839 - val_accuracy: 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [04:58, 94.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.7204 - accuracy: 0.7872 - val_loss: 1.5514 - val_accuracy: 0.9222\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5448 - accuracy: 0.9254 - val_loss: 1.5354 - val_accuracy: 0.9327\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.5290 - accuracy: 0.9383 - val_loss: 1.5246 - val_accuracy: 0.9412\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5188 - accuracy: 0.9472 - val_loss: 1.5202 - val_accuracy: 0.9442\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5117 - accuracy: 0.9536 - val_loss: 1.5142 - val_accuracy: 0.9499\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5070 - accuracy: 0.9580 - val_loss: 1.5105 - val_accuracy: 0.9527\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5028 - accuracy: 0.9620 - val_loss: 1.5072 - val_accuracy: 0.9566\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4992 - accuracy: 0.9654 - val_loss: 1.5057 - val_accuracy: 0.9578\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4966 - accuracy: 0.9676 - val_loss: 1.5030 - val_accuracy: 0.9605\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4942 - accuracy: 0.9699 - val_loss: 1.5017 - val_accuracy: 0.9620\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4919 - accuracy: 0.9717 - val_loss: 1.5011 - val_accuracy: 0.9631\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4899 - accuracy: 0.9740 - val_loss: 1.4976 - val_accuracy: 0.9653\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4882 - accuracy: 0.9753 - val_loss: 1.4971 - val_accuracy: 0.9653\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4865 - accuracy: 0.9771 - val_loss: 1.4973 - val_accuracy: 0.9655\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4853 - accuracy: 0.9779 - val_loss: 1.4953 - val_accuracy: 0.9668\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4838 - accuracy: 0.9794 - val_loss: 1.4953 - val_accuracy: 0.9675\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4826 - accuracy: 0.9803 - val_loss: 1.4936 - val_accuracy: 0.9687\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4815 - accuracy: 0.9814 - val_loss: 1.4937 - val_accuracy: 0.9689\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4805 - accuracy: 0.9824 - val_loss: 1.4923 - val_accuracy: 0.9703\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4795 - accuracy: 0.9832 - val_loss: 1.4931 - val_accuracy: 0.9697\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4786 - accuracy: 0.9840 - val_loss: 1.4916 - val_accuracy: 0.9709\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4781 - accuracy: 0.9844 - val_loss: 1.4921 - val_accuracy: 0.9700\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4772 - accuracy: 0.9854 - val_loss: 1.4914 - val_accuracy: 0.9703\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4766 - accuracy: 0.9858 - val_loss: 1.4927 - val_accuracy: 0.9688\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4762 - accuracy: 0.9861 - val_loss: 1.4919 - val_accuracy: 0.9708\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4759 - accuracy: 0.9864 - val_loss: 1.4914 - val_accuracy: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [07:13, 106.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.9638 - accuracy: 0.5416 - val_loss: 1.5879 - val_accuracy: 0.8990\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5717 - accuracy: 0.9054 - val_loss: 1.5539 - val_accuracy: 0.9168\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5507 - accuracy: 0.9193 - val_loss: 1.5439 - val_accuracy: 0.9235\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5409 - accuracy: 0.9279 - val_loss: 1.5366 - val_accuracy: 0.9292\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5340 - accuracy: 0.9329 - val_loss: 1.5323 - val_accuracy: 0.9328\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5289 - accuracy: 0.9374 - val_loss: 1.5284 - val_accuracy: 0.9364\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5247 - accuracy: 0.9415 - val_loss: 1.5260 - val_accuracy: 0.9393\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.5213 - accuracy: 0.9439 - val_loss: 1.5228 - val_accuracy: 0.9413\n",
      "final pruning and eval\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5179 - accuracy: 0.9477 - val_loss: 1.5199 - val_accuracy: 0.9438\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5149 - accuracy: 0.9504 - val_loss: 1.5198 - val_accuracy: 0.9444\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5124 - accuracy: 0.9522 - val_loss: 1.5179 - val_accuracy: 0.9457\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5099 - accuracy: 0.9552 - val_loss: 1.5153 - val_accuracy: 0.9470\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5078 - accuracy: 0.9571 - val_loss: 1.5144 - val_accuracy: 0.9497\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5060 - accuracy: 0.9588 - val_loss: 1.5135 - val_accuracy: 0.9493\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5042 - accuracy: 0.9603 - val_loss: 1.5119 - val_accuracy: 0.9508\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5026 - accuracy: 0.9624 - val_loss: 1.5114 - val_accuracy: 0.9521\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.5011 - accuracy: 0.9634 - val_loss: 1.5097 - val_accuracy: 0.9528\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4996 - accuracy: 0.9648 - val_loss: 1.5091 - val_accuracy: 0.9534\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4984 - accuracy: 0.9657 - val_loss: 1.5087 - val_accuracy: 0.9528\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.4974 - accuracy: 0.9666 - val_loss: 1.5078 - val_accuracy: 0.9545\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4963 - accuracy: 0.9677 - val_loss: 1.5079 - val_accuracy: 0.9548\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4952 - accuracy: 0.9686 - val_loss: 1.5069 - val_accuracy: 0.9554\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4944 - accuracy: 0.9695 - val_loss: 1.5059 - val_accuracy: 0.9567\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4933 - accuracy: 0.9704 - val_loss: 1.5057 - val_accuracy: 0.9561\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.4924 - accuracy: 0.9713 - val_loss: 1.5057 - val_accuracy: 0.9569\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4916 - accuracy: 0.9722 - val_loss: 1.5054 - val_accuracy: 0.9571\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.4911 - accuracy: 0.9725 - val_loss: 1.5036 - val_accuracy: 0.9606\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4902 - accuracy: 0.9731 - val_loss: 1.5038 - val_accuracy: 0.9592\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4895 - accuracy: 0.9738 - val_loss: 1.5040 - val_accuracy: 0.9585\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4889 - accuracy: 0.9742 - val_loss: 1.5034 - val_accuracy: 0.9585\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4882 - accuracy: 0.9749 - val_loss: 1.5031 - val_accuracy: 0.9587\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4875 - accuracy: 0.9757 - val_loss: 1.5028 - val_accuracy: 0.9591\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4869 - accuracy: 0.9762 - val_loss: 1.5023 - val_accuracy: 0.9603\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4863 - accuracy: 0.9766 - val_loss: 1.5039 - val_accuracy: 0.9586\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4860 - accuracy: 0.9772 - val_loss: 1.5023 - val_accuracy: 0.9600\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4853 - accuracy: 0.9776 - val_loss: 1.5028 - val_accuracy: 0.9597\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4851 - accuracy: 0.9777 - val_loss: 1.5022 - val_accuracy: 0.9601\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4845 - accuracy: 0.9783 - val_loss: 1.5023 - val_accuracy: 0.9599\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4842 - accuracy: 0.9784 - val_loss: 1.5022 - val_accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4838 - accuracy: 0.9787 - val_loss: 1.5022 - val_accuracy: 0.9596\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4837 - accuracy: 0.9789 - val_loss: 1.5012 - val_accuracy: 0.9604\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4833 - accuracy: 0.9792 - val_loss: 1.5005 - val_accuracy: 0.9625\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4829 - accuracy: 0.9794 - val_loss: 1.5013 - val_accuracy: 0.9605\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4827 - accuracy: 0.9797 - val_loss: 1.5009 - val_accuracy: 0.9605\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.4824 - accuracy: 0.9799 - val_loss: 1.5006 - val_accuracy: 0.9608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [11:18, 148.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 2.2565 - accuracy: 0.1646 - val_loss: 2.2032 - val_accuracy: 0.2654\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 2.0491 - accuracy: 0.3997 - val_loss: 1.9404 - val_accuracy: 0.4866\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.8887 - accuracy: 0.5200 - val_loss: 1.8623 - val_accuracy: 0.5353\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.8490 - accuracy: 0.5490 - val_loss: 1.8178 - val_accuracy: 0.5775\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.8095 - accuracy: 0.5864 - val_loss: 1.7976 - val_accuracy: 0.5973\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.7953 - accuracy: 0.5989 - val_loss: 1.7869 - val_accuracy: 0.6057\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 1.7864 - accuracy: 0.6073 - val_loss: 1.7802 - val_accuracy: 0.6100\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.7801 - accuracy: 0.6115 - val_loss: 1.7750 - val_accuracy: 0.6147\n",
      "Epoch 1/2\n",
      "308/938 [========>.....................] - ETA: 2s - loss: 1.7765 - accuracy: 0.6135"
     ]
    }
   ],
   "source": [
    "\n",
    "pgd_success_rates = []\n",
    "cw2_success_rates = []\n",
    "\n",
    "all_accuracies = []\n",
    "for j in tqdm(range(ITERATIONS)):\n",
    "    model = initialize_base_model(j, save_weights=True)\n",
    "\n",
    "    accuracies = []\n",
    "    pgd_success_rate = []\n",
    "    cw2_success_rate = []\n",
    "    compression_rates = [1, 2, 4, 8, 16, 32, 64]\n",
    "    pruning_ratios = [1-1/x for x in compression_rates]\n",
    "    for index, pruning_ratio in tqdm(enumerate(pruning_ratios)):\n",
    "        model.load_weights(f'./saved-weights/{EXPERIMENT_NAME}-{j}')\n",
    "\n",
    "        #iteratively prune and train (only to convergence if the final stage of pruning is reached)\n",
    "        for i in range(index + 1):\n",
    "            if i != index:\n",
    "                #glocbal pruning\n",
    "                model.prune_random_global_unstruct(pruning_ratio)\n",
    "                #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                #              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                #              metrics=['accuracy'],\n",
    "                #             )\n",
    "                             \n",
    "                #finetuning\n",
    "                model = train_model(model, to_convergence=False)\n",
    "            if i == index:\n",
    "                print('final pruning and eval')\n",
    "                model.prune_random_global_unstruct(pruning_ratio)\n",
    "                #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                #              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                #              metrics=['accuracy'],\n",
    "                #             )\n",
    "                #finetuning\n",
    "                model = train_model(model, to_convergence=True)\n",
    "                accuracies.append(model.evaluate(x_test, y_test, verbose=0))\n",
    "                pgd_success_rate.append(pgd_attack(model))\n",
    "                #cw2_success_rate.append(cw2_attack(model))\n",
    "    all_accuracies.append(accuracies)\n",
    "    pgd_success_rates.append(pgd_success_rate)\n",
    "    cw2_success_rates.append(cw2_success_rate)\n",
    "\n",
    "    \n",
    "pd.DataFrame(all_accuracies).to_csv(f'saved-results/{EXPERIMENT_NAME}-accuracies.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-accuracies.json', 'w') as f:\n",
    "    json.dump(all_accuracies, f)\n",
    "    \n",
    "pd.DataFrame(pgd_success_rates).to_csv(f'saved-results/{EXPERIMENT_NAME}-pgd-success.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-pgd-success.json', 'w') as f:\n",
    "    json.dump(pgd_success_rates, f)\n",
    "    \n",
    "pd.DataFrame(cw2_success_rates).to_csv(f'saved-results/{EXPERIMENT_NAME}-cw2-success.csv',index=False)\n",
    "with open(f'saved-results/{EXPERIMENT_NAME}-cw2-success.json', 'w') as f:\n",
    "    json.dump(cw2_success_rates, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=100,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=2,\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def prune_weights(model, pruning_ratio):\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        if (index == 0) or (index == 2) or (index == 4):\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index].flatten()\n",
    "            mask = weights_to_prune[index+1].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            #mask_df = pd.DataFrame(mask)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            #print(no_of_weights_to_prune)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                mask[idx_to_delete] = 0\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+1].shape\n",
    "            mask_reshaped = mask.reshape(dims)\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            weights_to_prune[index+1] = mask_reshaped\n",
    "            weights_to_prune[index] = weights_reshaped\n",
    "    \n",
    "    return weights_to_prune\n",
    "\n",
    "\n",
    "\n",
    "def pgd_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.LinfProjectedGradientDescentAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[15/255]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/len(y)\n",
    "\n",
    "def cw2_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[.5]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/len(y)\n",
    "\n",
    "def initialize_base_model(index, save_weights=False):\n",
    "    model = LeNet300_100()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "                 )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=x_train,\n",
    "              y=y_train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n",
    "    if save_weights == True:\n",
    "        model.save_weights(f'./saved-weights/{EXPERIMENT_NAME}-{index}')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x = tf.convert_to_tensor(x_train[:500].reshape(500,28*28))\n",
    "y = tf.convert_to_tensor([y_train[:500]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, activation='relu'):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #print(input_shape)\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                name='unpruned_weights')\n",
    "        self.mask = self.add_weight(shape=(self.w.shape),\n",
    "                                    initializer='ones',\n",
    "                                    trainable=False,\n",
    "                                   name='pruning_mask')\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #self.mask_2 = tf.multiply(self.mask, self.mask_2)\n",
    "        x = tf.multiply(self.w, self.mask)\n",
    "        #print(self.pruned_w.eval())\n",
    "        x = tf.matmul(inputs, x)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return tf.keras.activations.relu(x)\n",
    "        if self.activation == 'softmax':\n",
    "            return tf.keras.activations.softmax(x)\n",
    "        raise ValueError('Activation function not implemented')\n",
    "\n",
    "class LeNet300_100(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet300_100, self).__init__()\n",
    "        self.dense1 = CustomLayer(300)\n",
    "        self.dense2 = CustomLayer(100)\n",
    "        self.dense3 = CustomLayer(10, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "    \n",
    "    def prune_random_global_unstruct(self, ratio):\n",
    "        weights = self.get_weights()\n",
    "        layers_to_prune = [0, 2, 4]\n",
    "        flat_weights = np.array([])\n",
    "        flat_mask = np.array([])\n",
    "        for x in layers_to_prune:\n",
    "            flat_weights = np.concatenate([flat_weights, weights[x].flatten()])\n",
    "            flat_mask = np.concatenate([flat_mask, weights[x+1].flatten()])\n",
    "        no_of_weights_to_prune = ratio * len(flat_weights)\n",
    "        # find unpruned weights\n",
    "        non_zero_weights = np.nonzero(flat_mask)[0]\n",
    "        # calculate the amount of weights to be pruned this round\n",
    "        no_of_weights_to_prune_left = int(no_of_weights_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "        # shuffle all non-zero weights\n",
    "        random.shuffle(non_zero_weights)\n",
    "        # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "        indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "        for idx_to_delete in indices_to_delete:\n",
    "            flat_mask[idx_to_delete] = 0\n",
    "            flat_weights[idx_to_delete] = 0\n",
    "            \n",
    "        #reshape\n",
    "        z = 0\n",
    "        for x in layers_to_prune:\n",
    "            weights[x] = flat_weights[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            weights[x + 1] = flat_mask[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            z = z + np.prod(weights[x].shape)\n",
    "        self.set_weights(weights)\n",
    "        return True\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    def prune_random_local_unstruct(self, ratio):\n",
    "        layers = self.get_weights()\n",
    "        layers_to_prune = [0, 2, 4]\n",
    "        for index, weights in enumerate(layers):\n",
    "            if index in layers_to_prune:\n",
    "                shape = weights.shape\n",
    "                flat_weights = weights.flatten()\n",
    "                flat_mask = layers[index+1].flatten()\n",
    "                no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                # find unpruned weights\n",
    "                non_zero_weights = np.nonzero(flat_mask)[0]\n",
    "                # calculate the amount of weights to be pruned this round\n",
    "                no_of_weights_to_prune_left = int(no_of_weights_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "                # shuffle all non-zero weights\n",
    "                random.shuffle(non_zero_weights)\n",
    "                # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "                indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    flat_mask[idx_to_delete] = 0\n",
    "                    flat_weights[idx_to_delete] = 0\n",
    "                \n",
    "                mask_reshaped = flat_mask.reshape(shape)\n",
    "                weights_reshaped = flat_weights.reshape(shape)\n",
    "                layers[index+1] = mask_reshaped\n",
    "                layers[index] = weights_reshaped\n",
    "        self.set_weights(layers)\n",
    "        return True\n",
    "        \n",
    "    \n",
    "    def prune_magnitude_global_unstruct(self,ratio):\n",
    "                \n",
    "        shape1 = self.dense1.w.shape\n",
    "        shape2 = self.dense2.w.shape\n",
    "        shape3 = self.dense3.w.shape\n",
    "\n",
    "        flat_weights = np.append(self.dense1.w.numpy().flatten() ,self.dense2.w.numpy().flatten())\n",
    "        flat_weights = np.append(flat_weights ,self.dense3.w.numpy().flatten())\n",
    "        flat_mask = np.append(self.dense1.mask.numpy().flatten(), self.dense2.mask.numpy().flatten())\n",
    "        flat_mask = np.append(flat_mask, self.dense3.mask.numpy().flatten())\n",
    "        \n",
    "        no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "        indices_to_delete = np.abs(flat_weights).argsort()[:no_of_weights_to_prune]\n",
    "        \n",
    "        for idx_to_delete in indices_to_delete:\n",
    "            flat_mask[idx_to_delete] = 0\n",
    "            flat_weights[idx_to_delete] = 0\n",
    "            \n",
    "        w1 = flat_weights[:shape1[0]*shape1[1]].reshape(shape1)\n",
    "        w2 = flat_weights[shape1[0]*shape1[1]:shape1[0]*shape1[1]+shape2[0]*shape2[1]].reshape(shape2)\n",
    "        w3 = flat_weights[-shape3[0]*shape3[1]:].reshape(shape3)\n",
    "        m1 = flat_mask[:shape1[0]*shape1[1]].reshape(shape1)\n",
    "        m2 = flat_mask[shape1[0]*shape1[1]:shape1[0]*shape1[1]+shape2[0]*shape2[1]].reshape(shape2)\n",
    "        m3 = flat_mask[-shape3[0]*shape3[1]:].reshape(shape3)\n",
    "        self.set_weights([w1,m1,w2,m2,w3,m3])\n",
    "        #print(weights)\n",
    "        return True\n",
    "    \n",
    "    def prune_magnitude_local_unstruct(self, ratio):\n",
    "        layers = self.get_weights()\n",
    "        layers_to_prune = [0, 2, 4]\n",
    "        for index, weights in enumerate(layers):\n",
    "            if index in layers_to_prune:\n",
    "                shape = weights.shape\n",
    "                flat_weights = weights.flatten()\n",
    "                mask = layers[index+1].flatten()\n",
    "                \n",
    "                no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                indices_to_delete = np.abs(flat_weights).argsort()[:no_of_weights_to_prune]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    mask[idx_to_delete] = 0\n",
    "                    flat_weights[idx_to_delete] = 0\n",
    "                \n",
    "                mask_reshaped = mask.reshape(shape)\n",
    "                weights_reshaped = flat_weights.reshape(shape)\n",
    "                layers[index+1] = mask_reshaped\n",
    "                layers[index] = weights_reshaped\n",
    "        self.set_weights(layers)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet300_100()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "             )\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(x_test, y_test),\n",
    "         )\n",
    "\n",
    "model.save('./saved-models/mini-pipeline-mlp-baseline-model')\n",
    "model.save_weights('./saved-models/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(list(range(100)));zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_of_weighs_to_prune = rate * len(weights)\n",
    "\n",
    "non_zero_weights = np.nonzero(zz)[0]\n",
    "no_of_weights_to_prune_left = int(no_of_weighs_to_prune - (len(weights) - len(non_zero_weights)) )\n",
    "\n",
    "random.shuffle(non_zero_weights)\n",
    "indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
