{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHITECTURE = 'cnn'\n",
    "#EXPERIMENT_NAME = 'cnn-global-magnitude-unstruct'\n",
    "ITERATIONS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import foolbox as fb\n",
    "import random\n",
    "import json\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5962 - accuracy: 0.8835 - val_loss: 1.5154 - val_accuracy: 0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.0\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5047 - accuracy: 0.9599 - val_loss: 1.4944 - val_accuracy: 0.9687\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4920 - accuracy: 0.9711 - val_loss: 1.4886 - val_accuracy: 0.9739\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4855 - accuracy: 0.9773 - val_loss: 1.4844 - val_accuracy: 0.9778\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4818 - accuracy: 0.9804 - val_loss: 1.4837 - val_accuracy: 0.9781\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4789 - accuracy: 0.9834 - val_loss: 1.4810 - val_accuracy: 0.9812\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4776 - accuracy: 0.9843 - val_loss: 1.4796 - val_accuracy: 0.9824\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4752 - accuracy: 0.9868 - val_loss: 1.4811 - val_accuracy: 0.9804\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4749 - accuracy: 0.9867 - val_loss: 1.4792 - val_accuracy: 0.9823\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4735 - accuracy: 0.9882 - val_loss: 1.4775 - val_accuracy: 0.9840\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4719 - accuracy: 0.9899 - val_loss: 1.4787 - val_accuracy: 0.9825\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4722 - accuracy: 0.9894 - val_loss: 1.4752 - val_accuracy: 0.9861\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4706 - accuracy: 0.9911 - val_loss: 1.4761 - val_accuracy: 0.9856\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4704 - accuracy: 0.9913 - val_loss: 1.4750 - val_accuracy: 0.9868\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4704 - accuracy: 0.9911 - val_loss: 1.4735 - val_accuracy: 0.9879\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4690 - accuracy: 0.9926 - val_loss: 1.4741 - val_accuracy: 0.9877\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.4688 - accuracy: 0.9927 - val_loss: 1.4737 - val_accuracy: 0.9876\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4690 - accuracy: 0.9926 - val_loss: 1.4742 - val_accuracy: 0.9874\n",
      "WARNING:tensorflow:From /Users/florianmerkle/dev/foolbox/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [04:56, 296.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.5\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5047 - accuracy: 0.9596 - val_loss: 1.4951 - val_accuracy: 0.9688\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4921 - accuracy: 0.9709 - val_loss: 1.4916 - val_accuracy: 0.9720\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4857 - accuracy: 0.9768 - val_loss: 1.4845 - val_accuracy: 0.9771\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4818 - accuracy: 0.9804 - val_loss: 1.4840 - val_accuracy: 0.9776\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4796 - accuracy: 0.9828 - val_loss: 1.4828 - val_accuracy: 0.9789\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4776 - accuracy: 0.9843 - val_loss: 1.4804 - val_accuracy: 0.9816\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4758 - accuracy: 0.9862 - val_loss: 1.4789 - val_accuracy: 0.9825\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4738 - accuracy: 0.9880 - val_loss: 1.4777 - val_accuracy: 0.9842\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4734 - accuracy: 0.9884 - val_loss: 1.4796 - val_accuracy: 0.9822\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4725 - accuracy: 0.9892 - val_loss: 1.4771 - val_accuracy: 0.9841\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4711 - accuracy: 0.9906 - val_loss: 1.4762 - val_accuracy: 0.9852\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4712 - accuracy: 0.9904 - val_loss: 1.4759 - val_accuracy: 0.9859\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4703 - accuracy: 0.9914 - val_loss: 1.4766 - val_accuracy: 0.9847\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4698 - accuracy: 0.9919 - val_loss: 1.4773 - val_accuracy: 0.9846\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4692 - accuracy: 0.9923 - val_loss: 1.4793 - val_accuracy: 0.9815\n",
      "current pruning ratio is0.5, goal ratio ist 0.5\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4838 - accuracy: 0.9841 - val_loss: 1.4792 - val_accuracy: 0.9852\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4740 - accuracy: 0.9902 - val_loss: 1.4765 - val_accuracy: 0.9868\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4714 - accuracy: 0.9919 - val_loss: 1.4758 - val_accuracy: 0.9866\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4703 - accuracy: 0.9924 - val_loss: 1.4753 - val_accuracy: 0.9872\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4691 - accuracy: 0.9934 - val_loss: 1.4758 - val_accuracy: 0.9871\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4684 - accuracy: 0.9940 - val_loss: 1.4745 - val_accuracy: 0.9876\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4680 - accuracy: 0.9943 - val_loss: 1.4731 - val_accuracy: 0.9885\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4669 - accuracy: 0.9952 - val_loss: 1.4733 - val_accuracy: 0.9891\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4672 - accuracy: 0.9947 - val_loss: 1.4736 - val_accuracy: 0.9886\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4666 - accuracy: 0.9952 - val_loss: 1.4731 - val_accuracy: 0.9890\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4664 - accuracy: 0.9955 - val_loss: 1.4732 - val_accuracy: 0.9881\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4660 - accuracy: 0.9957 - val_loss: 1.4725 - val_accuracy: 0.9893\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4659 - accuracy: 0.9958 - val_loss: 1.4742 - val_accuracy: 0.9876\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4656 - accuracy: 0.9961 - val_loss: 1.4739 - val_accuracy: 0.9874\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4654 - accuracy: 0.9962 - val_loss: 1.4734 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [13:30, 361.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.75\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5040 - accuracy: 0.9605 - val_loss: 1.5010 - val_accuracy: 0.9635\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4920 - accuracy: 0.9711 - val_loss: 1.4890 - val_accuracy: 0.9735\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.4856 - accuracy: 0.9770 - val_loss: 1.4848 - val_accuracy: 0.9778\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4814 - accuracy: 0.9808 - val_loss: 1.4829 - val_accuracy: 0.9794\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4793 - accuracy: 0.9828 - val_loss: 1.4796 - val_accuracy: 0.9823\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4767 - accuracy: 0.9853 - val_loss: 1.4804 - val_accuracy: 0.9815\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4752 - accuracy: 0.9866 - val_loss: 1.4791 - val_accuracy: 0.9828\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.4738 - accuracy: 0.9882 - val_loss: 1.4795 - val_accuracy: 0.9822\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4726 - accuracy: 0.9892 - val_loss: 1.4760 - val_accuracy: 0.9859\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4720 - accuracy: 0.9898 - val_loss: 1.4760 - val_accuracy: 0.9857\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4708 - accuracy: 0.9911 - val_loss: 1.4770 - val_accuracy: 0.9848\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9912 - val_loss: 1.4757 - val_accuracy: 0.9858\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9911 - val_loss: 1.4762 - val_accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4694 - accuracy: 0.9924 - val_loss: 1.4752 - val_accuracy: 0.9860\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4694 - accuracy: 0.9923 - val_loss: 1.4753 - val_accuracy: 0.9860\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4687 - accuracy: 0.9930 - val_loss: 1.4761 - val_accuracy: 0.9852\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4681 - accuracy: 0.9936 - val_loss: 1.4753 - val_accuracy: 0.9862\n",
      "current pruning ratio is0.5, goal ratio ist 0.75\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4864 - accuracy: 0.9821 - val_loss: 1.4796 - val_accuracy: 0.9841\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4743 - accuracy: 0.9900 - val_loss: 1.4765 - val_accuracy: 0.9871\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4712 - accuracy: 0.9920 - val_loss: 1.4749 - val_accuracy: 0.9883\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4699 - accuracy: 0.9928 - val_loss: 1.4746 - val_accuracy: 0.9879\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4688 - accuracy: 0.9936 - val_loss: 1.4739 - val_accuracy: 0.9884\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4682 - accuracy: 0.9942 - val_loss: 1.4747 - val_accuracy: 0.9873\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4675 - accuracy: 0.9947 - val_loss: 1.4755 - val_accuracy: 0.9867\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4669 - accuracy: 0.9952 - val_loss: 1.4746 - val_accuracy: 0.9876\n",
      "current pruning ratio is0.75, goal ratio ist 0.75\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5327 - accuracy: 0.9520 - val_loss: 1.4937 - val_accuracy: 0.9775\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4876 - accuracy: 0.9807 - val_loss: 1.4838 - val_accuracy: 0.9818\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4808 - accuracy: 0.9849 - val_loss: 1.4812 - val_accuracy: 0.9832\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4765 - accuracy: 0.9880 - val_loss: 1.4778 - val_accuracy: 0.9860\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4745 - accuracy: 0.9892 - val_loss: 1.4767 - val_accuracy: 0.9864\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4728 - accuracy: 0.9908 - val_loss: 1.4762 - val_accuracy: 0.9864\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4716 - accuracy: 0.9914 - val_loss: 1.4750 - val_accuracy: 0.9881\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4705 - accuracy: 0.9925 - val_loss: 1.4765 - val_accuracy: 0.9866\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4697 - accuracy: 0.9931 - val_loss: 1.4752 - val_accuracy: 0.9868\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4692 - accuracy: 0.9935 - val_loss: 1.4747 - val_accuracy: 0.9876\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4685 - accuracy: 0.9940 - val_loss: 1.4755 - val_accuracy: 0.9861\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4680 - accuracy: 0.9942 - val_loss: 1.4745 - val_accuracy: 0.9873\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4675 - accuracy: 0.9949 - val_loss: 1.4743 - val_accuracy: 0.9879\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4673 - accuracy: 0.9950 - val_loss: 1.4741 - val_accuracy: 0.9876\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4667 - accuracy: 0.9955 - val_loss: 1.4731 - val_accuracy: 0.9890\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4667 - accuracy: 0.9954 - val_loss: 1.4729 - val_accuracy: 0.9892\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4662 - accuracy: 0.9959 - val_loss: 1.4749 - val_accuracy: 0.9870\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4661 - accuracy: 0.9959 - val_loss: 1.4736 - val_accuracy: 0.9885\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4661 - accuracy: 0.9958 - val_loss: 1.4739 - val_accuracy: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [25:26, 467.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5045 - accuracy: 0.9601 - val_loss: 1.4971 - val_accuracy: 0.9659\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4919 - accuracy: 0.9711 - val_loss: 1.4879 - val_accuracy: 0.9755\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4853 - accuracy: 0.9774 - val_loss: 1.4840 - val_accuracy: 0.9788\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4815 - accuracy: 0.9809 - val_loss: 1.4831 - val_accuracy: 0.9791\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4782 - accuracy: 0.9843 - val_loss: 1.4798 - val_accuracy: 0.9821\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4774 - accuracy: 0.9845 - val_loss: 1.4792 - val_accuracy: 0.9825\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4752 - accuracy: 0.9866 - val_loss: 1.4798 - val_accuracy: 0.9816\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4736 - accuracy: 0.9882 - val_loss: 1.4775 - val_accuracy: 0.9843\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4738 - accuracy: 0.9882 - val_loss: 1.4757 - val_accuracy: 0.9860\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4716 - accuracy: 0.9902 - val_loss: 1.4783 - val_accuracy: 0.9830\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4708 - accuracy: 0.9909 - val_loss: 1.4758 - val_accuracy: 0.9860\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4715 - accuracy: 0.9900 - val_loss: 1.4761 - val_accuracy: 0.9857\n",
      "current pruning ratio is0.5, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4948 - accuracy: 0.9767 - val_loss: 1.4803 - val_accuracy: 0.9849\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4770 - accuracy: 0.9875 - val_loss: 1.4776 - val_accuracy: 0.9859\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4737 - accuracy: 0.9897 - val_loss: 1.4771 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9912 - val_loss: 1.4752 - val_accuracy: 0.9869\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4707 - accuracy: 0.9919 - val_loss: 1.4757 - val_accuracy: 0.9863\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4698 - accuracy: 0.9926 - val_loss: 1.4754 - val_accuracy: 0.9865\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4686 - accuracy: 0.9934 - val_loss: 1.4743 - val_accuracy: 0.9879\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4683 - accuracy: 0.9940 - val_loss: 1.4756 - val_accuracy: 0.9865\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4674 - accuracy: 0.9948 - val_loss: 1.4739 - val_accuracy: 0.9879\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4670 - accuracy: 0.9951 - val_loss: 1.4734 - val_accuracy: 0.9883\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4666 - accuracy: 0.9954 - val_loss: 1.4737 - val_accuracy: 0.9876\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4666 - accuracy: 0.9952 - val_loss: 1.4755 - val_accuracy: 0.9861\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4664 - accuracy: 0.9953 - val_loss: 1.4734 - val_accuracy: 0.9883\n",
      "current pruning ratio is0.75, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5167 - accuracy: 0.9632 - val_loss: 1.4884 - val_accuracy: 0.9806\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4850 - accuracy: 0.9822 - val_loss: 1.4833 - val_accuracy: 0.9831\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4794 - accuracy: 0.9861 - val_loss: 1.4799 - val_accuracy: 0.9845\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4767 - accuracy: 0.9876 - val_loss: 1.4787 - val_accuracy: 0.9846\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4745 - accuracy: 0.9894 - val_loss: 1.4779 - val_accuracy: 0.9857\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4729 - accuracy: 0.9905 - val_loss: 1.4790 - val_accuracy: 0.9850\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4714 - accuracy: 0.9920 - val_loss: 1.4772 - val_accuracy: 0.9856\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4707 - accuracy: 0.9922 - val_loss: 1.4777 - val_accuracy: 0.9852\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4699 - accuracy: 0.9931 - val_loss: 1.4763 - val_accuracy: 0.9855\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4690 - accuracy: 0.9937 - val_loss: 1.4764 - val_accuracy: 0.9860\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4684 - accuracy: 0.9942 - val_loss: 1.4759 - val_accuracy: 0.9862\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4679 - accuracy: 0.9945 - val_loss: 1.4750 - val_accuracy: 0.9864\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4675 - accuracy: 0.9950 - val_loss: 1.4748 - val_accuracy: 0.9872\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4670 - accuracy: 0.9953 - val_loss: 1.4758 - val_accuracy: 0.9861\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4668 - accuracy: 0.9953 - val_loss: 1.4749 - val_accuracy: 0.9870\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4665 - accuracy: 0.9957 - val_loss: 1.4750 - val_accuracy: 0.9864\n",
      "current pruning ratio is0.875, goal ratio ist 0.875\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5858 - accuracy: 0.8955 - val_loss: 1.5060 - val_accuracy: 0.9659\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5016 - accuracy: 0.9679 - val_loss: 1.4924 - val_accuracy: 0.9749\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4920 - accuracy: 0.9751 - val_loss: 1.4881 - val_accuracy: 0.9781\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4864 - accuracy: 0.9796 - val_loss: 1.4843 - val_accuracy: 0.9807\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4831 - accuracy: 0.9821 - val_loss: 1.4822 - val_accuracy: 0.9829\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4806 - accuracy: 0.9847 - val_loss: 1.4800 - val_accuracy: 0.9835\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4790 - accuracy: 0.9854 - val_loss: 1.4807 - val_accuracy: 0.9828\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4776 - accuracy: 0.9864 - val_loss: 1.4777 - val_accuracy: 0.9856\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4763 - accuracy: 0.9878 - val_loss: 1.4785 - val_accuracy: 0.9854\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4752 - accuracy: 0.9885 - val_loss: 1.4782 - val_accuracy: 0.9853\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4743 - accuracy: 0.9893 - val_loss: 1.4768 - val_accuracy: 0.9864\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4738 - accuracy: 0.9893 - val_loss: 1.4766 - val_accuracy: 0.9863\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4732 - accuracy: 0.9902 - val_loss: 1.4759 - val_accuracy: 0.9863\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4725 - accuracy: 0.9905 - val_loss: 1.4757 - val_accuracy: 0.9871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4719 - accuracy: 0.9911 - val_loss: 1.4763 - val_accuracy: 0.9859\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4714 - accuracy: 0.9916 - val_loss: 1.4760 - val_accuracy: 0.9873\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4709 - accuracy: 0.9919 - val_loss: 1.4764 - val_accuracy: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [41:15, 612.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5051 - accuracy: 0.9590 - val_loss: 1.5045 - val_accuracy: 0.9599\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4917 - accuracy: 0.9714 - val_loss: 1.4872 - val_accuracy: 0.9754\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4860 - accuracy: 0.9767 - val_loss: 1.4887 - val_accuracy: 0.9738\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4810 - accuracy: 0.9813 - val_loss: 1.4835 - val_accuracy: 0.9791\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4792 - accuracy: 0.9830 - val_loss: 1.4792 - val_accuracy: 0.9829\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4770 - accuracy: 0.9852 - val_loss: 1.4791 - val_accuracy: 0.9824\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4753 - accuracy: 0.9866 - val_loss: 1.4791 - val_accuracy: 0.9828\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4741 - accuracy: 0.9878 - val_loss: 1.4799 - val_accuracy: 0.9814\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4732 - accuracy: 0.9884 - val_loss: 1.4753 - val_accuracy: 0.9865\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4722 - accuracy: 0.9894 - val_loss: 1.4750 - val_accuracy: 0.9866\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4714 - accuracy: 0.9903 - val_loss: 1.4750 - val_accuracy: 0.9867\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4697 - accuracy: 0.9919 - val_loss: 1.4746 - val_accuracy: 0.9873\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4698 - accuracy: 0.9919 - val_loss: 1.4759 - val_accuracy: 0.9854\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4692 - accuracy: 0.9926 - val_loss: 1.4738 - val_accuracy: 0.9879\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4698 - accuracy: 0.9919 - val_loss: 1.4747 - val_accuracy: 0.9867\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4690 - accuracy: 0.9927 - val_loss: 1.4781 - val_accuracy: 0.9832\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4683 - accuracy: 0.9932 - val_loss: 1.4743 - val_accuracy: 0.9875\n",
      "current pruning ratio is0.5, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4847 - accuracy: 0.9838 - val_loss: 1.4798 - val_accuracy: 0.9848\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4737 - accuracy: 0.9904 - val_loss: 1.4773 - val_accuracy: 0.9853\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9922 - val_loss: 1.4743 - val_accuracy: 0.9886\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4694 - accuracy: 0.9935 - val_loss: 1.4748 - val_accuracy: 0.9870\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4688 - accuracy: 0.9936 - val_loss: 1.4749 - val_accuracy: 0.9870\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4682 - accuracy: 0.9941 - val_loss: 1.4741 - val_accuracy: 0.9873\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4673 - accuracy: 0.9948 - val_loss: 1.4738 - val_accuracy: 0.9881\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4671 - accuracy: 0.9950 - val_loss: 1.4750 - val_accuracy: 0.9868\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4667 - accuracy: 0.9954 - val_loss: 1.4732 - val_accuracy: 0.9887\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4662 - accuracy: 0.9957 - val_loss: 1.4728 - val_accuracy: 0.9894\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4659 - accuracy: 0.9959 - val_loss: 1.4727 - val_accuracy: 0.9892\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4657 - accuracy: 0.9960 - val_loss: 1.4730 - val_accuracy: 0.9886\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4656 - accuracy: 0.9962 - val_loss: 1.4732 - val_accuracy: 0.9886\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4657 - accuracy: 0.9961 - val_loss: 1.4738 - val_accuracy: 0.9875\n",
      "current pruning ratio is0.75, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5122 - accuracy: 0.9665 - val_loss: 1.4879 - val_accuracy: 0.9798\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4829 - accuracy: 0.9841 - val_loss: 1.4826 - val_accuracy: 0.9821\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4771 - accuracy: 0.9880 - val_loss: 1.4794 - val_accuracy: 0.9843\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4745 - accuracy: 0.9896 - val_loss: 1.4768 - val_accuracy: 0.9866\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4721 - accuracy: 0.9918 - val_loss: 1.4772 - val_accuracy: 0.9853\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4709 - accuracy: 0.9924 - val_loss: 1.4755 - val_accuracy: 0.9872\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4702 - accuracy: 0.9930 - val_loss: 1.4754 - val_accuracy: 0.9871\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4694 - accuracy: 0.9936 - val_loss: 1.4767 - val_accuracy: 0.9862\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4687 - accuracy: 0.9939 - val_loss: 1.4762 - val_accuracy: 0.9857\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4679 - accuracy: 0.9948 - val_loss: 1.4752 - val_accuracy: 0.9871\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4675 - accuracy: 0.9950 - val_loss: 1.4744 - val_accuracy: 0.9879\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4670 - accuracy: 0.9954 - val_loss: 1.4752 - val_accuracy: 0.9870\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4667 - accuracy: 0.9956 - val_loss: 1.4744 - val_accuracy: 0.9881\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4663 - accuracy: 0.9959 - val_loss: 1.4746 - val_accuracy: 0.9869\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4660 - accuracy: 0.9961 - val_loss: 1.4743 - val_accuracy: 0.9878\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4658 - accuracy: 0.9962 - val_loss: 1.4729 - val_accuracy: 0.9886\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4657 - accuracy: 0.9963 - val_loss: 1.4722 - val_accuracy: 0.9898\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4656 - accuracy: 0.9964 - val_loss: 1.4733 - val_accuracy: 0.9884\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4651 - accuracy: 0.9967 - val_loss: 1.4734 - val_accuracy: 0.9882\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4650 - accuracy: 0.9967 - val_loss: 1.4731 - val_accuracy: 0.9888\n",
      "current pruning ratio is0.875, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5662 - accuracy: 0.9179 - val_loss: 1.5091 - val_accuracy: 0.9634\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5032 - accuracy: 0.9680 - val_loss: 1.4954 - val_accuracy: 0.9733\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4929 - accuracy: 0.9747 - val_loss: 1.4891 - val_accuracy: 0.9773\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4875 - accuracy: 0.9793 - val_loss: 1.4874 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4838 - accuracy: 0.9819 - val_loss: 1.4854 - val_accuracy: 0.9794\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4816 - accuracy: 0.9836 - val_loss: 1.4855 - val_accuracy: 0.9783\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4794 - accuracy: 0.9853 - val_loss: 1.4821 - val_accuracy: 0.9819\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4781 - accuracy: 0.9863 - val_loss: 1.4803 - val_accuracy: 0.9832\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4769 - accuracy: 0.9874 - val_loss: 1.4797 - val_accuracy: 0.9835\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4758 - accuracy: 0.9882 - val_loss: 1.4793 - val_accuracy: 0.9831\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4746 - accuracy: 0.9894 - val_loss: 1.4794 - val_accuracy: 0.9839\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4742 - accuracy: 0.9894 - val_loss: 1.4781 - val_accuracy: 0.9852\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4732 - accuracy: 0.9902 - val_loss: 1.4781 - val_accuracy: 0.9847\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4725 - accuracy: 0.9908 - val_loss: 1.4777 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4720 - accuracy: 0.9915 - val_loss: 1.4775 - val_accuracy: 0.9853\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4715 - accuracy: 0.9916 - val_loss: 1.4771 - val_accuracy: 0.9856\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4709 - accuracy: 0.9923 - val_loss: 1.4771 - val_accuracy: 0.9859\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4707 - accuracy: 0.9924 - val_loss: 1.4778 - val_accuracy: 0.9850\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4703 - accuracy: 0.9927 - val_loss: 1.4794 - val_accuracy: 0.9835\n",
      "current pruning ratio is0.9375, goal ratio ist 0.9375\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6943 - accuracy: 0.7993 - val_loss: 1.5649 - val_accuracy: 0.9163\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5527 - accuracy: 0.9254 - val_loss: 1.5360 - val_accuracy: 0.9393\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5324 - accuracy: 0.9395 - val_loss: 1.5222 - val_accuracy: 0.9501\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5217 - accuracy: 0.9487 - val_loss: 1.5142 - val_accuracy: 0.9558\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5144 - accuracy: 0.9544 - val_loss: 1.5100 - val_accuracy: 0.9595\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5093 - accuracy: 0.9584 - val_loss: 1.5053 - val_accuracy: 0.9621\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5053 - accuracy: 0.9619 - val_loss: 1.5041 - val_accuracy: 0.9635\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5025 - accuracy: 0.9638 - val_loss: 1.5003 - val_accuracy: 0.9658\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5003 - accuracy: 0.9659 - val_loss: 1.4992 - val_accuracy: 0.9672\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4980 - accuracy: 0.9682 - val_loss: 1.4976 - val_accuracy: 0.9684\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4962 - accuracy: 0.9698 - val_loss: 1.4963 - val_accuracy: 0.9685\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4948 - accuracy: 0.9706 - val_loss: 1.4951 - val_accuracy: 0.9695\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4932 - accuracy: 0.9723 - val_loss: 1.4934 - val_accuracy: 0.9716\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4920 - accuracy: 0.9729 - val_loss: 1.4925 - val_accuracy: 0.9728\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4910 - accuracy: 0.9738 - val_loss: 1.4926 - val_accuracy: 0.9724\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4899 - accuracy: 0.9751 - val_loss: 1.4911 - val_accuracy: 0.9737\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4889 - accuracy: 0.9757 - val_loss: 1.4900 - val_accuracy: 0.9750\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4878 - accuracy: 0.9771 - val_loss: 1.4917 - val_accuracy: 0.9729\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4872 - accuracy: 0.9779 - val_loss: 1.4906 - val_accuracy: 0.9744\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4863 - accuracy: 0.9785 - val_loss: 1.4890 - val_accuracy: 0.9750\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4856 - accuracy: 0.9785 - val_loss: 1.4887 - val_accuracy: 0.9748\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4851 - accuracy: 0.9793 - val_loss: 1.4897 - val_accuracy: 0.9745\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4843 - accuracy: 0.9800 - val_loss: 1.4887 - val_accuracy: 0.9750\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4840 - accuracy: 0.9804 - val_loss: 1.4877 - val_accuracy: 0.9752\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4833 - accuracy: 0.9810 - val_loss: 1.4869 - val_accuracy: 0.9773\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4827 - accuracy: 0.9812 - val_loss: 1.4882 - val_accuracy: 0.9747\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4821 - accuracy: 0.9823 - val_loss: 1.4882 - val_accuracy: 0.9757\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4816 - accuracy: 0.9827 - val_loss: 1.4863 - val_accuracy: 0.9774\n",
      "Epoch 29/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4812 - accuracy: 0.9830 - val_loss: 1.4865 - val_accuracy: 0.9764\n",
      "Epoch 30/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4809 - accuracy: 0.9828 - val_loss: 1.4870 - val_accuracy: 0.9767\n",
      "Epoch 31/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4803 - accuracy: 0.9839 - val_loss: 1.4865 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [1:08:49, 924.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5045 - accuracy: 0.9598 - val_loss: 1.4944 - val_accuracy: 0.9695\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4923 - accuracy: 0.9709 - val_loss: 1.4884 - val_accuracy: 0.9740\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4861 - accuracy: 0.9764 - val_loss: 1.4827 - val_accuracy: 0.9790\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4816 - accuracy: 0.9806 - val_loss: 1.4837 - val_accuracy: 0.9785\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4785 - accuracy: 0.9837 - val_loss: 1.4785 - val_accuracy: 0.9834\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4769 - accuracy: 0.9850 - val_loss: 1.4778 - val_accuracy: 0.9839\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4753 - accuracy: 0.9866 - val_loss: 1.4773 - val_accuracy: 0.9849\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4742 - accuracy: 0.9877 - val_loss: 1.4756 - val_accuracy: 0.9866\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4730 - accuracy: 0.9888 - val_loss: 1.4756 - val_accuracy: 0.9862\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4723 - accuracy: 0.9895 - val_loss: 1.4793 - val_accuracy: 0.9824\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4720 - accuracy: 0.9898 - val_loss: 1.4777 - val_accuracy: 0.9836\n",
      "current pruning ratio is0.5, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4928 - accuracy: 0.9782 - val_loss: 1.4825 - val_accuracy: 0.9820\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4780 - accuracy: 0.9864 - val_loss: 1.4786 - val_accuracy: 0.9847\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4749 - accuracy: 0.9887 - val_loss: 1.4764 - val_accuracy: 0.9869\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4725 - accuracy: 0.9904 - val_loss: 1.4764 - val_accuracy: 0.9857\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4719 - accuracy: 0.9906 - val_loss: 1.4750 - val_accuracy: 0.9875\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4709 - accuracy: 0.9913 - val_loss: 1.4756 - val_accuracy: 0.9866\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4698 - accuracy: 0.9926 - val_loss: 1.4755 - val_accuracy: 0.9865\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4694 - accuracy: 0.9926 - val_loss: 1.4741 - val_accuracy: 0.9871\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4687 - accuracy: 0.9933 - val_loss: 1.4750 - val_accuracy: 0.9866\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4678 - accuracy: 0.9942 - val_loss: 1.4746 - val_accuracy: 0.9873\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4678 - accuracy: 0.9944 - val_loss: 1.4740 - val_accuracy: 0.9877\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4671 - accuracy: 0.9947 - val_loss: 1.4735 - val_accuracy: 0.9886\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4668 - accuracy: 0.9951 - val_loss: 1.4740 - val_accuracy: 0.9869\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4663 - accuracy: 0.9955 - val_loss: 1.4742 - val_accuracy: 0.9874\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4665 - accuracy: 0.9952 - val_loss: 1.4736 - val_accuracy: 0.9879\n",
      "current pruning ratio is0.75, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5128 - accuracy: 0.9672 - val_loss: 1.4900 - val_accuracy: 0.9784\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4833 - accuracy: 0.9837 - val_loss: 1.4814 - val_accuracy: 0.9840\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4780 - accuracy: 0.9869 - val_loss: 1.4802 - val_accuracy: 0.9834\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4753 - accuracy: 0.9886 - val_loss: 1.4777 - val_accuracy: 0.9859\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4738 - accuracy: 0.9898 - val_loss: 1.4762 - val_accuracy: 0.9864\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4721 - accuracy: 0.9914 - val_loss: 1.4763 - val_accuracy: 0.9864\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4712 - accuracy: 0.9919 - val_loss: 1.4769 - val_accuracy: 0.9855\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4699 - accuracy: 0.9932 - val_loss: 1.4755 - val_accuracy: 0.9872\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4692 - accuracy: 0.9936 - val_loss: 1.4756 - val_accuracy: 0.9871\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4686 - accuracy: 0.9941 - val_loss: 1.4753 - val_accuracy: 0.9870\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4681 - accuracy: 0.9942 - val_loss: 1.4747 - val_accuracy: 0.9875\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4677 - accuracy: 0.9949 - val_loss: 1.4752 - val_accuracy: 0.9868\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4675 - accuracy: 0.9945 - val_loss: 1.4746 - val_accuracy: 0.9876\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4668 - accuracy: 0.9954 - val_loss: 1.4732 - val_accuracy: 0.9887\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4663 - accuracy: 0.9959 - val_loss: 1.4739 - val_accuracy: 0.9884\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4660 - accuracy: 0.9962 - val_loss: 1.4737 - val_accuracy: 0.9884\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4660 - accuracy: 0.9961 - val_loss: 1.4743 - val_accuracy: 0.9871\n",
      "current pruning ratio is0.875, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5661 - accuracy: 0.9188 - val_loss: 1.5058 - val_accuracy: 0.9662\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4995 - accuracy: 0.9706 - val_loss: 1.4935 - val_accuracy: 0.9737\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4907 - accuracy: 0.9769 - val_loss: 1.4887 - val_accuracy: 0.9778\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4863 - accuracy: 0.9798 - val_loss: 1.4855 - val_accuracy: 0.9797\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4830 - accuracy: 0.9822 - val_loss: 1.4831 - val_accuracy: 0.9807\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4811 - accuracy: 0.9833 - val_loss: 1.4829 - val_accuracy: 0.9806\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4794 - accuracy: 0.9849 - val_loss: 1.4804 - val_accuracy: 0.9833\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4779 - accuracy: 0.9861 - val_loss: 1.4816 - val_accuracy: 0.9817\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4767 - accuracy: 0.9872 - val_loss: 1.4801 - val_accuracy: 0.9835\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4755 - accuracy: 0.9882 - val_loss: 1.4797 - val_accuracy: 0.9833\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4749 - accuracy: 0.9887 - val_loss: 1.4783 - val_accuracy: 0.9849\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4740 - accuracy: 0.9897 - val_loss: 1.4792 - val_accuracy: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4736 - accuracy: 0.9897 - val_loss: 1.4782 - val_accuracy: 0.9851\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4730 - accuracy: 0.9900 - val_loss: 1.4780 - val_accuracy: 0.9841\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4725 - accuracy: 0.9909 - val_loss: 1.4783 - val_accuracy: 0.9838\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9909 - val_loss: 1.4778 - val_accuracy: 0.9853\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4714 - accuracy: 0.9916 - val_loss: 1.4774 - val_accuracy: 0.9851\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9917 - val_loss: 1.4770 - val_accuracy: 0.9858\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9922 - val_loss: 1.4768 - val_accuracy: 0.9846\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4701 - accuracy: 0.9926 - val_loss: 1.4761 - val_accuracy: 0.9862\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4697 - accuracy: 0.9931 - val_loss: 1.4763 - val_accuracy: 0.9857\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4694 - accuracy: 0.9932 - val_loss: 1.4767 - val_accuracy: 0.9861\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4692 - accuracy: 0.9933 - val_loss: 1.4767 - val_accuracy: 0.9861\n",
      "current pruning ratio is0.9375, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6605 - accuracy: 0.8329 - val_loss: 1.5336 - val_accuracy: 0.9437\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5264 - accuracy: 0.9487 - val_loss: 1.5131 - val_accuracy: 0.9576\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5114 - accuracy: 0.9593 - val_loss: 1.5043 - val_accuracy: 0.9644\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5036 - accuracy: 0.9649 - val_loss: 1.4994 - val_accuracy: 0.9671\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4989 - accuracy: 0.9685 - val_loss: 1.4964 - val_accuracy: 0.9700\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4953 - accuracy: 0.9713 - val_loss: 1.4942 - val_accuracy: 0.9711\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4925 - accuracy: 0.9736 - val_loss: 1.4918 - val_accuracy: 0.9740\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4906 - accuracy: 0.9750 - val_loss: 1.4907 - val_accuracy: 0.9746\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4887 - accuracy: 0.9766 - val_loss: 1.4887 - val_accuracy: 0.9761\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4873 - accuracy: 0.9778 - val_loss: 1.4876 - val_accuracy: 0.9767\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4860 - accuracy: 0.9787 - val_loss: 1.4875 - val_accuracy: 0.9760\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4849 - accuracy: 0.9801 - val_loss: 1.4868 - val_accuracy: 0.9773\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4841 - accuracy: 0.9804 - val_loss: 1.4860 - val_accuracy: 0.9775\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4831 - accuracy: 0.9814 - val_loss: 1.4856 - val_accuracy: 0.9780\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4822 - accuracy: 0.9822 - val_loss: 1.4847 - val_accuracy: 0.9790\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4818 - accuracy: 0.9822 - val_loss: 1.4838 - val_accuracy: 0.9808\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4808 - accuracy: 0.9833 - val_loss: 1.4839 - val_accuracy: 0.9798\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4804 - accuracy: 0.9837 - val_loss: 1.4839 - val_accuracy: 0.9796\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4798 - accuracy: 0.9843 - val_loss: 1.4837 - val_accuracy: 0.9793\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4795 - accuracy: 0.9845 - val_loss: 1.4828 - val_accuracy: 0.9815\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4789 - accuracy: 0.9852 - val_loss: 1.4830 - val_accuracy: 0.9802\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4784 - accuracy: 0.9855 - val_loss: 1.4825 - val_accuracy: 0.9808\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4779 - accuracy: 0.9859 - val_loss: 1.4831 - val_accuracy: 0.9800\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4775 - accuracy: 0.9864 - val_loss: 1.4825 - val_accuracy: 0.9807\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4773 - accuracy: 0.9861 - val_loss: 1.4828 - val_accuracy: 0.9806\n",
      "current pruning ratio is0.96875, goal ratio ist 0.96875\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.9284 - accuracy: 0.5484 - val_loss: 1.7662 - val_accuracy: 0.7125\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6923 - accuracy: 0.7858 - val_loss: 1.5926 - val_accuracy: 0.8882\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5842 - accuracy: 0.8916 - val_loss: 1.5682 - val_accuracy: 0.9057\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5681 - accuracy: 0.9041 - val_loss: 1.5555 - val_accuracy: 0.9154\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5582 - accuracy: 0.9126 - val_loss: 1.5480 - val_accuracy: 0.9229\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5512 - accuracy: 0.9184 - val_loss: 1.5445 - val_accuracy: 0.9244\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5459 - accuracy: 0.9229 - val_loss: 1.5383 - val_accuracy: 0.9310\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5415 - accuracy: 0.9265 - val_loss: 1.5360 - val_accuracy: 0.9312\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5378 - accuracy: 0.9305 - val_loss: 1.5329 - val_accuracy: 0.9343\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5347 - accuracy: 0.9332 - val_loss: 1.5302 - val_accuracy: 0.9376\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5320 - accuracy: 0.9355 - val_loss: 1.5281 - val_accuracy: 0.9383\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5296 - accuracy: 0.9377 - val_loss: 1.5275 - val_accuracy: 0.9379\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5276 - accuracy: 0.9395 - val_loss: 1.5249 - val_accuracy: 0.9416\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5260 - accuracy: 0.9408 - val_loss: 1.5242 - val_accuracy: 0.9422\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5240 - accuracy: 0.9429 - val_loss: 1.5224 - val_accuracy: 0.9422\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5227 - accuracy: 0.9437 - val_loss: 1.5202 - val_accuracy: 0.9462\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5216 - accuracy: 0.9443 - val_loss: 1.5199 - val_accuracy: 0.9454\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5200 - accuracy: 0.9459 - val_loss: 1.5185 - val_accuracy: 0.9472\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5191 - accuracy: 0.9472 - val_loss: 1.5174 - val_accuracy: 0.9474\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5178 - accuracy: 0.9482 - val_loss: 1.5177 - val_accuracy: 0.9471\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5170 - accuracy: 0.9488 - val_loss: 1.5180 - val_accuracy: 0.9465\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5163 - accuracy: 0.9495 - val_loss: 1.5165 - val_accuracy: 0.9475\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5154 - accuracy: 0.9499 - val_loss: 1.5152 - val_accuracy: 0.9489\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5148 - accuracy: 0.9508 - val_loss: 1.5150 - val_accuracy: 0.9490\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5139 - accuracy: 0.9517 - val_loss: 1.5143 - val_accuracy: 0.9504\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5132 - accuracy: 0.9520 - val_loss: 1.5153 - val_accuracy: 0.9497\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5126 - accuracy: 0.9528 - val_loss: 1.5150 - val_accuracy: 0.9499\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5121 - accuracy: 0.9531 - val_loss: 1.5122 - val_accuracy: 0.9523\n",
      "Epoch 29/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5113 - accuracy: 0.9538 - val_loss: 1.5157 - val_accuracy: 0.9483\n",
      "Epoch 30/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5110 - accuracy: 0.9546 - val_loss: 1.5125 - val_accuracy: 0.9524\n",
      "Epoch 31/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5106 - accuracy: 0.9545 - val_loss: 1.5162 - val_accuracy: 0.9481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [1:42:11, 1248.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5048 - accuracy: 0.9596 - val_loss: 1.4936 - val_accuracy: 0.9695\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4923 - accuracy: 0.9710 - val_loss: 1.4913 - val_accuracy: 0.9711\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4856 - accuracy: 0.9770 - val_loss: 1.4857 - val_accuracy: 0.9762\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4820 - accuracy: 0.9800 - val_loss: 1.4865 - val_accuracy: 0.9750\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4792 - accuracy: 0.9830 - val_loss: 1.4797 - val_accuracy: 0.9817\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4773 - accuracy: 0.9847 - val_loss: 1.4823 - val_accuracy: 0.9800\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4757 - accuracy: 0.9861 - val_loss: 1.4791 - val_accuracy: 0.9826\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4750 - accuracy: 0.9870 - val_loss: 1.4788 - val_accuracy: 0.9828\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4730 - accuracy: 0.9889 - val_loss: 1.4774 - val_accuracy: 0.9842\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4725 - accuracy: 0.9894 - val_loss: 1.4778 - val_accuracy: 0.9836\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4710 - accuracy: 0.9907 - val_loss: 1.4777 - val_accuracy: 0.9841\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4709 - accuracy: 0.9908 - val_loss: 1.4771 - val_accuracy: 0.9838\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4703 - accuracy: 0.9915 - val_loss: 1.4755 - val_accuracy: 0.9858\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4694 - accuracy: 0.9923 - val_loss: 1.4752 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4692 - accuracy: 0.9924 - val_loss: 1.4752 - val_accuracy: 0.9859\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4691 - accuracy: 0.9923 - val_loss: 1.4757 - val_accuracy: 0.9857\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4692 - accuracy: 0.9924 - val_loss: 1.4737 - val_accuracy: 0.9878\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4683 - accuracy: 0.9933 - val_loss: 1.4764 - val_accuracy: 0.9850\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4681 - accuracy: 0.9934 - val_loss: 1.4749 - val_accuracy: 0.9865\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4680 - accuracy: 0.9936 - val_loss: 1.4745 - val_accuracy: 0.9868\n",
      "current pruning ratio is0.5, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4840 - accuracy: 0.9843 - val_loss: 1.4795 - val_accuracy: 0.9849\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4735 - accuracy: 0.9904 - val_loss: 1.4772 - val_accuracy: 0.9863\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4709 - accuracy: 0.9923 - val_loss: 1.4761 - val_accuracy: 0.9870\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4695 - accuracy: 0.9934 - val_loss: 1.4771 - val_accuracy: 0.9853\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4687 - accuracy: 0.9938 - val_loss: 1.4749 - val_accuracy: 0.9871\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4678 - accuracy: 0.9947 - val_loss: 1.4745 - val_accuracy: 0.9879\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4672 - accuracy: 0.9951 - val_loss: 1.4750 - val_accuracy: 0.9866\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4666 - accuracy: 0.9955 - val_loss: 1.4761 - val_accuracy: 0.9852\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4666 - accuracy: 0.9953 - val_loss: 1.4734 - val_accuracy: 0.9886\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4661 - accuracy: 0.9957 - val_loss: 1.4740 - val_accuracy: 0.9873\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4661 - accuracy: 0.9958 - val_loss: 1.4740 - val_accuracy: 0.9876\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4658 - accuracy: 0.9959 - val_loss: 1.4740 - val_accuracy: 0.9879\n",
      "current pruning ratio is0.75, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5122 - accuracy: 0.9660 - val_loss: 1.4877 - val_accuracy: 0.9792\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4827 - accuracy: 0.9838 - val_loss: 1.4813 - val_accuracy: 0.9838\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4777 - accuracy: 0.9872 - val_loss: 1.4799 - val_accuracy: 0.9841\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4749 - accuracy: 0.9892 - val_loss: 1.4797 - val_accuracy: 0.9839\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4729 - accuracy: 0.9910 - val_loss: 1.4766 - val_accuracy: 0.9860\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4715 - accuracy: 0.9919 - val_loss: 1.4759 - val_accuracy: 0.9869\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4707 - accuracy: 0.9923 - val_loss: 1.4778 - val_accuracy: 0.9846\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4697 - accuracy: 0.9933 - val_loss: 1.4765 - val_accuracy: 0.9861\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4689 - accuracy: 0.9939 - val_loss: 1.4764 - val_accuracy: 0.9857\n",
      "current pruning ratio is0.875, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6220 - accuracy: 0.8766 - val_loss: 1.5214 - val_accuracy: 0.9548\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5135 - accuracy: 0.9596 - val_loss: 1.5010 - val_accuracy: 0.9683\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4987 - accuracy: 0.9704 - val_loss: 1.4922 - val_accuracy: 0.9745\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4911 - accuracy: 0.9757 - val_loss: 1.4881 - val_accuracy: 0.9779\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4868 - accuracy: 0.9793 - val_loss: 1.4858 - val_accuracy: 0.9785\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4839 - accuracy: 0.9814 - val_loss: 1.4842 - val_accuracy: 0.9799\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4815 - accuracy: 0.9831 - val_loss: 1.4817 - val_accuracy: 0.9822\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4799 - accuracy: 0.9843 - val_loss: 1.4818 - val_accuracy: 0.9813\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4783 - accuracy: 0.9855 - val_loss: 1.4797 - val_accuracy: 0.9838\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4770 - accuracy: 0.9869 - val_loss: 1.4797 - val_accuracy: 0.9830\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4761 - accuracy: 0.9874 - val_loss: 1.4793 - val_accuracy: 0.9832\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4754 - accuracy: 0.9880 - val_loss: 1.4784 - val_accuracy: 0.9841\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4745 - accuracy: 0.9889 - val_loss: 1.4783 - val_accuracy: 0.9841\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4737 - accuracy: 0.9895 - val_loss: 1.4778 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4733 - accuracy: 0.9898 - val_loss: 1.4769 - val_accuracy: 0.9857\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4728 - accuracy: 0.9900 - val_loss: 1.4765 - val_accuracy: 0.9866\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4721 - accuracy: 0.9907 - val_loss: 1.4769 - val_accuracy: 0.9861\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9909 - val_loss: 1.4759 - val_accuracy: 0.9865\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4712 - accuracy: 0.9916 - val_loss: 1.4765 - val_accuracy: 0.9855\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4706 - accuracy: 0.9919 - val_loss: 1.4769 - val_accuracy: 0.9851\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4703 - accuracy: 0.9924 - val_loss: 1.4772 - val_accuracy: 0.9855\n",
      "current pruning ratio is0.9375, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8304 - accuracy: 0.6521 - val_loss: 1.6244 - val_accuracy: 0.8630\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5672 - accuracy: 0.9107 - val_loss: 1.5438 - val_accuracy: 0.9286\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5421 - accuracy: 0.9298 - val_loss: 1.5312 - val_accuracy: 0.9372\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5308 - accuracy: 0.9395 - val_loss: 1.5231 - val_accuracy: 0.9453\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5227 - accuracy: 0.9465 - val_loss: 1.5173 - val_accuracy: 0.9497\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5164 - accuracy: 0.9516 - val_loss: 1.5127 - val_accuracy: 0.9538\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5119 - accuracy: 0.9553 - val_loss: 1.5097 - val_accuracy: 0.9563\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5078 - accuracy: 0.9587 - val_loss: 1.5055 - val_accuracy: 0.9606\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5048 - accuracy: 0.9614 - val_loss: 1.5033 - val_accuracy: 0.9625\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5018 - accuracy: 0.9646 - val_loss: 1.5012 - val_accuracy: 0.9645\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4997 - accuracy: 0.9663 - val_loss: 1.4995 - val_accuracy: 0.9661\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4977 - accuracy: 0.9683 - val_loss: 1.5001 - val_accuracy: 0.9636\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4962 - accuracy: 0.9697 - val_loss: 1.4983 - val_accuracy: 0.9660\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4948 - accuracy: 0.9706 - val_loss: 1.4971 - val_accuracy: 0.9681\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4935 - accuracy: 0.9717 - val_loss: 1.4951 - val_accuracy: 0.9695\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4924 - accuracy: 0.9727 - val_loss: 1.4946 - val_accuracy: 0.9692\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4917 - accuracy: 0.9730 - val_loss: 1.4936 - val_accuracy: 0.9691\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4906 - accuracy: 0.9742 - val_loss: 1.4928 - val_accuracy: 0.9700\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4898 - accuracy: 0.9751 - val_loss: 1.4937 - val_accuracy: 0.9690\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4893 - accuracy: 0.9752 - val_loss: 1.4932 - val_accuracy: 0.9698\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4884 - accuracy: 0.9760 - val_loss: 1.4926 - val_accuracy: 0.9691\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4875 - accuracy: 0.9767 - val_loss: 1.4920 - val_accuracy: 0.9714\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4872 - accuracy: 0.9770 - val_loss: 1.4914 - val_accuracy: 0.9716\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4865 - accuracy: 0.9778 - val_loss: 1.4907 - val_accuracy: 0.9727\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4859 - accuracy: 0.9782 - val_loss: 1.4904 - val_accuracy: 0.9725\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4855 - accuracy: 0.9785 - val_loss: 1.4905 - val_accuracy: 0.9721\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4853 - accuracy: 0.9788 - val_loss: 1.4905 - val_accuracy: 0.9726\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4847 - accuracy: 0.9794 - val_loss: 1.4902 - val_accuracy: 0.9730\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4840 - accuracy: 0.9801 - val_loss: 1.4901 - val_accuracy: 0.9730\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4838 - accuracy: 0.9798 - val_loss: 1.4897 - val_accuracy: 0.9728\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4835 - accuracy: 0.9802 - val_loss: 1.4892 - val_accuracy: 0.9729\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4830 - accuracy: 0.9805 - val_loss: 1.4894 - val_accuracy: 0.9728\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4828 - accuracy: 0.9809 - val_loss: 1.4903 - val_accuracy: 0.9722\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4824 - accuracy: 0.9813 - val_loss: 1.4887 - val_accuracy: 0.9741\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4819 - accuracy: 0.9819 - val_loss: 1.4882 - val_accuracy: 0.9748\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4815 - accuracy: 0.9821 - val_loss: 1.4883 - val_accuracy: 0.9741\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4813 - accuracy: 0.9825 - val_loss: 1.4894 - val_accuracy: 0.9727\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4812 - accuracy: 0.9826 - val_loss: 1.4881 - val_accuracy: 0.9749\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4807 - accuracy: 0.9827 - val_loss: 1.4883 - val_accuracy: 0.9739\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4806 - accuracy: 0.9828 - val_loss: 1.4890 - val_accuracy: 0.9731\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4804 - accuracy: 0.9830 - val_loss: 1.4884 - val_accuracy: 0.9740\n",
      "current pruning ratio is0.96875, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8802 - accuracy: 0.6035 - val_loss: 1.7423 - val_accuracy: 0.7580\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7106 - accuracy: 0.7812 - val_loss: 1.6803 - val_accuracy: 0.8019\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6724 - accuracy: 0.8078 - val_loss: 1.6552 - val_accuracy: 0.8219\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6552 - accuracy: 0.8199 - val_loss: 1.6434 - val_accuracy: 0.8289\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6454 - accuracy: 0.8264 - val_loss: 1.6360 - val_accuracy: 0.8351\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6388 - accuracy: 0.8313 - val_loss: 1.6305 - val_accuracy: 0.8386\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6342 - accuracy: 0.8350 - val_loss: 1.6276 - val_accuracy: 0.8395\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6303 - accuracy: 0.8385 - val_loss: 1.6257 - val_accuracy: 0.8405\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6271 - accuracy: 0.8405 - val_loss: 1.6236 - val_accuracy: 0.8423\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6246 - accuracy: 0.8424 - val_loss: 1.6216 - val_accuracy: 0.8434\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6221 - accuracy: 0.8449 - val_loss: 1.6202 - val_accuracy: 0.8440\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6204 - accuracy: 0.8460 - val_loss: 1.6204 - val_accuracy: 0.8442\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6187 - accuracy: 0.8476 - val_loss: 1.6183 - val_accuracy: 0.8462\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6172 - accuracy: 0.8481 - val_loss: 1.6169 - val_accuracy: 0.8468\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6161 - accuracy: 0.8496 - val_loss: 1.6160 - val_accuracy: 0.8485\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6149 - accuracy: 0.8505 - val_loss: 1.6148 - val_accuracy: 0.8495\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6139 - accuracy: 0.8510 - val_loss: 1.6145 - val_accuracy: 0.8502\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6130 - accuracy: 0.8525 - val_loss: 1.6135 - val_accuracy: 0.8489\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6121 - accuracy: 0.8528 - val_loss: 1.6123 - val_accuracy: 0.8515\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6116 - accuracy: 0.8533 - val_loss: 1.6124 - val_accuracy: 0.8529\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6106 - accuracy: 0.8544 - val_loss: 1.6122 - val_accuracy: 0.8515\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6101 - accuracy: 0.8544 - val_loss: 1.6102 - val_accuracy: 0.8536\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6093 - accuracy: 0.8555 - val_loss: 1.6098 - val_accuracy: 0.8528\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6087 - accuracy: 0.8560 - val_loss: 1.6098 - val_accuracy: 0.8538\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6083 - accuracy: 0.8556 - val_loss: 1.6094 - val_accuracy: 0.8543\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6077 - accuracy: 0.8569 - val_loss: 1.6087 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.6073 - accuracy: 0.8569 - val_loss: 1.6077 - val_accuracy: 0.8549\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6066 - accuracy: 0.8573 - val_loss: 1.6103 - val_accuracy: 0.8517\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6063 - accuracy: 0.8579 - val_loss: 1.6093 - val_accuracy: 0.8527\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6060 - accuracy: 0.8582 - val_loss: 1.6073 - val_accuracy: 0.8560\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6053 - accuracy: 0.8583 - val_loss: 1.6066 - val_accuracy: 0.8567\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6050 - accuracy: 0.8592 - val_loss: 1.6069 - val_accuracy: 0.8563\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6048 - accuracy: 0.8591 - val_loss: 1.6062 - val_accuracy: 0.8568\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6043 - accuracy: 0.8594 - val_loss: 1.6060 - val_accuracy: 0.8569\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6039 - accuracy: 0.8598 - val_loss: 1.6053 - val_accuracy: 0.8575\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6036 - accuracy: 0.8604 - val_loss: 1.6056 - val_accuracy: 0.8572\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6031 - accuracy: 0.8607 - val_loss: 1.6049 - val_accuracy: 0.8588\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6030 - accuracy: 0.8607 - val_loss: 1.6061 - val_accuracy: 0.8566\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6026 - accuracy: 0.8611 - val_loss: 1.6065 - val_accuracy: 0.8559\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6024 - accuracy: 0.8613 - val_loss: 1.6066 - val_accuracy: 0.8547\n",
      "current pruning ratio is0.984375, goal ratio ist 0.984375\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.9129 - accuracy: 0.5624 - val_loss: 1.8145 - val_accuracy: 0.6669\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7990 - accuracy: 0.6792 - val_loss: 1.7802 - val_accuracy: 0.6966\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.7784 - accuracy: 0.6956 - val_loss: 1.7663 - val_accuracy: 0.7061\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.7687 - accuracy: 0.7035 - val_loss: 1.7606 - val_accuracy: 0.7096\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.7628 - accuracy: 0.7065 - val_loss: 1.7560 - val_accuracy: 0.7138\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7590 - accuracy: 0.7093 - val_loss: 1.7509 - val_accuracy: 0.7165\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7562 - accuracy: 0.7115 - val_loss: 1.7493 - val_accuracy: 0.7182\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7541 - accuracy: 0.7131 - val_loss: 1.7462 - val_accuracy: 0.7219\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7526 - accuracy: 0.7135 - val_loss: 1.7446 - val_accuracy: 0.7231\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7509 - accuracy: 0.7154 - val_loss: 1.7429 - val_accuracy: 0.7246\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7498 - accuracy: 0.7163 - val_loss: 1.7431 - val_accuracy: 0.7228\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7487 - accuracy: 0.7166 - val_loss: 1.7422 - val_accuracy: 0.7220\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7478 - accuracy: 0.7172 - val_loss: 1.7401 - val_accuracy: 0.7270\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7469 - accuracy: 0.7178 - val_loss: 1.7398 - val_accuracy: 0.7256\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7460 - accuracy: 0.7190 - val_loss: 1.7409 - val_accuracy: 0.7251\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7454 - accuracy: 0.7187 - val_loss: 1.7399 - val_accuracy: 0.7252\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7446 - accuracy: 0.7200 - val_loss: 1.7411 - val_accuracy: 0.7238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [2:26:15, 1253.58s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [2:26:33<4:53:06, 8793.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5922 - accuracy: 0.8911 - val_loss: 1.5137 - val_accuracy: 0.9528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.0\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5046 - accuracy: 0.9603 - val_loss: 1.4938 - val_accuracy: 0.9701\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4916 - accuracy: 0.9716 - val_loss: 1.4880 - val_accuracy: 0.9746\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4848 - accuracy: 0.9778 - val_loss: 1.4853 - val_accuracy: 0.9772\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4811 - accuracy: 0.9815 - val_loss: 1.4820 - val_accuracy: 0.9796\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4785 - accuracy: 0.9837 - val_loss: 1.4817 - val_accuracy: 0.9804\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4757 - accuracy: 0.9863 - val_loss: 1.4783 - val_accuracy: 0.9833\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4751 - accuracy: 0.9870 - val_loss: 1.4795 - val_accuracy: 0.9824\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4740 - accuracy: 0.9879 - val_loss: 1.4766 - val_accuracy: 0.9851\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4728 - accuracy: 0.9889 - val_loss: 1.4774 - val_accuracy: 0.9841\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4716 - accuracy: 0.9903 - val_loss: 1.4754 - val_accuracy: 0.9862\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4714 - accuracy: 0.9903 - val_loss: 1.4779 - val_accuracy: 0.9838\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4708 - accuracy: 0.9907 - val_loss: 1.4799 - val_accuracy: 0.9824\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4702 - accuracy: 0.9916 - val_loss: 1.4747 - val_accuracy: 0.9868\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4693 - accuracy: 0.9924 - val_loss: 1.4772 - val_accuracy: 0.9847\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4693 - accuracy: 0.9923 - val_loss: 1.4759 - val_accuracy: 0.9854\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4688 - accuracy: 0.9928 - val_loss: 1.4752 - val_accuracy: 0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [04:36, 276.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.5\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5045 - accuracy: 0.9600 - val_loss: 1.4929 - val_accuracy: 0.9704\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4908 - accuracy: 0.9724 - val_loss: 1.4866 - val_accuracy: 0.9763\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4853 - accuracy: 0.9769 - val_loss: 1.4873 - val_accuracy: 0.9756\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4811 - accuracy: 0.9815 - val_loss: 1.4843 - val_accuracy: 0.9780\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4783 - accuracy: 0.9836 - val_loss: 1.4828 - val_accuracy: 0.9790\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4761 - accuracy: 0.9860 - val_loss: 1.4784 - val_accuracy: 0.9835\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4743 - accuracy: 0.9876 - val_loss: 1.4798 - val_accuracy: 0.9818\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4740 - accuracy: 0.9877 - val_loss: 1.4819 - val_accuracy: 0.9797\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4727 - accuracy: 0.9892 - val_loss: 1.4777 - val_accuracy: 0.9841\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4722 - accuracy: 0.9894 - val_loss: 1.4819 - val_accuracy: 0.9799\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9899 - val_loss: 1.4764 - val_accuracy: 0.9846\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4700 - accuracy: 0.9919 - val_loss: 1.4771 - val_accuracy: 0.9840\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4698 - accuracy: 0.9918 - val_loss: 1.4778 - val_accuracy: 0.9836\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4702 - accuracy: 0.9916 - val_loss: 1.4743 - val_accuracy: 0.9874\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4689 - accuracy: 0.9926 - val_loss: 1.4766 - val_accuracy: 0.9847\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4693 - accuracy: 0.9923 - val_loss: 1.4758 - val_accuracy: 0.9860\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4687 - accuracy: 0.9930 - val_loss: 1.4753 - val_accuracy: 0.9862\n",
      "current pruning ratio is0.5, goal ratio ist 0.5\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4873 - accuracy: 0.9809 - val_loss: 1.4795 - val_accuracy: 0.9852\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4746 - accuracy: 0.9891 - val_loss: 1.4779 - val_accuracy: 0.9858\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9916 - val_loss: 1.4769 - val_accuracy: 0.9863\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4702 - accuracy: 0.9926 - val_loss: 1.4749 - val_accuracy: 0.9872\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4690 - accuracy: 0.9934 - val_loss: 1.4750 - val_accuracy: 0.9869\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4687 - accuracy: 0.9936 - val_loss: 1.4752 - val_accuracy: 0.9868\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4680 - accuracy: 0.9942 - val_loss: 1.4741 - val_accuracy: 0.9877\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4673 - accuracy: 0.9946 - val_loss: 1.4744 - val_accuracy: 0.9876\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4673 - accuracy: 0.9946 - val_loss: 1.4727 - val_accuracy: 0.9893\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4669 - accuracy: 0.9952 - val_loss: 1.4741 - val_accuracy: 0.9877\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4662 - accuracy: 0.9956 - val_loss: 1.4738 - val_accuracy: 0.9878\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4662 - accuracy: 0.9954 - val_loss: 1.4738 - val_accuracy: 0.9876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [12:44, 339.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.75\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5052 - accuracy: 0.9597 - val_loss: 1.4957 - val_accuracy: 0.9678\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4908 - accuracy: 0.9724 - val_loss: 1.4890 - val_accuracy: 0.9735\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4849 - accuracy: 0.9779 - val_loss: 1.4873 - val_accuracy: 0.9750\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4816 - accuracy: 0.9808 - val_loss: 1.4846 - val_accuracy: 0.9773\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4783 - accuracy: 0.9839 - val_loss: 1.4813 - val_accuracy: 0.9802\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4763 - accuracy: 0.9857 - val_loss: 1.4800 - val_accuracy: 0.9818\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4751 - accuracy: 0.9867 - val_loss: 1.4783 - val_accuracy: 0.9840\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4741 - accuracy: 0.9878 - val_loss: 1.4771 - val_accuracy: 0.9846\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4727 - accuracy: 0.9891 - val_loss: 1.4775 - val_accuracy: 0.9846\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4715 - accuracy: 0.9903 - val_loss: 1.4765 - val_accuracy: 0.9853\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4713 - accuracy: 0.9904 - val_loss: 1.4752 - val_accuracy: 0.9866\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4708 - accuracy: 0.9910 - val_loss: 1.4763 - val_accuracy: 0.9854\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4703 - accuracy: 0.9913 - val_loss: 1.4762 - val_accuracy: 0.9857\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4695 - accuracy: 0.9922 - val_loss: 1.4751 - val_accuracy: 0.9867\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4689 - accuracy: 0.9927 - val_loss: 1.4765 - val_accuracy: 0.9845\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4689 - accuracy: 0.9927 - val_loss: 1.4778 - val_accuracy: 0.9832\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4686 - accuracy: 0.9929 - val_loss: 1.4759 - val_accuracy: 0.9856\n",
      "current pruning ratio is0.5, goal ratio ist 0.75\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4942 - accuracy: 0.9754 - val_loss: 1.4820 - val_accuracy: 0.9825\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4763 - accuracy: 0.9882 - val_loss: 1.4775 - val_accuracy: 0.9869\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4731 - accuracy: 0.9903 - val_loss: 1.4767 - val_accuracy: 0.9867\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4715 - accuracy: 0.9913 - val_loss: 1.4775 - val_accuracy: 0.9855\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4700 - accuracy: 0.9924 - val_loss: 1.4761 - val_accuracy: 0.9860\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4693 - accuracy: 0.9931 - val_loss: 1.4745 - val_accuracy: 0.9874\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.4684 - accuracy: 0.9938 - val_loss: 1.4752 - val_accuracy: 0.9869\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4680 - accuracy: 0.9942 - val_loss: 1.4741 - val_accuracy: 0.9881\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4674 - accuracy: 0.9946 - val_loss: 1.4740 - val_accuracy: 0.9879\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4670 - accuracy: 0.9951 - val_loss: 1.4738 - val_accuracy: 0.9879\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 1.4667 - accuracy: 0.9952 - val_loss: 1.4745 - val_accuracy: 0.9871\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4670 - accuracy: 0.9948 - val_loss: 1.4757 - val_accuracy: 0.9860\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 1.4662 - accuracy: 0.9956 - val_loss: 1.4742 - val_accuracy: 0.9874\n",
      "current pruning ratio is0.75, goal ratio ist 0.75\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 1.5187 - accuracy: 0.9580 - val_loss: 1.4917 - val_accuracy: 0.9757\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.4855 - accuracy: 0.9808 - val_loss: 1.4848 - val_accuracy: 0.9807\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4795 - accuracy: 0.9857 - val_loss: 1.4802 - val_accuracy: 0.9841\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 1.4766 - accuracy: 0.9877 - val_loss: 1.4792 - val_accuracy: 0.9849\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.4743 - accuracy: 0.9894 - val_loss: 1.4789 - val_accuracy: 0.9848\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4730 - accuracy: 0.9903 - val_loss: 1.4775 - val_accuracy: 0.9855\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4715 - accuracy: 0.9917 - val_loss: 1.4776 - val_accuracy: 0.9853\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4707 - accuracy: 0.9922 - val_loss: 1.4775 - val_accuracy: 0.9847\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4699 - accuracy: 0.9929 - val_loss: 1.4785 - val_accuracy: 0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [24:10, 443.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5048 - accuracy: 0.9597 - val_loss: 1.4948 - val_accuracy: 0.9689\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4904 - accuracy: 0.9727 - val_loss: 1.4900 - val_accuracy: 0.9728\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4847 - accuracy: 0.9782 - val_loss: 1.4848 - val_accuracy: 0.9773\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4809 - accuracy: 0.9815 - val_loss: 1.4841 - val_accuracy: 0.9775\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 1.4781 - accuracy: 0.9840 - val_loss: 1.4823 - val_accuracy: 0.9800\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4768 - accuracy: 0.9852 - val_loss: 1.4830 - val_accuracy: 0.9783\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.4751 - accuracy: 0.9868 - val_loss: 1.4776 - val_accuracy: 0.9843\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4731 - accuracy: 0.9890 - val_loss: 1.4796 - val_accuracy: 0.9828\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.4722 - accuracy: 0.9898 - val_loss: 1.4777 - val_accuracy: 0.9839\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.4716 - accuracy: 0.9903 - val_loss: 1.4784 - val_accuracy: 0.9827\n",
      "current pruning ratio is0.5, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 1.4875 - accuracy: 0.9825 - val_loss: 1.4803 - val_accuracy: 0.9846\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.4764 - accuracy: 0.9880 - val_loss: 1.4774 - val_accuracy: 0.9857\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.4735 - accuracy: 0.9898 - val_loss: 1.4759 - val_accuracy: 0.9875\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.4717 - accuracy: 0.9912 - val_loss: 1.4781 - val_accuracy: 0.9847\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 1.4705 - accuracy: 0.9923 - val_loss: 1.4766 - val_accuracy: 0.9855\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4702 - accuracy: 0.9922 - val_loss: 1.4763 - val_accuracy: 0.9855\n",
      "current pruning ratio is0.75, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5188 - accuracy: 0.9645 - val_loss: 1.4912 - val_accuracy: 0.9770\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4855 - accuracy: 0.9818 - val_loss: 1.4845 - val_accuracy: 0.9803\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4794 - accuracy: 0.9857 - val_loss: 1.4803 - val_accuracy: 0.9839\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4764 - accuracy: 0.9876 - val_loss: 1.4775 - val_accuracy: 0.9854\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4746 - accuracy: 0.9891 - val_loss: 1.4780 - val_accuracy: 0.9851\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4733 - accuracy: 0.9901 - val_loss: 1.4788 - val_accuracy: 0.9840\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4718 - accuracy: 0.9914 - val_loss: 1.4758 - val_accuracy: 0.9863\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4710 - accuracy: 0.9920 - val_loss: 1.4759 - val_accuracy: 0.9865\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4700 - accuracy: 0.9927 - val_loss: 1.4748 - val_accuracy: 0.9872\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4698 - accuracy: 0.9927 - val_loss: 1.4750 - val_accuracy: 0.9874\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4691 - accuracy: 0.9932 - val_loss: 1.4746 - val_accuracy: 0.9880\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4684 - accuracy: 0.9938 - val_loss: 1.4739 - val_accuracy: 0.9878\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4680 - accuracy: 0.9944 - val_loss: 1.4757 - val_accuracy: 0.9861\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4680 - accuracy: 0.9942 - val_loss: 1.4746 - val_accuracy: 0.9872\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4673 - accuracy: 0.9948 - val_loss: 1.4748 - val_accuracy: 0.9868\n",
      "current pruning ratio is0.875, goal ratio ist 0.875\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5548 - accuracy: 0.9328 - val_loss: 1.5043 - val_accuracy: 0.9671\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4987 - accuracy: 0.9712 - val_loss: 1.4921 - val_accuracy: 0.9759\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4900 - accuracy: 0.9775 - val_loss: 1.4874 - val_accuracy: 0.9788\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4853 - accuracy: 0.9806 - val_loss: 1.4840 - val_accuracy: 0.9810\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4821 - accuracy: 0.9832 - val_loss: 1.4833 - val_accuracy: 0.9815\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4801 - accuracy: 0.9844 - val_loss: 1.4821 - val_accuracy: 0.9822\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4784 - accuracy: 0.9862 - val_loss: 1.4800 - val_accuracy: 0.9830\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4770 - accuracy: 0.9870 - val_loss: 1.4813 - val_accuracy: 0.9821\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4759 - accuracy: 0.9881 - val_loss: 1.4797 - val_accuracy: 0.9834\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4751 - accuracy: 0.9884 - val_loss: 1.4793 - val_accuracy: 0.9843\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4744 - accuracy: 0.9892 - val_loss: 1.4785 - val_accuracy: 0.9849\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4737 - accuracy: 0.9897 - val_loss: 1.4777 - val_accuracy: 0.9851\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4729 - accuracy: 0.9903 - val_loss: 1.4783 - val_accuracy: 0.9839\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4724 - accuracy: 0.9907 - val_loss: 1.4793 - val_accuracy: 0.9835\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4719 - accuracy: 0.9913 - val_loss: 1.4772 - val_accuracy: 0.9856\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4715 - accuracy: 0.9915 - val_loss: 1.4765 - val_accuracy: 0.9855\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4708 - accuracy: 0.9920 - val_loss: 1.4780 - val_accuracy: 0.9841\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4705 - accuracy: 0.9923 - val_loss: 1.4780 - val_accuracy: 0.9842\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4699 - accuracy: 0.9927 - val_loss: 1.4780 - val_accuracy: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [39:02, 578.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5043 - accuracy: 0.9605 - val_loss: 1.4979 - val_accuracy: 0.9667\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4908 - accuracy: 0.9725 - val_loss: 1.4879 - val_accuracy: 0.9754\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4853 - accuracy: 0.9778 - val_loss: 1.4858 - val_accuracy: 0.9762\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4809 - accuracy: 0.9814 - val_loss: 1.4817 - val_accuracy: 0.9797\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4786 - accuracy: 0.9834 - val_loss: 1.4815 - val_accuracy: 0.9808\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4758 - accuracy: 0.9864 - val_loss: 1.4819 - val_accuracy: 0.9801\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4744 - accuracy: 0.9876 - val_loss: 1.4801 - val_accuracy: 0.9813\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4730 - accuracy: 0.9889 - val_loss: 1.4774 - val_accuracy: 0.9845\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4724 - accuracy: 0.9895 - val_loss: 1.4781 - val_accuracy: 0.9838\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4716 - accuracy: 0.9902 - val_loss: 1.4757 - val_accuracy: 0.9858\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4710 - accuracy: 0.9906 - val_loss: 1.4767 - val_accuracy: 0.9844\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9905 - val_loss: 1.4747 - val_accuracy: 0.9870\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4699 - accuracy: 0.9919 - val_loss: 1.4762 - val_accuracy: 0.9855\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.4693 - accuracy: 0.9923 - val_loss: 1.4752 - val_accuracy: 0.9863\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4691 - accuracy: 0.9926 - val_loss: 1.4764 - val_accuracy: 0.9846\n",
      "current pruning ratio is0.5, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4851 - accuracy: 0.9830 - val_loss: 1.4773 - val_accuracy: 0.9870\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 1.4741 - accuracy: 0.9900 - val_loss: 1.4751 - val_accuracy: 0.9883\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4717 - accuracy: 0.9916 - val_loss: 1.4763 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4704 - accuracy: 0.9924 - val_loss: 1.4756 - val_accuracy: 0.9874\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4695 - accuracy: 0.9931 - val_loss: 1.4742 - val_accuracy: 0.9878\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4686 - accuracy: 0.9938 - val_loss: 1.4737 - val_accuracy: 0.9885\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4678 - accuracy: 0.9944 - val_loss: 1.4738 - val_accuracy: 0.9882\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4677 - accuracy: 0.9945 - val_loss: 1.4739 - val_accuracy: 0.9881\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4671 - accuracy: 0.9949 - val_loss: 1.4740 - val_accuracy: 0.9878\n",
      "current pruning ratio is0.75, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5256 - accuracy: 0.9581 - val_loss: 1.4929 - val_accuracy: 0.9765\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4864 - accuracy: 0.9813 - val_loss: 1.4835 - val_accuracy: 0.9833\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4801 - accuracy: 0.9851 - val_loss: 1.4793 - val_accuracy: 0.9851\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4767 - accuracy: 0.9878 - val_loss: 1.4784 - val_accuracy: 0.9858\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4745 - accuracy: 0.9894 - val_loss: 1.4758 - val_accuracy: 0.9875\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4730 - accuracy: 0.9908 - val_loss: 1.4753 - val_accuracy: 0.9877\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4720 - accuracy: 0.9912 - val_loss: 1.4760 - val_accuracy: 0.9869\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9917 - val_loss: 1.4779 - val_accuracy: 0.9851\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4703 - accuracy: 0.9925 - val_loss: 1.4758 - val_accuracy: 0.9873\n",
      "current pruning ratio is0.875, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5756 - accuracy: 0.9173 - val_loss: 1.5095 - val_accuracy: 0.9647\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5038 - accuracy: 0.9684 - val_loss: 1.4952 - val_accuracy: 0.9738\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4931 - accuracy: 0.9747 - val_loss: 1.4913 - val_accuracy: 0.9756\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4876 - accuracy: 0.9789 - val_loss: 1.4858 - val_accuracy: 0.9796\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4840 - accuracy: 0.9814 - val_loss: 1.4845 - val_accuracy: 0.9794\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4816 - accuracy: 0.9833 - val_loss: 1.4825 - val_accuracy: 0.9816\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4796 - accuracy: 0.9847 - val_loss: 1.4824 - val_accuracy: 0.9815\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4782 - accuracy: 0.9861 - val_loss: 1.4807 - val_accuracy: 0.9825\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4766 - accuracy: 0.9872 - val_loss: 1.4810 - val_accuracy: 0.9813\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4756 - accuracy: 0.9883 - val_loss: 1.4798 - val_accuracy: 0.9825\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4750 - accuracy: 0.9885 - val_loss: 1.4807 - val_accuracy: 0.9825\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4740 - accuracy: 0.9894 - val_loss: 1.4785 - val_accuracy: 0.9839\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4730 - accuracy: 0.9907 - val_loss: 1.4795 - val_accuracy: 0.9827\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4726 - accuracy: 0.9908 - val_loss: 1.4783 - val_accuracy: 0.9835\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4722 - accuracy: 0.9908 - val_loss: 1.4785 - val_accuracy: 0.9843\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4715 - accuracy: 0.9915 - val_loss: 1.4781 - val_accuracy: 0.9839\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4710 - accuracy: 0.9916 - val_loss: 1.4768 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9923 - val_loss: 1.4782 - val_accuracy: 0.9839\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9922 - val_loss: 1.4780 - val_accuracy: 0.9838\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4701 - accuracy: 0.9926 - val_loss: 1.4764 - val_accuracy: 0.9857\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4697 - accuracy: 0.9930 - val_loss: 1.4766 - val_accuracy: 0.9861\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4695 - accuracy: 0.9930 - val_loss: 1.4757 - val_accuracy: 0.9863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4693 - accuracy: 0.9932 - val_loss: 1.4772 - val_accuracy: 0.9848\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4688 - accuracy: 0.9936 - val_loss: 1.4775 - val_accuracy: 0.9845\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4688 - accuracy: 0.9937 - val_loss: 1.4765 - val_accuracy: 0.9850\n",
      "current pruning ratio is0.9375, goal ratio ist 0.9375\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7107 - accuracy: 0.7738 - val_loss: 1.6273 - val_accuracy: 0.8452\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5594 - accuracy: 0.9173 - val_loss: 1.5291 - val_accuracy: 0.9438\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5246 - accuracy: 0.9473 - val_loss: 1.5164 - val_accuracy: 0.9534\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5137 - accuracy: 0.9560 - val_loss: 1.5084 - val_accuracy: 0.9604\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5070 - accuracy: 0.9613 - val_loss: 1.5030 - val_accuracy: 0.9652\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5023 - accuracy: 0.9655 - val_loss: 1.5006 - val_accuracy: 0.9665\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4987 - accuracy: 0.9682 - val_loss: 1.4982 - val_accuracy: 0.9673\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4959 - accuracy: 0.9705 - val_loss: 1.4965 - val_accuracy: 0.9691\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4939 - accuracy: 0.9717 - val_loss: 1.4948 - val_accuracy: 0.9700\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4920 - accuracy: 0.9735 - val_loss: 1.4948 - val_accuracy: 0.9706\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4903 - accuracy: 0.9750 - val_loss: 1.4932 - val_accuracy: 0.9705\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4889 - accuracy: 0.9765 - val_loss: 1.4918 - val_accuracy: 0.9726\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4879 - accuracy: 0.9768 - val_loss: 1.4922 - val_accuracy: 0.9725\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4868 - accuracy: 0.9777 - val_loss: 1.4905 - val_accuracy: 0.9728\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4860 - accuracy: 0.9782 - val_loss: 1.4898 - val_accuracy: 0.9738\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.4849 - accuracy: 0.9798 - val_loss: 1.4889 - val_accuracy: 0.9752\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4840 - accuracy: 0.9805 - val_loss: 1.4891 - val_accuracy: 0.9751\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4835 - accuracy: 0.9805 - val_loss: 1.4881 - val_accuracy: 0.9753\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4828 - accuracy: 0.9814 - val_loss: 1.4887 - val_accuracy: 0.9740\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4825 - accuracy: 0.9815 - val_loss: 1.4888 - val_accuracy: 0.9750\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4817 - accuracy: 0.9821 - val_loss: 1.4875 - val_accuracy: 0.9755\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4812 - accuracy: 0.9825 - val_loss: 1.4886 - val_accuracy: 0.9740\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4809 - accuracy: 0.9828 - val_loss: 1.4891 - val_accuracy: 0.9738\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4803 - accuracy: 0.9833 - val_loss: 1.4874 - val_accuracy: 0.9763\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4801 - accuracy: 0.9834 - val_loss: 1.4866 - val_accuracy: 0.9762\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4798 - accuracy: 0.9838 - val_loss: 1.4877 - val_accuracy: 0.9752\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4793 - accuracy: 0.9840 - val_loss: 1.4859 - val_accuracy: 0.9764\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4789 - accuracy: 0.9846 - val_loss: 1.4858 - val_accuracy: 0.9765\n",
      "Epoch 29/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4786 - accuracy: 0.9850 - val_loss: 1.4853 - val_accuracy: 0.9770\n",
      "Epoch 30/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4783 - accuracy: 0.9850 - val_loss: 1.4854 - val_accuracy: 0.9770\n",
      "Epoch 31/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4780 - accuracy: 0.9853 - val_loss: 1.4861 - val_accuracy: 0.9771\n",
      "Epoch 32/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4779 - accuracy: 0.9852 - val_loss: 1.4854 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [1:03:27, 844.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5051 - accuracy: 0.9596 - val_loss: 1.4929 - val_accuracy: 0.9707\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4913 - accuracy: 0.9718 - val_loss: 1.4903 - val_accuracy: 0.9726\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4844 - accuracy: 0.9780 - val_loss: 1.4827 - val_accuracy: 0.9802\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4806 - accuracy: 0.9818 - val_loss: 1.4817 - val_accuracy: 0.9799\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4781 - accuracy: 0.9839 - val_loss: 1.4808 - val_accuracy: 0.9818\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4766 - accuracy: 0.9855 - val_loss: 1.4781 - val_accuracy: 0.9833\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4743 - accuracy: 0.9879 - val_loss: 1.4770 - val_accuracy: 0.9848\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4740 - accuracy: 0.9877 - val_loss: 1.4833 - val_accuracy: 0.9786\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4726 - accuracy: 0.9893 - val_loss: 1.4772 - val_accuracy: 0.9844\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4722 - accuracy: 0.9896 - val_loss: 1.4776 - val_accuracy: 0.9841\n",
      "current pruning ratio is0.5, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4883 - accuracy: 0.9815 - val_loss: 1.4833 - val_accuracy: 0.9824\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4769 - accuracy: 0.9870 - val_loss: 1.4788 - val_accuracy: 0.9848\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4741 - accuracy: 0.9892 - val_loss: 1.4767 - val_accuracy: 0.9865\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4719 - accuracy: 0.9911 - val_loss: 1.4766 - val_accuracy: 0.9861\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4708 - accuracy: 0.9916 - val_loss: 1.4758 - val_accuracy: 0.9870\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4702 - accuracy: 0.9923 - val_loss: 1.4737 - val_accuracy: 0.9886\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4692 - accuracy: 0.9930 - val_loss: 1.4744 - val_accuracy: 0.9878\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4682 - accuracy: 0.9940 - val_loss: 1.4743 - val_accuracy: 0.9873\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4680 - accuracy: 0.9942 - val_loss: 1.4743 - val_accuracy: 0.9879\n",
      "current pruning ratio is0.75, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5239 - accuracy: 0.9573 - val_loss: 1.4905 - val_accuracy: 0.9782\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4844 - accuracy: 0.9831 - val_loss: 1.4826 - val_accuracy: 0.9836\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4786 - accuracy: 0.9865 - val_loss: 1.4816 - val_accuracy: 0.9823\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4756 - accuracy: 0.9888 - val_loss: 1.4786 - val_accuracy: 0.9845\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4738 - accuracy: 0.9901 - val_loss: 1.4787 - val_accuracy: 0.9838\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4724 - accuracy: 0.9911 - val_loss: 1.4778 - val_accuracy: 0.9843\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4714 - accuracy: 0.9917 - val_loss: 1.4772 - val_accuracy: 0.9852\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4704 - accuracy: 0.9926 - val_loss: 1.4764 - val_accuracy: 0.9852\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4699 - accuracy: 0.9928 - val_loss: 1.4766 - val_accuracy: 0.9858\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4693 - accuracy: 0.9934 - val_loss: 1.4760 - val_accuracy: 0.9868\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4683 - accuracy: 0.9942 - val_loss: 1.4760 - val_accuracy: 0.9868\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4679 - accuracy: 0.9946 - val_loss: 1.4754 - val_accuracy: 0.9866\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4676 - accuracy: 0.9947 - val_loss: 1.4763 - val_accuracy: 0.9852\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4673 - accuracy: 0.9948 - val_loss: 1.4757 - val_accuracy: 0.9860\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4669 - accuracy: 0.9952 - val_loss: 1.4756 - val_accuracy: 0.9861\n",
      "current pruning ratio is0.875, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5526 - accuracy: 0.9396 - val_loss: 1.5047 - val_accuracy: 0.9688\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4993 - accuracy: 0.9714 - val_loss: 1.4937 - val_accuracy: 0.9754\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4902 - accuracy: 0.9775 - val_loss: 1.4876 - val_accuracy: 0.9784\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4851 - accuracy: 0.9813 - val_loss: 1.4842 - val_accuracy: 0.9815\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4820 - accuracy: 0.9833 - val_loss: 1.4819 - val_accuracy: 0.9833\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4796 - accuracy: 0.9854 - val_loss: 1.4819 - val_accuracy: 0.9822\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4777 - accuracy: 0.9870 - val_loss: 1.4809 - val_accuracy: 0.9829\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4764 - accuracy: 0.9875 - val_loss: 1.4787 - val_accuracy: 0.9845\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4751 - accuracy: 0.9890 - val_loss: 1.4795 - val_accuracy: 0.9832\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4741 - accuracy: 0.9897 - val_loss: 1.4786 - val_accuracy: 0.9846\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4732 - accuracy: 0.9905 - val_loss: 1.4775 - val_accuracy: 0.9858\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4722 - accuracy: 0.9912 - val_loss: 1.4769 - val_accuracy: 0.9864\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4718 - accuracy: 0.9914 - val_loss: 1.4776 - val_accuracy: 0.9850\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4713 - accuracy: 0.9918 - val_loss: 1.4778 - val_accuracy: 0.9852\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4705 - accuracy: 0.9928 - val_loss: 1.4775 - val_accuracy: 0.9851\n",
      "current pruning ratio is0.9375, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.7255 - accuracy: 0.7644 - val_loss: 1.5705 - val_accuracy: 0.9152\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5508 - accuracy: 0.9271 - val_loss: 1.5319 - val_accuracy: 0.9416\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5282 - accuracy: 0.9431 - val_loss: 1.5186 - val_accuracy: 0.9515\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5170 - accuracy: 0.9522 - val_loss: 1.5107 - val_accuracy: 0.9591\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5098 - accuracy: 0.9583 - val_loss: 1.5055 - val_accuracy: 0.9623\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5047 - accuracy: 0.9626 - val_loss: 1.5019 - val_accuracy: 0.9654\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5009 - accuracy: 0.9657 - val_loss: 1.4999 - val_accuracy: 0.9663\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4979 - accuracy: 0.9681 - val_loss: 1.4966 - val_accuracy: 0.9686\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4953 - accuracy: 0.9700 - val_loss: 1.4967 - val_accuracy: 0.9683\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4933 - accuracy: 0.9719 - val_loss: 1.4937 - val_accuracy: 0.9706\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4914 - accuracy: 0.9739 - val_loss: 1.4931 - val_accuracy: 0.9717\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4899 - accuracy: 0.9749 - val_loss: 1.4912 - val_accuracy: 0.9737\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4886 - accuracy: 0.9763 - val_loss: 1.4909 - val_accuracy: 0.9720\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4876 - accuracy: 0.9771 - val_loss: 1.4900 - val_accuracy: 0.9736\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4863 - accuracy: 0.9783 - val_loss: 1.4908 - val_accuracy: 0.9727\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4853 - accuracy: 0.9791 - val_loss: 1.4902 - val_accuracy: 0.9729\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 1.4846 - accuracy: 0.9797 - val_loss: 1.4903 - val_accuracy: 0.9729\n",
      "current pruning ratio is0.96875, goal ratio ist 0.96875\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7827 - accuracy: 0.7104 - val_loss: 1.6157 - val_accuracy: 0.8757\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5981 - accuracy: 0.8864 - val_loss: 1.5718 - val_accuracy: 0.9080\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5688 - accuracy: 0.9099 - val_loss: 1.5548 - val_accuracy: 0.9219\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5545 - accuracy: 0.9207 - val_loss: 1.5449 - val_accuracy: 0.9281\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5459 - accuracy: 0.9267 - val_loss: 1.5384 - val_accuracy: 0.9331\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5394 - accuracy: 0.9318 - val_loss: 1.5337 - val_accuracy: 0.9354\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5350 - accuracy: 0.9355 - val_loss: 1.5296 - val_accuracy: 0.9397\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5313 - accuracy: 0.9386 - val_loss: 1.5281 - val_accuracy: 0.9402\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5283 - accuracy: 0.9406 - val_loss: 1.5245 - val_accuracy: 0.9427\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5259 - accuracy: 0.9422 - val_loss: 1.5229 - val_accuracy: 0.9440\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5238 - accuracy: 0.9441 - val_loss: 1.5217 - val_accuracy: 0.9453\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5221 - accuracy: 0.9453 - val_loss: 1.5192 - val_accuracy: 0.9465\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5201 - accuracy: 0.9476 - val_loss: 1.5193 - val_accuracy: 0.9471\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5189 - accuracy: 0.9478 - val_loss: 1.5172 - val_accuracy: 0.9485\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5176 - accuracy: 0.9491 - val_loss: 1.5167 - val_accuracy: 0.9479\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5164 - accuracy: 0.9504 - val_loss: 1.5167 - val_accuracy: 0.9479\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5154 - accuracy: 0.9510 - val_loss: 1.5140 - val_accuracy: 0.9512\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5145 - accuracy: 0.9519 - val_loss: 1.5133 - val_accuracy: 0.9510\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5135 - accuracy: 0.9528 - val_loss: 1.5136 - val_accuracy: 0.9519\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5127 - accuracy: 0.9530 - val_loss: 1.5152 - val_accuracy: 0.9507\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5118 - accuracy: 0.9541 - val_loss: 1.5123 - val_accuracy: 0.9521\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5113 - accuracy: 0.9542 - val_loss: 1.5126 - val_accuracy: 0.9522\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5110 - accuracy: 0.9546 - val_loss: 1.5104 - val_accuracy: 0.9532\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5100 - accuracy: 0.9554 - val_loss: 1.5110 - val_accuracy: 0.9534\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5095 - accuracy: 0.9562 - val_loss: 1.5094 - val_accuracy: 0.9547\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5091 - accuracy: 0.9560 - val_loss: 1.5095 - val_accuracy: 0.9547\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5084 - accuracy: 0.9567 - val_loss: 1.5101 - val_accuracy: 0.9545\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5080 - accuracy: 0.9570 - val_loss: 1.5094 - val_accuracy: 0.9543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [1:29:08, 1053.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5045 - accuracy: 0.9599 - val_loss: 1.4962 - val_accuracy: 0.9675\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4915 - accuracy: 0.9717 - val_loss: 1.4866 - val_accuracy: 0.9760\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4848 - accuracy: 0.9778 - val_loss: 1.4823 - val_accuracy: 0.9802\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4813 - accuracy: 0.9810 - val_loss: 1.4824 - val_accuracy: 0.9805\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4783 - accuracy: 0.9840 - val_loss: 1.4815 - val_accuracy: 0.9803\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4765 - accuracy: 0.9852 - val_loss: 1.4794 - val_accuracy: 0.9831\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4752 - accuracy: 0.9868 - val_loss: 1.4781 - val_accuracy: 0.9831\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4744 - accuracy: 0.9876 - val_loss: 1.4783 - val_accuracy: 0.9831\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4727 - accuracy: 0.9891 - val_loss: 1.4776 - val_accuracy: 0.9841\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4724 - accuracy: 0.9892 - val_loss: 1.4762 - val_accuracy: 0.9853\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9908 - val_loss: 1.4764 - val_accuracy: 0.9854\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4712 - accuracy: 0.9906 - val_loss: 1.4787 - val_accuracy: 0.9832\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9912 - val_loss: 1.4760 - val_accuracy: 0.9850\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4698 - accuracy: 0.9918 - val_loss: 1.4748 - val_accuracy: 0.9871\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4690 - accuracy: 0.9926 - val_loss: 1.4783 - val_accuracy: 0.9834\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4690 - accuracy: 0.9925 - val_loss: 1.4753 - val_accuracy: 0.9860\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4679 - accuracy: 0.9936 - val_loss: 1.4751 - val_accuracy: 0.9869\n",
      "current pruning ratio is0.5, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4846 - accuracy: 0.9836 - val_loss: 1.4802 - val_accuracy: 0.9844\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4740 - accuracy: 0.9900 - val_loss: 1.4756 - val_accuracy: 0.9881\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4712 - accuracy: 0.9920 - val_loss: 1.4757 - val_accuracy: 0.9874\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4700 - accuracy: 0.9928 - val_loss: 1.4743 - val_accuracy: 0.9882\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4688 - accuracy: 0.9938 - val_loss: 1.4740 - val_accuracy: 0.9884\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4681 - accuracy: 0.9942 - val_loss: 1.4750 - val_accuracy: 0.9874\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4676 - accuracy: 0.9946 - val_loss: 1.4731 - val_accuracy: 0.9888\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4673 - accuracy: 0.9946 - val_loss: 1.4745 - val_accuracy: 0.9874\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4667 - accuracy: 0.9952 - val_loss: 1.4744 - val_accuracy: 0.9873\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4661 - accuracy: 0.9958 - val_loss: 1.4753 - val_accuracy: 0.9866\n",
      "current pruning ratio is0.75, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5117 - accuracy: 0.9674 - val_loss: 1.4868 - val_accuracy: 0.9805\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4825 - accuracy: 0.9845 - val_loss: 1.4826 - val_accuracy: 0.9820\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4778 - accuracy: 0.9877 - val_loss: 1.4792 - val_accuracy: 0.9852\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4748 - accuracy: 0.9894 - val_loss: 1.4777 - val_accuracy: 0.9852\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4731 - accuracy: 0.9903 - val_loss: 1.4770 - val_accuracy: 0.9857\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4719 - accuracy: 0.9918 - val_loss: 1.4769 - val_accuracy: 0.9860\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4707 - accuracy: 0.9928 - val_loss: 1.4755 - val_accuracy: 0.9865\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4696 - accuracy: 0.9935 - val_loss: 1.4763 - val_accuracy: 0.9855\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4691 - accuracy: 0.9937 - val_loss: 1.4742 - val_accuracy: 0.9880\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4684 - accuracy: 0.9944 - val_loss: 1.4744 - val_accuracy: 0.9880\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4679 - accuracy: 0.9945 - val_loss: 1.4742 - val_accuracy: 0.9880\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4676 - accuracy: 0.9948 - val_loss: 1.4747 - val_accuracy: 0.9879\n",
      "current pruning ratio is0.875, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5675 - accuracy: 0.9208 - val_loss: 1.5070 - val_accuracy: 0.9671\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5008 - accuracy: 0.9702 - val_loss: 1.4938 - val_accuracy: 0.9745\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4905 - accuracy: 0.9772 - val_loss: 1.4869 - val_accuracy: 0.9801\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4852 - accuracy: 0.9809 - val_loss: 1.4856 - val_accuracy: 0.9806\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4815 - accuracy: 0.9842 - val_loss: 1.4836 - val_accuracy: 0.9808\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4799 - accuracy: 0.9847 - val_loss: 1.4800 - val_accuracy: 0.9846\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4778 - accuracy: 0.9867 - val_loss: 1.4809 - val_accuracy: 0.9822\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4767 - accuracy: 0.9874 - val_loss: 1.4797 - val_accuracy: 0.9840\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4755 - accuracy: 0.9882 - val_loss: 1.4787 - val_accuracy: 0.9844\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4743 - accuracy: 0.9893 - val_loss: 1.4778 - val_accuracy: 0.9850\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4736 - accuracy: 0.9899 - val_loss: 1.4778 - val_accuracy: 0.9857\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4729 - accuracy: 0.9903 - val_loss: 1.4764 - val_accuracy: 0.9860\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4722 - accuracy: 0.9906 - val_loss: 1.4764 - val_accuracy: 0.9863\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4715 - accuracy: 0.9915 - val_loss: 1.4771 - val_accuracy: 0.9850\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4709 - accuracy: 0.9922 - val_loss: 1.4768 - val_accuracy: 0.9854\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4708 - accuracy: 0.9922 - val_loss: 1.4759 - val_accuracy: 0.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4702 - accuracy: 0.9925 - val_loss: 1.4759 - val_accuracy: 0.9866\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4698 - accuracy: 0.9929 - val_loss: 1.4761 - val_accuracy: 0.9861\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4696 - accuracy: 0.9931 - val_loss: 1.4762 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4692 - accuracy: 0.9935 - val_loss: 1.4754 - val_accuracy: 0.9867\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4689 - accuracy: 0.9937 - val_loss: 1.4752 - val_accuracy: 0.9872\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4685 - accuracy: 0.9938 - val_loss: 1.4755 - val_accuracy: 0.9868\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4683 - accuracy: 0.9942 - val_loss: 1.4764 - val_accuracy: 0.9859\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4682 - accuracy: 0.9941 - val_loss: 1.4750 - val_accuracy: 0.9867\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4678 - accuracy: 0.9944 - val_loss: 1.4752 - val_accuracy: 0.9869\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4676 - accuracy: 0.9947 - val_loss: 1.4752 - val_accuracy: 0.9865\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4675 - accuracy: 0.9947 - val_loss: 1.4761 - val_accuracy: 0.9865\n",
      "current pruning ratio is0.9375, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6497 - accuracy: 0.8375 - val_loss: 1.5421 - val_accuracy: 0.9355\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5330 - accuracy: 0.9409 - val_loss: 1.5210 - val_accuracy: 0.9522\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5180 - accuracy: 0.9527 - val_loss: 1.5103 - val_accuracy: 0.9594\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5092 - accuracy: 0.9601 - val_loss: 1.5041 - val_accuracy: 0.9646\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5037 - accuracy: 0.9645 - val_loss: 1.5000 - val_accuracy: 0.9667\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4996 - accuracy: 0.9676 - val_loss: 1.4960 - val_accuracy: 0.9698\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4965 - accuracy: 0.9702 - val_loss: 1.4946 - val_accuracy: 0.9705\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4941 - accuracy: 0.9719 - val_loss: 1.4917 - val_accuracy: 0.9725\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4922 - accuracy: 0.9735 - val_loss: 1.4913 - val_accuracy: 0.9722\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4905 - accuracy: 0.9748 - val_loss: 1.4894 - val_accuracy: 0.9747\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4891 - accuracy: 0.9761 - val_loss: 1.4896 - val_accuracy: 0.9747\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4878 - accuracy: 0.9772 - val_loss: 1.4886 - val_accuracy: 0.9749\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4870 - accuracy: 0.9776 - val_loss: 1.4876 - val_accuracy: 0.9755\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4856 - accuracy: 0.9792 - val_loss: 1.4864 - val_accuracy: 0.9778\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4848 - accuracy: 0.9798 - val_loss: 1.4856 - val_accuracy: 0.9784\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4841 - accuracy: 0.9802 - val_loss: 1.4859 - val_accuracy: 0.9772\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4831 - accuracy: 0.9812 - val_loss: 1.4860 - val_accuracy: 0.9775\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4825 - accuracy: 0.9817 - val_loss: 1.4865 - val_accuracy: 0.9759\n",
      "current pruning ratio is0.96875, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.9178 - accuracy: 0.5815 - val_loss: 1.7370 - val_accuracy: 0.7720\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7052 - accuracy: 0.7944 - val_loss: 1.6770 - val_accuracy: 0.8130\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6682 - accuracy: 0.8157 - val_loss: 1.6536 - val_accuracy: 0.8273\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6516 - accuracy: 0.8253 - val_loss: 1.6407 - val_accuracy: 0.8348\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6415 - accuracy: 0.8316 - val_loss: 1.6330 - val_accuracy: 0.8399\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6343 - accuracy: 0.8365 - val_loss: 1.6271 - val_accuracy: 0.8425\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6287 - accuracy: 0.8406 - val_loss: 1.6239 - val_accuracy: 0.8455\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6244 - accuracy: 0.8436 - val_loss: 1.6195 - val_accuracy: 0.8469\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6206 - accuracy: 0.8464 - val_loss: 1.6172 - val_accuracy: 0.8491\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6174 - accuracy: 0.8502 - val_loss: 1.6146 - val_accuracy: 0.8506\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6149 - accuracy: 0.8514 - val_loss: 1.6136 - val_accuracy: 0.8510\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6126 - accuracy: 0.8535 - val_loss: 1.6123 - val_accuracy: 0.8535\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6109 - accuracy: 0.8546 - val_loss: 1.6100 - val_accuracy: 0.8549\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6094 - accuracy: 0.8561 - val_loss: 1.6095 - val_accuracy: 0.8556\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6080 - accuracy: 0.8571 - val_loss: 1.6078 - val_accuracy: 0.8566\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6071 - accuracy: 0.8576 - val_loss: 1.6070 - val_accuracy: 0.8579\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6064 - accuracy: 0.8581 - val_loss: 1.6058 - val_accuracy: 0.8583\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6052 - accuracy: 0.8591 - val_loss: 1.6063 - val_accuracy: 0.8578\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6041 - accuracy: 0.8604 - val_loss: 1.6050 - val_accuracy: 0.8581\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6037 - accuracy: 0.8604 - val_loss: 1.6045 - val_accuracy: 0.8588\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6029 - accuracy: 0.8614 - val_loss: 1.6037 - val_accuracy: 0.8593\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6024 - accuracy: 0.8615 - val_loss: 1.6047 - val_accuracy: 0.8587\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6017 - accuracy: 0.8622 - val_loss: 1.6040 - val_accuracy: 0.8589\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6011 - accuracy: 0.8626 - val_loss: 1.6028 - val_accuracy: 0.8603\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5822 - accuracy: 0.8839 - val_loss: 1.5337 - val_accuracy: 0.9349\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5295 - accuracy: 0.9390 - val_loss: 1.5253 - val_accuracy: 0.9428\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5253 - accuracy: 0.9425 - val_loss: 1.5235 - val_accuracy: 0.9440\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5230 - accuracy: 0.9442 - val_loss: 1.5214 - val_accuracy: 0.9451\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5212 - accuracy: 0.9459 - val_loss: 1.5206 - val_accuracy: 0.9448\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5199 - accuracy: 0.9468 - val_loss: 1.5194 - val_accuracy: 0.9464\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5189 - accuracy: 0.9479 - val_loss: 1.5184 - val_accuracy: 0.9472\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5178 - accuracy: 0.9486 - val_loss: 1.5191 - val_accuracy: 0.9464\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5169 - accuracy: 0.9492 - val_loss: 1.5197 - val_accuracy: 0.9467\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5164 - accuracy: 0.9498 - val_loss: 1.5179 - val_accuracy: 0.9481\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5155 - accuracy: 0.9508 - val_loss: 1.5176 - val_accuracy: 0.9479\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5149 - accuracy: 0.9511 - val_loss: 1.5174 - val_accuracy: 0.9481\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5145 - accuracy: 0.9518 - val_loss: 1.5168 - val_accuracy: 0.9476\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5138 - accuracy: 0.9523 - val_loss: 1.5164 - val_accuracy: 0.9485\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5135 - accuracy: 0.9521 - val_loss: 1.5153 - val_accuracy: 0.9497\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5130 - accuracy: 0.9527 - val_loss: 1.5145 - val_accuracy: 0.9493\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5129 - accuracy: 0.9525 - val_loss: 1.5137 - val_accuracy: 0.9514\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5123 - accuracy: 0.9531 - val_loss: 1.5147 - val_accuracy: 0.9492\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5119 - accuracy: 0.9536 - val_loss: 1.5139 - val_accuracy: 0.9504\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5116 - accuracy: 0.9535 - val_loss: 1.5151 - val_accuracy: 0.9489\n",
      "current pruning ratio is0.984375, goal ratio ist 0.984375\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.9958 - accuracy: 0.4794 - val_loss: 1.8850 - val_accuracy: 0.5933\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8753 - accuracy: 0.5968 - val_loss: 1.8498 - val_accuracy: 0.6191\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8518 - accuracy: 0.6168 - val_loss: 1.8350 - val_accuracy: 0.6316\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8392 - accuracy: 0.6286 - val_loss: 1.8260 - val_accuracy: 0.6408\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8299 - accuracy: 0.6385 - val_loss: 1.8176 - val_accuracy: 0.6514\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8214 - accuracy: 0.6485 - val_loss: 1.8103 - val_accuracy: 0.6608\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.8138 - accuracy: 0.6581 - val_loss: 1.8024 - val_accuracy: 0.6700\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8068 - accuracy: 0.6672 - val_loss: 1.7964 - val_accuracy: 0.6759\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8008 - accuracy: 0.6727 - val_loss: 1.7929 - val_accuracy: 0.6784\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7963 - accuracy: 0.6767 - val_loss: 1.7881 - val_accuracy: 0.6834\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7925 - accuracy: 0.6804 - val_loss: 1.7842 - val_accuracy: 0.6856\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7893 - accuracy: 0.6832 - val_loss: 1.7812 - val_accuracy: 0.6895\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7866 - accuracy: 0.6854 - val_loss: 1.7789 - val_accuracy: 0.6912\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7842 - accuracy: 0.6868 - val_loss: 1.7778 - val_accuracy: 0.6903\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7824 - accuracy: 0.6871 - val_loss: 1.7758 - val_accuracy: 0.6936\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7806 - accuracy: 0.6889 - val_loss: 1.7725 - val_accuracy: 0.6967\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7791 - accuracy: 0.6899 - val_loss: 1.7715 - val_accuracy: 0.6967\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7778 - accuracy: 0.6904 - val_loss: 1.7713 - val_accuracy: 0.6967\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.7764 - accuracy: 0.6916 - val_loss: 1.7690 - val_accuracy: 0.6985\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7752 - accuracy: 0.6927 - val_loss: 1.7700 - val_accuracy: 0.6970\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7742 - accuracy: 0.6930 - val_loss: 1.7681 - val_accuracy: 0.6987\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7729 - accuracy: 0.6942 - val_loss: 1.7657 - val_accuracy: 0.7013\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7717 - accuracy: 0.6948 - val_loss: 1.7648 - val_accuracy: 0.7020\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7711 - accuracy: 0.6953 - val_loss: 1.7634 - val_accuracy: 0.7047\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7700 - accuracy: 0.6965 - val_loss: 1.7628 - val_accuracy: 0.7040\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7691 - accuracy: 0.6976 - val_loss: 1.7614 - val_accuracy: 0.7057\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7685 - accuracy: 0.6972 - val_loss: 1.7616 - val_accuracy: 0.7044\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7677 - accuracy: 0.6984 - val_loss: 1.7622 - val_accuracy: 0.7041\n",
      "Epoch 29/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7673 - accuracy: 0.6986 - val_loss: 1.7603 - val_accuracy: 0.7047\n",
      "Epoch 30/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7664 - accuracy: 0.6992 - val_loss: 1.7599 - val_accuracy: 0.7059\n",
      "Epoch 31/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7658 - accuracy: 0.6996 - val_loss: 1.7590 - val_accuracy: 0.7077\n",
      "Epoch 32/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7654 - accuracy: 0.7003 - val_loss: 1.7576 - val_accuracy: 0.7073\n",
      "Epoch 33/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7647 - accuracy: 0.7010 - val_loss: 1.7567 - val_accuracy: 0.7091\n",
      "Epoch 34/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7641 - accuracy: 0.7014 - val_loss: 1.7580 - val_accuracy: 0.7069\n",
      "Epoch 35/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7636 - accuracy: 0.7019 - val_loss: 1.7571 - val_accuracy: 0.7075\n",
      "Epoch 36/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7631 - accuracy: 0.7013 - val_loss: 1.7555 - val_accuracy: 0.7089\n",
      "Epoch 37/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7623 - accuracy: 0.7029 - val_loss: 1.7548 - val_accuracy: 0.7106\n",
      "Epoch 38/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7614 - accuracy: 0.7040 - val_loss: 1.7550 - val_accuracy: 0.7102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7607 - accuracy: 0.7040 - val_loss: 1.7539 - val_accuracy: 0.7109\n",
      "Epoch 40/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7597 - accuracy: 0.7050 - val_loss: 1.7544 - val_accuracy: 0.7096\n",
      "Epoch 41/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7591 - accuracy: 0.7053 - val_loss: 1.7523 - val_accuracy: 0.7130\n",
      "Epoch 42/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7580 - accuracy: 0.7069 - val_loss: 1.7498 - val_accuracy: 0.7154\n",
      "Epoch 43/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7572 - accuracy: 0.7075 - val_loss: 1.7515 - val_accuracy: 0.7137\n",
      "Epoch 44/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7565 - accuracy: 0.7084 - val_loss: 1.7508 - val_accuracy: 0.7148\n",
      "Epoch 45/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7559 - accuracy: 0.7089 - val_loss: 1.7484 - val_accuracy: 0.7158\n",
      "Epoch 46/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7556 - accuracy: 0.7088 - val_loss: 1.7478 - val_accuracy: 0.7170\n",
      "Epoch 47/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7547 - accuracy: 0.7100 - val_loss: 1.7484 - val_accuracy: 0.7151\n",
      "Epoch 48/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7544 - accuracy: 0.7099 - val_loss: 1.7486 - val_accuracy: 0.7159\n",
      "Epoch 49/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7537 - accuracy: 0.7108 - val_loss: 1.7469 - val_accuracy: 0.7171\n",
      "Epoch 50/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7532 - accuracy: 0.7111 - val_loss: 1.7484 - val_accuracy: 0.7146\n",
      "Epoch 51/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7531 - accuracy: 0.7111 - val_loss: 1.7460 - val_accuracy: 0.7173\n",
      "Epoch 52/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7527 - accuracy: 0.7110 - val_loss: 1.7455 - val_accuracy: 0.7177\n",
      "Epoch 53/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7523 - accuracy: 0.7120 - val_loss: 1.7453 - val_accuracy: 0.7186\n",
      "Epoch 54/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7521 - accuracy: 0.7111 - val_loss: 1.7452 - val_accuracy: 0.7191\n",
      "Epoch 55/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7517 - accuracy: 0.7121 - val_loss: 1.7442 - val_accuracy: 0.7192\n",
      "Epoch 56/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7513 - accuracy: 0.7124 - val_loss: 1.7471 - val_accuracy: 0.7152\n",
      "Epoch 57/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.7510 - accuracy: 0.7127 - val_loss: 1.7459 - val_accuracy: 0.7175\n",
      "Epoch 58/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7508 - accuracy: 0.7128 - val_loss: 1.7448 - val_accuracy: 0.7185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [2:19:50, 1198.60s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [4:46:40<2:24:37, 8677.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5965 - accuracy: 0.8867 - val_loss: 1.5222 - val_accuracy: 0.9436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.0\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5049 - accuracy: 0.9590 - val_loss: 1.4937 - val_accuracy: 0.9697\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4921 - accuracy: 0.9709 - val_loss: 1.4863 - val_accuracy: 0.9771\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4856 - accuracy: 0.9772 - val_loss: 1.4838 - val_accuracy: 0.9791\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4821 - accuracy: 0.9803 - val_loss: 1.4825 - val_accuracy: 0.9797\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4791 - accuracy: 0.9830 - val_loss: 1.4805 - val_accuracy: 0.9818\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4776 - accuracy: 0.9845 - val_loss: 1.4802 - val_accuracy: 0.9814\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4758 - accuracy: 0.9860 - val_loss: 1.4800 - val_accuracy: 0.9814\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4739 - accuracy: 0.9880 - val_loss: 1.4801 - val_accuracy: 0.9814\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4730 - accuracy: 0.9886 - val_loss: 1.4787 - val_accuracy: 0.9827\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4727 - accuracy: 0.9890 - val_loss: 1.4772 - val_accuracy: 0.9842\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4719 - accuracy: 0.9899 - val_loss: 1.4761 - val_accuracy: 0.9855\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9907 - val_loss: 1.4770 - val_accuracy: 0.9842\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4704 - accuracy: 0.9911 - val_loss: 1.4764 - val_accuracy: 0.9848\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4702 - accuracy: 0.9913 - val_loss: 1.4775 - val_accuracy: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [03:58, 238.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.5\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5046 - accuracy: 0.9596 - val_loss: 1.4954 - val_accuracy: 0.9679\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4922 - accuracy: 0.9710 - val_loss: 1.4892 - val_accuracy: 0.9739\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4860 - accuracy: 0.9768 - val_loss: 1.4829 - val_accuracy: 0.9794\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4820 - accuracy: 0.9803 - val_loss: 1.4817 - val_accuracy: 0.9801\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4796 - accuracy: 0.9825 - val_loss: 1.4827 - val_accuracy: 0.9794\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4774 - accuracy: 0.9844 - val_loss: 1.4788 - val_accuracy: 0.9830\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4762 - accuracy: 0.9856 - val_loss: 1.4795 - val_accuracy: 0.9818\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4744 - accuracy: 0.9875 - val_loss: 1.4784 - val_accuracy: 0.9835\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4732 - accuracy: 0.9886 - val_loss: 1.4773 - val_accuracy: 0.9840\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4727 - accuracy: 0.9889 - val_loss: 1.4773 - val_accuracy: 0.9844\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4721 - accuracy: 0.9894 - val_loss: 1.4763 - val_accuracy: 0.9850\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4717 - accuracy: 0.9898 - val_loss: 1.4773 - val_accuracy: 0.9846\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4703 - accuracy: 0.9913 - val_loss: 1.4774 - val_accuracy: 0.9838\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4700 - accuracy: 0.9916 - val_loss: 1.4754 - val_accuracy: 0.9859\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4702 - accuracy: 0.9912 - val_loss: 1.4754 - val_accuracy: 0.9857\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4694 - accuracy: 0.9922 - val_loss: 1.4763 - val_accuracy: 0.9853\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4692 - accuracy: 0.9924 - val_loss: 1.4761 - val_accuracy: 0.9855\n",
      "current pruning ratio is0.5, goal ratio ist 0.5\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4838 - accuracy: 0.9834 - val_loss: 1.4790 - val_accuracy: 0.9850\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4742 - accuracy: 0.9900 - val_loss: 1.4756 - val_accuracy: 0.9882\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9912 - val_loss: 1.4763 - val_accuracy: 0.9867\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4699 - accuracy: 0.9929 - val_loss: 1.4741 - val_accuracy: 0.9884\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4691 - accuracy: 0.9934 - val_loss: 1.4762 - val_accuracy: 0.9857\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4682 - accuracy: 0.9941 - val_loss: 1.4740 - val_accuracy: 0.9886\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4678 - accuracy: 0.9945 - val_loss: 1.4753 - val_accuracy: 0.9864\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4671 - accuracy: 0.9951 - val_loss: 1.4741 - val_accuracy: 0.9880\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4668 - accuracy: 0.9953 - val_loss: 1.4743 - val_accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [11:14, 297.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.75\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5053 - accuracy: 0.9593 - val_loss: 1.4973 - val_accuracy: 0.9654\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4924 - accuracy: 0.9710 - val_loss: 1.4883 - val_accuracy: 0.9748\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4861 - accuracy: 0.9767 - val_loss: 1.4853 - val_accuracy: 0.9778\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4821 - accuracy: 0.9801 - val_loss: 1.4819 - val_accuracy: 0.9797\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4797 - accuracy: 0.9826 - val_loss: 1.4809 - val_accuracy: 0.9816\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4778 - accuracy: 0.9844 - val_loss: 1.4797 - val_accuracy: 0.9817\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4758 - accuracy: 0.9863 - val_loss: 1.4768 - val_accuracy: 0.9847\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4746 - accuracy: 0.9874 - val_loss: 1.4765 - val_accuracy: 0.9846\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4735 - accuracy: 0.9883 - val_loss: 1.4773 - val_accuracy: 0.9845\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4727 - accuracy: 0.9891 - val_loss: 1.4776 - val_accuracy: 0.9841\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9898 - val_loss: 1.4775 - val_accuracy: 0.9834\n",
      "current pruning ratio is0.5, goal ratio ist 0.75\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4932 - accuracy: 0.9771 - val_loss: 1.4832 - val_accuracy: 0.9825\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4776 - accuracy: 0.9870 - val_loss: 1.4783 - val_accuracy: 0.9860\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4743 - accuracy: 0.9893 - val_loss: 1.4754 - val_accuracy: 0.9876\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4723 - accuracy: 0.9906 - val_loss: 1.4765 - val_accuracy: 0.9854\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9915 - val_loss: 1.4767 - val_accuracy: 0.9860\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4703 - accuracy: 0.9921 - val_loss: 1.4760 - val_accuracy: 0.9863\n",
      "current pruning ratio is0.75, goal ratio ist 0.75\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5136 - accuracy: 0.9701 - val_loss: 1.4886 - val_accuracy: 0.9801\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4845 - accuracy: 0.9825 - val_loss: 1.4813 - val_accuracy: 0.9842\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4795 - accuracy: 0.9855 - val_loss: 1.4789 - val_accuracy: 0.9852\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4769 - accuracy: 0.9872 - val_loss: 1.4787 - val_accuracy: 0.9839\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4746 - accuracy: 0.9894 - val_loss: 1.4770 - val_accuracy: 0.9859\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4730 - accuracy: 0.9902 - val_loss: 1.4764 - val_accuracy: 0.9862\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4722 - accuracy: 0.9910 - val_loss: 1.4774 - val_accuracy: 0.9851\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4708 - accuracy: 0.9921 - val_loss: 1.4764 - val_accuracy: 0.9868\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4702 - accuracy: 0.9926 - val_loss: 1.4742 - val_accuracy: 0.9879\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4695 - accuracy: 0.9932 - val_loss: 1.4753 - val_accuracy: 0.9870\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4691 - accuracy: 0.9934 - val_loss: 1.4744 - val_accuracy: 0.9881\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4685 - accuracy: 0.9938 - val_loss: 1.4752 - val_accuracy: 0.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [19:17, 353.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5051 - accuracy: 0.9595 - val_loss: 1.4958 - val_accuracy: 0.9668\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4919 - accuracy: 0.9711 - val_loss: 1.4874 - val_accuracy: 0.9753\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4859 - accuracy: 0.9766 - val_loss: 1.4867 - val_accuracy: 0.9756\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4819 - accuracy: 0.9805 - val_loss: 1.4813 - val_accuracy: 0.9804\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4794 - accuracy: 0.9828 - val_loss: 1.4809 - val_accuracy: 0.9802\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4780 - accuracy: 0.9840 - val_loss: 1.4783 - val_accuracy: 0.9839\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4759 - accuracy: 0.9860 - val_loss: 1.4793 - val_accuracy: 0.9825\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4745 - accuracy: 0.9873 - val_loss: 1.4792 - val_accuracy: 0.9828\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4739 - accuracy: 0.9879 - val_loss: 1.4768 - val_accuracy: 0.9847\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4727 - accuracy: 0.9890 - val_loss: 1.4758 - val_accuracy: 0.9859\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4719 - accuracy: 0.9898 - val_loss: 1.4780 - val_accuracy: 0.9840\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4717 - accuracy: 0.9900 - val_loss: 1.4814 - val_accuracy: 0.9794\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4709 - accuracy: 0.9906 - val_loss: 1.4758 - val_accuracy: 0.9851\n",
      "current pruning ratio is0.5, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4849 - accuracy: 0.9833 - val_loss: 1.4796 - val_accuracy: 0.9840\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4748 - accuracy: 0.9894 - val_loss: 1.4773 - val_accuracy: 0.9847\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4724 - accuracy: 0.9909 - val_loss: 1.4762 - val_accuracy: 0.9860\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9919 - val_loss: 1.4755 - val_accuracy: 0.9866\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4697 - accuracy: 0.9927 - val_loss: 1.4742 - val_accuracy: 0.9883\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4691 - accuracy: 0.9932 - val_loss: 1.4743 - val_accuracy: 0.9882\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4685 - accuracy: 0.9938 - val_loss: 1.4788 - val_accuracy: 0.9839\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4676 - accuracy: 0.9945 - val_loss: 1.4740 - val_accuracy: 0.9881\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4677 - accuracy: 0.9944 - val_loss: 1.4742 - val_accuracy: 0.9877\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4671 - accuracy: 0.9948 - val_loss: 1.4737 - val_accuracy: 0.9879\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4668 - accuracy: 0.9950 - val_loss: 1.4748 - val_accuracy: 0.9867\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4665 - accuracy: 0.9953 - val_loss: 1.4761 - val_accuracy: 0.9855\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4663 - accuracy: 0.9953 - val_loss: 1.4748 - val_accuracy: 0.9865\n",
      "current pruning ratio is0.75, goal ratio ist 0.875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5115 - accuracy: 0.9681 - val_loss: 1.4862 - val_accuracy: 0.9813\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4829 - accuracy: 0.9842 - val_loss: 1.4821 - val_accuracy: 0.9837\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4775 - accuracy: 0.9877 - val_loss: 1.4775 - val_accuracy: 0.9872\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4748 - accuracy: 0.9898 - val_loss: 1.4795 - val_accuracy: 0.9837\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4729 - accuracy: 0.9910 - val_loss: 1.4746 - val_accuracy: 0.9882\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9917 - val_loss: 1.4756 - val_accuracy: 0.9877\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4706 - accuracy: 0.9926 - val_loss: 1.4745 - val_accuracy: 0.9882\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4698 - accuracy: 0.9931 - val_loss: 1.4732 - val_accuracy: 0.9888\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4692 - accuracy: 0.9933 - val_loss: 1.4745 - val_accuracy: 0.9878\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4686 - accuracy: 0.9939 - val_loss: 1.4741 - val_accuracy: 0.9878\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4680 - accuracy: 0.9945 - val_loss: 1.4735 - val_accuracy: 0.9893\n",
      "current pruning ratio is0.875, goal ratio ist 0.875\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5837 - accuracy: 0.9024 - val_loss: 1.5082 - val_accuracy: 0.9670\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5010 - accuracy: 0.9699 - val_loss: 1.4929 - val_accuracy: 0.9758\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4908 - accuracy: 0.9768 - val_loss: 1.4883 - val_accuracy: 0.9778\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4856 - accuracy: 0.9806 - val_loss: 1.4865 - val_accuracy: 0.9783\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4825 - accuracy: 0.9831 - val_loss: 1.4845 - val_accuracy: 0.9794\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4801 - accuracy: 0.9850 - val_loss: 1.4820 - val_accuracy: 0.9821\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4784 - accuracy: 0.9863 - val_loss: 1.4804 - val_accuracy: 0.9828\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4769 - accuracy: 0.9872 - val_loss: 1.4802 - val_accuracy: 0.9833\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4757 - accuracy: 0.9882 - val_loss: 1.4796 - val_accuracy: 0.9833\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4750 - accuracy: 0.9887 - val_loss: 1.4786 - val_accuracy: 0.9847\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4739 - accuracy: 0.9894 - val_loss: 1.4780 - val_accuracy: 0.9855\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4731 - accuracy: 0.9904 - val_loss: 1.4774 - val_accuracy: 0.9855\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4725 - accuracy: 0.9907 - val_loss: 1.4769 - val_accuracy: 0.9865\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4720 - accuracy: 0.9912 - val_loss: 1.4779 - val_accuracy: 0.9855\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4714 - accuracy: 0.9916 - val_loss: 1.4776 - val_accuracy: 0.9853\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4711 - accuracy: 0.9916 - val_loss: 1.4767 - val_accuracy: 0.9860\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4707 - accuracy: 0.9920 - val_loss: 1.4768 - val_accuracy: 0.9853\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4701 - accuracy: 0.9927 - val_loss: 1.4781 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4697 - accuracy: 0.9928 - val_loss: 1.4775 - val_accuracy: 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [34:43, 525.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5050 - accuracy: 0.9597 - val_loss: 1.4945 - val_accuracy: 0.9695\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4912 - accuracy: 0.9721 - val_loss: 1.4886 - val_accuracy: 0.9741\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4859 - accuracy: 0.9769 - val_loss: 1.4832 - val_accuracy: 0.9797\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4816 - accuracy: 0.9806 - val_loss: 1.4873 - val_accuracy: 0.9742\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4799 - accuracy: 0.9822 - val_loss: 1.4799 - val_accuracy: 0.9817\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4778 - accuracy: 0.9843 - val_loss: 1.4812 - val_accuracy: 0.9802\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4755 - accuracy: 0.9862 - val_loss: 1.4778 - val_accuracy: 0.9844\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4746 - accuracy: 0.9872 - val_loss: 1.4776 - val_accuracy: 0.9836\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4736 - accuracy: 0.9880 - val_loss: 1.4776 - val_accuracy: 0.9838\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4727 - accuracy: 0.9890 - val_loss: 1.4787 - val_accuracy: 0.9826\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4721 - accuracy: 0.9896 - val_loss: 1.4775 - val_accuracy: 0.9838\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4713 - accuracy: 0.9904 - val_loss: 1.4767 - val_accuracy: 0.9847\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9913 - val_loss: 1.4767 - val_accuracy: 0.9846\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4702 - accuracy: 0.9915 - val_loss: 1.4756 - val_accuracy: 0.9854\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4701 - accuracy: 0.9915 - val_loss: 1.4756 - val_accuracy: 0.9857\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4695 - accuracy: 0.9921 - val_loss: 1.4747 - val_accuracy: 0.9865\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4691 - accuracy: 0.9924 - val_loss: 1.4754 - val_accuracy: 0.9859\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4686 - accuracy: 0.9928 - val_loss: 1.4746 - val_accuracy: 0.9868\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4682 - accuracy: 0.9934 - val_loss: 1.4750 - val_accuracy: 0.9864\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4681 - accuracy: 0.9934 - val_loss: 1.4751 - val_accuracy: 0.9863\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4673 - accuracy: 0.9942 - val_loss: 1.4758 - val_accuracy: 0.9856\n",
      "current pruning ratio is0.5, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4809 - accuracy: 0.9859 - val_loss: 1.4782 - val_accuracy: 0.9864\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4728 - accuracy: 0.9908 - val_loss: 1.4767 - val_accuracy: 0.9858\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4704 - accuracy: 0.9924 - val_loss: 1.4740 - val_accuracy: 0.9879\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4693 - accuracy: 0.9932 - val_loss: 1.4743 - val_accuracy: 0.9880\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4684 - accuracy: 0.9941 - val_loss: 1.4748 - val_accuracy: 0.9875\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4678 - accuracy: 0.9945 - val_loss: 1.4735 - val_accuracy: 0.9877\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4672 - accuracy: 0.9948 - val_loss: 1.4726 - val_accuracy: 0.9898\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4668 - accuracy: 0.9953 - val_loss: 1.4736 - val_accuracy: 0.9882\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4662 - accuracy: 0.9959 - val_loss: 1.4717 - val_accuracy: 0.9898\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4661 - accuracy: 0.9957 - val_loss: 1.4736 - val_accuracy: 0.9878\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4659 - accuracy: 0.9959 - val_loss: 1.4747 - val_accuracy: 0.9869\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4653 - accuracy: 0.9965 - val_loss: 1.4736 - val_accuracy: 0.9883\n",
      "current pruning ratio is0.75, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5291 - accuracy: 0.9517 - val_loss: 1.4909 - val_accuracy: 0.9767\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4849 - accuracy: 0.9823 - val_loss: 1.4833 - val_accuracy: 0.9820\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4787 - accuracy: 0.9866 - val_loss: 1.4794 - val_accuracy: 0.9843\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4757 - accuracy: 0.9890 - val_loss: 1.4778 - val_accuracy: 0.9853\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4735 - accuracy: 0.9904 - val_loss: 1.4776 - val_accuracy: 0.9848\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4719 - accuracy: 0.9915 - val_loss: 1.4752 - val_accuracy: 0.9871\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4708 - accuracy: 0.9923 - val_loss: 1.4765 - val_accuracy: 0.9861\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4700 - accuracy: 0.9928 - val_loss: 1.4750 - val_accuracy: 0.9878\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4690 - accuracy: 0.9938 - val_loss: 1.4764 - val_accuracy: 0.9866\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4685 - accuracy: 0.9939 - val_loss: 1.4756 - val_accuracy: 0.9865\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4683 - accuracy: 0.9942 - val_loss: 1.4751 - val_accuracy: 0.9867\n",
      "current pruning ratio is0.875, goal ratio ist 0.9375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5918 - accuracy: 0.9006 - val_loss: 1.5133 - val_accuracy: 0.9623\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5057 - accuracy: 0.9663 - val_loss: 1.4972 - val_accuracy: 0.9724\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4942 - accuracy: 0.9743 - val_loss: 1.4899 - val_accuracy: 0.9770\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4880 - accuracy: 0.9789 - val_loss: 1.4867 - val_accuracy: 0.9786\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4845 - accuracy: 0.9813 - val_loss: 1.4850 - val_accuracy: 0.9791\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4816 - accuracy: 0.9837 - val_loss: 1.4835 - val_accuracy: 0.9811\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4796 - accuracy: 0.9851 - val_loss: 1.4825 - val_accuracy: 0.9814\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.4783 - accuracy: 0.9862 - val_loss: 1.4811 - val_accuracy: 0.9825\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.4769 - accuracy: 0.9869 - val_loss: 1.4800 - val_accuracy: 0.9829\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4758 - accuracy: 0.9880 - val_loss: 1.4798 - val_accuracy: 0.9844\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4747 - accuracy: 0.9890 - val_loss: 1.4788 - val_accuracy: 0.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4741 - accuracy: 0.9895 - val_loss: 1.4787 - val_accuracy: 0.9835\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4731 - accuracy: 0.9905 - val_loss: 1.4776 - val_accuracy: 0.9850\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4724 - accuracy: 0.9908 - val_loss: 1.4789 - val_accuracy: 0.9847\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4720 - accuracy: 0.9913 - val_loss: 1.4782 - val_accuracy: 0.9843\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4717 - accuracy: 0.9913 - val_loss: 1.4770 - val_accuracy: 0.9863\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4710 - accuracy: 0.9921 - val_loss: 1.4769 - val_accuracy: 0.9857\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4706 - accuracy: 0.9925 - val_loss: 1.4770 - val_accuracy: 0.9855\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4700 - accuracy: 0.9930 - val_loss: 1.4768 - val_accuracy: 0.9860\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4698 - accuracy: 0.9930 - val_loss: 1.4762 - val_accuracy: 0.9864\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4696 - accuracy: 0.9931 - val_loss: 1.4754 - val_accuracy: 0.9869\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4692 - accuracy: 0.9934 - val_loss: 1.4756 - val_accuracy: 0.9872\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4688 - accuracy: 0.9937 - val_loss: 1.4754 - val_accuracy: 0.9869\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4684 - accuracy: 0.9941 - val_loss: 1.4755 - val_accuracy: 0.9869\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4682 - accuracy: 0.9942 - val_loss: 1.4757 - val_accuracy: 0.9867\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4680 - accuracy: 0.9945 - val_loss: 1.4761 - val_accuracy: 0.9864\n",
      "current pruning ratio is0.9375, goal ratio ist 0.9375\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6761 - accuracy: 0.8135 - val_loss: 1.5564 - val_accuracy: 0.9232\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5453 - accuracy: 0.9294 - val_loss: 1.5324 - val_accuracy: 0.9397\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5294 - accuracy: 0.9410 - val_loss: 1.5221 - val_accuracy: 0.9487\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5204 - accuracy: 0.9487 - val_loss: 1.5156 - val_accuracy: 0.9528\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5142 - accuracy: 0.9540 - val_loss: 1.5109 - val_accuracy: 0.9572\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5092 - accuracy: 0.9584 - val_loss: 1.5062 - val_accuracy: 0.9615\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5054 - accuracy: 0.9617 - val_loss: 1.5036 - val_accuracy: 0.9635\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5021 - accuracy: 0.9645 - val_loss: 1.5006 - val_accuracy: 0.9652\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4991 - accuracy: 0.9676 - val_loss: 1.4989 - val_accuracy: 0.9671\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4970 - accuracy: 0.9693 - val_loss: 1.4975 - val_accuracy: 0.9690\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4950 - accuracy: 0.9709 - val_loss: 1.4949 - val_accuracy: 0.9707\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4932 - accuracy: 0.9725 - val_loss: 1.4938 - val_accuracy: 0.9704\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4921 - accuracy: 0.9733 - val_loss: 1.4925 - val_accuracy: 0.9718\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4905 - accuracy: 0.9749 - val_loss: 1.4923 - val_accuracy: 0.9717\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4895 - accuracy: 0.9755 - val_loss: 1.4902 - val_accuracy: 0.9735\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4883 - accuracy: 0.9765 - val_loss: 1.4902 - val_accuracy: 0.9740\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4874 - accuracy: 0.9774 - val_loss: 1.4894 - val_accuracy: 0.9742\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4864 - accuracy: 0.9783 - val_loss: 1.4894 - val_accuracy: 0.9749\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4854 - accuracy: 0.9790 - val_loss: 1.4889 - val_accuracy: 0.9745\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4850 - accuracy: 0.9791 - val_loss: 1.4877 - val_accuracy: 0.9755\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4840 - accuracy: 0.9803 - val_loss: 1.4876 - val_accuracy: 0.9754\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4837 - accuracy: 0.9803 - val_loss: 1.4870 - val_accuracy: 0.9774\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4829 - accuracy: 0.9813 - val_loss: 1.4862 - val_accuracy: 0.9771\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4826 - accuracy: 0.9815 - val_loss: 1.4860 - val_accuracy: 0.9769\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4817 - accuracy: 0.9825 - val_loss: 1.4859 - val_accuracy: 0.9775\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4812 - accuracy: 0.9828 - val_loss: 1.4865 - val_accuracy: 0.9764\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4808 - accuracy: 0.9832 - val_loss: 1.4857 - val_accuracy: 0.9772\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4803 - accuracy: 0.9835 - val_loss: 1.4852 - val_accuracy: 0.9782\n",
      "Epoch 29/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4800 - accuracy: 0.9839 - val_loss: 1.4842 - val_accuracy: 0.9782\n",
      "Epoch 30/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4796 - accuracy: 0.9842 - val_loss: 1.4846 - val_accuracy: 0.9788\n",
      "Epoch 31/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4789 - accuracy: 0.9848 - val_loss: 1.4841 - val_accuracy: 0.9791\n",
      "Epoch 32/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4788 - accuracy: 0.9851 - val_loss: 1.4854 - val_accuracy: 0.9774\n",
      "Epoch 33/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4786 - accuracy: 0.9851 - val_loss: 1.4844 - val_accuracy: 0.9788\n",
      "Epoch 34/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4782 - accuracy: 0.9857 - val_loss: 1.4860 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [1:03:24, 883.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5052 - accuracy: 0.9591 - val_loss: 1.4949 - val_accuracy: 0.9688\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4916 - accuracy: 0.9716 - val_loss: 1.4886 - val_accuracy: 0.9738\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4861 - accuracy: 0.9763 - val_loss: 1.4851 - val_accuracy: 0.9772\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4818 - accuracy: 0.9808 - val_loss: 1.4835 - val_accuracy: 0.9785\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4794 - accuracy: 0.9825 - val_loss: 1.4819 - val_accuracy: 0.9799\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4772 - accuracy: 0.9851 - val_loss: 1.4817 - val_accuracy: 0.9807\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4759 - accuracy: 0.9862 - val_loss: 1.4783 - val_accuracy: 0.9835\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4739 - accuracy: 0.9880 - val_loss: 1.4802 - val_accuracy: 0.9814\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4731 - accuracy: 0.9887 - val_loss: 1.4776 - val_accuracy: 0.9839\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4721 - accuracy: 0.9898 - val_loss: 1.4785 - val_accuracy: 0.9834\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9900 - val_loss: 1.4770 - val_accuracy: 0.9844\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4718 - accuracy: 0.9899 - val_loss: 1.4765 - val_accuracy: 0.9848\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4709 - accuracy: 0.9907 - val_loss: 1.4838 - val_accuracy: 0.9772\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4701 - accuracy: 0.9915 - val_loss: 1.4759 - val_accuracy: 0.9858\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4695 - accuracy: 0.9922 - val_loss: 1.4758 - val_accuracy: 0.9857\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4693 - accuracy: 0.9924 - val_loss: 1.4760 - val_accuracy: 0.9853\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4693 - accuracy: 0.9923 - val_loss: 1.4748 - val_accuracy: 0.9864\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4693 - accuracy: 0.9920 - val_loss: 1.4747 - val_accuracy: 0.9865\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4684 - accuracy: 0.9932 - val_loss: 1.4760 - val_accuracy: 0.9847\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4681 - accuracy: 0.9935 - val_loss: 1.4742 - val_accuracy: 0.9875\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4678 - accuracy: 0.9937 - val_loss: 1.4745 - val_accuracy: 0.9867\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4680 - accuracy: 0.9934 - val_loss: 1.4744 - val_accuracy: 0.9869\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4678 - accuracy: 0.9935 - val_loss: 1.4742 - val_accuracy: 0.9868\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4670 - accuracy: 0.9944 - val_loss: 1.4753 - val_accuracy: 0.9864\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4675 - accuracy: 0.9939 - val_loss: 1.4738 - val_accuracy: 0.9875\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4670 - accuracy: 0.9944 - val_loss: 1.4743 - val_accuracy: 0.9869\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4663 - accuracy: 0.9952 - val_loss: 1.4741 - val_accuracy: 0.9873\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4666 - accuracy: 0.9948 - val_loss: 1.4751 - val_accuracy: 0.9862\n",
      "current pruning ratio is0.5, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4822 - accuracy: 0.9844 - val_loss: 1.4779 - val_accuracy: 0.9853\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4724 - accuracy: 0.9912 - val_loss: 1.4765 - val_accuracy: 0.9859\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4701 - accuracy: 0.9927 - val_loss: 1.4754 - val_accuracy: 0.9871\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4686 - accuracy: 0.9941 - val_loss: 1.4743 - val_accuracy: 0.9883\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4674 - accuracy: 0.9951 - val_loss: 1.4746 - val_accuracy: 0.9874\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4670 - accuracy: 0.9951 - val_loss: 1.4751 - val_accuracy: 0.9870\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4666 - accuracy: 0.9954 - val_loss: 1.4746 - val_accuracy: 0.9880\n",
      "current pruning ratio is0.75, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5194 - accuracy: 0.9589 - val_loss: 1.4894 - val_accuracy: 0.9794\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4835 - accuracy: 0.9837 - val_loss: 1.4818 - val_accuracy: 0.9835\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4781 - accuracy: 0.9873 - val_loss: 1.4817 - val_accuracy: 0.9832\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4751 - accuracy: 0.9890 - val_loss: 1.4768 - val_accuracy: 0.9870\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4732 - accuracy: 0.9906 - val_loss: 1.4765 - val_accuracy: 0.9860\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4717 - accuracy: 0.9918 - val_loss: 1.4760 - val_accuracy: 0.9871\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9927 - val_loss: 1.4745 - val_accuracy: 0.9882\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4695 - accuracy: 0.9934 - val_loss: 1.4748 - val_accuracy: 0.9881\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4688 - accuracy: 0.9939 - val_loss: 1.4749 - val_accuracy: 0.9881\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4680 - accuracy: 0.9947 - val_loss: 1.4751 - val_accuracy: 0.9873\n",
      "current pruning ratio is0.875, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5982 - accuracy: 0.8983 - val_loss: 1.5191 - val_accuracy: 0.9582\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5131 - accuracy: 0.9594 - val_loss: 1.5047 - val_accuracy: 0.9645\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4998 - accuracy: 0.9686 - val_loss: 1.4944 - val_accuracy: 0.9724\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4927 - accuracy: 0.9748 - val_loss: 1.4914 - val_accuracy: 0.9742\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4879 - accuracy: 0.9782 - val_loss: 1.4881 - val_accuracy: 0.9767\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4848 - accuracy: 0.9803 - val_loss: 1.4863 - val_accuracy: 0.9781\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4821 - accuracy: 0.9828 - val_loss: 1.4846 - val_accuracy: 0.9794\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4802 - accuracy: 0.9842 - val_loss: 1.4841 - val_accuracy: 0.9804\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4787 - accuracy: 0.9855 - val_loss: 1.4831 - val_accuracy: 0.9800\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4773 - accuracy: 0.9867 - val_loss: 1.4816 - val_accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4762 - accuracy: 0.9873 - val_loss: 1.4830 - val_accuracy: 0.9798\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4752 - accuracy: 0.9885 - val_loss: 1.4812 - val_accuracy: 0.9822\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4745 - accuracy: 0.9892 - val_loss: 1.4800 - val_accuracy: 0.9829\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4736 - accuracy: 0.9899 - val_loss: 1.4798 - val_accuracy: 0.9826\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4730 - accuracy: 0.9902 - val_loss: 1.4794 - val_accuracy: 0.9830\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4722 - accuracy: 0.9908 - val_loss: 1.4800 - val_accuracy: 0.9829\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4718 - accuracy: 0.9914 - val_loss: 1.4786 - val_accuracy: 0.9849\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4714 - accuracy: 0.9916 - val_loss: 1.4794 - val_accuracy: 0.9831\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4709 - accuracy: 0.9920 - val_loss: 1.4785 - val_accuracy: 0.9840\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4705 - accuracy: 0.9923 - val_loss: 1.4784 - val_accuracy: 0.9842\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4700 - accuracy: 0.9931 - val_loss: 1.4787 - val_accuracy: 0.9836\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4697 - accuracy: 0.9929 - val_loss: 1.4781 - val_accuracy: 0.9847\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4693 - accuracy: 0.9934 - val_loss: 1.4782 - val_accuracy: 0.9837\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4690 - accuracy: 0.9937 - val_loss: 1.4778 - val_accuracy: 0.9843\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4688 - accuracy: 0.9937 - val_loss: 1.4774 - val_accuracy: 0.9847\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4686 - accuracy: 0.9940 - val_loss: 1.4779 - val_accuracy: 0.9841\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4683 - accuracy: 0.9941 - val_loss: 1.4778 - val_accuracy: 0.9840\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4680 - accuracy: 0.9943 - val_loss: 1.4776 - val_accuracy: 0.9845\n",
      "current pruning ratio is0.9375, goal ratio ist 0.96875\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6670 - accuracy: 0.8161 - val_loss: 1.5421 - val_accuracy: 0.9360\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5352 - accuracy: 0.9389 - val_loss: 1.5224 - val_accuracy: 0.9506\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5204 - accuracy: 0.9503 - val_loss: 1.5119 - val_accuracy: 0.9581\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5123 - accuracy: 0.9562 - val_loss: 1.5056 - val_accuracy: 0.9626\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5067 - accuracy: 0.9612 - val_loss: 1.5028 - val_accuracy: 0.9640\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5026 - accuracy: 0.9645 - val_loss: 1.4986 - val_accuracy: 0.9669\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4996 - accuracy: 0.9669 - val_loss: 1.4991 - val_accuracy: 0.9663\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4972 - accuracy: 0.9688 - val_loss: 1.4957 - val_accuracy: 0.9696\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4950 - accuracy: 0.9703 - val_loss: 1.4949 - val_accuracy: 0.9699\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4932 - accuracy: 0.9719 - val_loss: 1.4938 - val_accuracy: 0.9695\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4918 - accuracy: 0.9730 - val_loss: 1.4933 - val_accuracy: 0.9722\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.4905 - accuracy: 0.9745 - val_loss: 1.4923 - val_accuracy: 0.9722\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4894 - accuracy: 0.9754 - val_loss: 1.4931 - val_accuracy: 0.9703\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4882 - accuracy: 0.9762 - val_loss: 1.4918 - val_accuracy: 0.9723\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4873 - accuracy: 0.9773 - val_loss: 1.4898 - val_accuracy: 0.9739\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4866 - accuracy: 0.9777 - val_loss: 1.4894 - val_accuracy: 0.9736\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4857 - accuracy: 0.9782 - val_loss: 1.4883 - val_accuracy: 0.9755\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4849 - accuracy: 0.9792 - val_loss: 1.4876 - val_accuracy: 0.9757\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4843 - accuracy: 0.9797 - val_loss: 1.4873 - val_accuracy: 0.9759\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4835 - accuracy: 0.9806 - val_loss: 1.4878 - val_accuracy: 0.9753\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4831 - accuracy: 0.9808 - val_loss: 1.4879 - val_accuracy: 0.9746\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4823 - accuracy: 0.9817 - val_loss: 1.4872 - val_accuracy: 0.9754\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4820 - accuracy: 0.9820 - val_loss: 1.4870 - val_accuracy: 0.9764\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4813 - accuracy: 0.9825 - val_loss: 1.4867 - val_accuracy: 0.9766\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4809 - accuracy: 0.9829 - val_loss: 1.4880 - val_accuracy: 0.9746\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4805 - accuracy: 0.9831 - val_loss: 1.4870 - val_accuracy: 0.9757\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4801 - accuracy: 0.9837 - val_loss: 1.4875 - val_accuracy: 0.9741\n",
      "current pruning ratio is0.96875, goal ratio ist 0.96875\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8441 - accuracy: 0.6415 - val_loss: 1.6477 - val_accuracy: 0.8461\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6199 - accuracy: 0.8656 - val_loss: 1.5969 - val_accuracy: 0.8838\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5889 - accuracy: 0.8891 - val_loss: 1.5769 - val_accuracy: 0.8998\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5746 - accuracy: 0.9003 - val_loss: 1.5662 - val_accuracy: 0.9058\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5650 - accuracy: 0.9072 - val_loss: 1.5579 - val_accuracy: 0.9137\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5581 - accuracy: 0.9135 - val_loss: 1.5524 - val_accuracy: 0.9173\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5532 - accuracy: 0.9168 - val_loss: 1.5493 - val_accuracy: 0.9196\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5488 - accuracy: 0.9204 - val_loss: 1.5453 - val_accuracy: 0.9229\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5451 - accuracy: 0.9231 - val_loss: 1.5411 - val_accuracy: 0.9267\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5420 - accuracy: 0.9262 - val_loss: 1.5386 - val_accuracy: 0.9295\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5394 - accuracy: 0.9285 - val_loss: 1.5359 - val_accuracy: 0.9314\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5365 - accuracy: 0.9310 - val_loss: 1.5340 - val_accuracy: 0.9325\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5343 - accuracy: 0.9328 - val_loss: 1.5321 - val_accuracy: 0.9348\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5323 - accuracy: 0.9346 - val_loss: 1.5306 - val_accuracy: 0.9355\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5305 - accuracy: 0.9360 - val_loss: 1.5299 - val_accuracy: 0.9357\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5292 - accuracy: 0.9374 - val_loss: 1.5294 - val_accuracy: 0.9356\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5276 - accuracy: 0.9392 - val_loss: 1.5271 - val_accuracy: 0.9379\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5263 - accuracy: 0.9400 - val_loss: 1.5259 - val_accuracy: 0.9383\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5249 - accuracy: 0.9414 - val_loss: 1.5252 - val_accuracy: 0.9405\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5240 - accuracy: 0.9421 - val_loss: 1.5240 - val_accuracy: 0.9406\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5228 - accuracy: 0.9433 - val_loss: 1.5234 - val_accuracy: 0.9417\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5220 - accuracy: 0.9444 - val_loss: 1.5221 - val_accuracy: 0.9427\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5210 - accuracy: 0.9449 - val_loss: 1.5223 - val_accuracy: 0.9421\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5205 - accuracy: 0.9454 - val_loss: 1.5212 - val_accuracy: 0.9428\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5193 - accuracy: 0.9466 - val_loss: 1.5221 - val_accuracy: 0.9418\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5187 - accuracy: 0.9471 - val_loss: 1.5202 - val_accuracy: 0.9442\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5181 - accuracy: 0.9468 - val_loss: 1.5197 - val_accuracy: 0.9438\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5175 - accuracy: 0.9481 - val_loss: 1.5200 - val_accuracy: 0.9437\n",
      "Epoch 29/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5169 - accuracy: 0.9486 - val_loss: 1.5190 - val_accuracy: 0.9454\n",
      "Epoch 30/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5166 - accuracy: 0.9486 - val_loss: 1.5182 - val_accuracy: 0.9462\n",
      "Epoch 31/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5159 - accuracy: 0.9493 - val_loss: 1.5173 - val_accuracy: 0.9470\n",
      "Epoch 32/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5153 - accuracy: 0.9498 - val_loss: 1.5171 - val_accuracy: 0.9463\n",
      "Epoch 33/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5150 - accuracy: 0.9503 - val_loss: 1.5185 - val_accuracy: 0.9456\n",
      "Epoch 34/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5146 - accuracy: 0.9503 - val_loss: 1.5176 - val_accuracy: 0.9460\n",
      "Epoch 35/500\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.5140 - accuracy: 0.9515 - val_loss: 1.5161 - val_accuracy: 0.9471\n",
      "Epoch 36/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5137 - accuracy: 0.9507 - val_loss: 1.5166 - val_accuracy: 0.9471\n",
      "Epoch 37/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5132 - accuracy: 0.9513 - val_loss: 1.5155 - val_accuracy: 0.9479\n",
      "Epoch 38/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5130 - accuracy: 0.9516 - val_loss: 1.5159 - val_accuracy: 0.9474\n",
      "Epoch 39/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5126 - accuracy: 0.9522 - val_loss: 1.5165 - val_accuracy: 0.9472\n",
      "Epoch 40/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5122 - accuracy: 0.9521 - val_loss: 1.5152 - val_accuracy: 0.9485\n",
      "Epoch 41/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5120 - accuracy: 0.9526 - val_loss: 1.5157 - val_accuracy: 0.9470\n",
      "Epoch 42/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5115 - accuracy: 0.9535 - val_loss: 1.5144 - val_accuracy: 0.9485\n",
      "Epoch 43/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5112 - accuracy: 0.9535 - val_loss: 1.5147 - val_accuracy: 0.9486\n",
      "Epoch 44/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5110 - accuracy: 0.9535 - val_loss: 1.5145 - val_accuracy: 0.9486\n",
      "Epoch 45/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5108 - accuracy: 0.9539 - val_loss: 1.5149 - val_accuracy: 0.9488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [1:43:33, 1341.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current pruning ratio is0.0, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5054 - accuracy: 0.9587 - val_loss: 1.4945 - val_accuracy: 0.9683\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4922 - accuracy: 0.9707 - val_loss: 1.4890 - val_accuracy: 0.9747\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4859 - accuracy: 0.9763 - val_loss: 1.4845 - val_accuracy: 0.9771\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4824 - accuracy: 0.9798 - val_loss: 1.4815 - val_accuracy: 0.9813\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4791 - accuracy: 0.9834 - val_loss: 1.4795 - val_accuracy: 0.9831\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4777 - accuracy: 0.9844 - val_loss: 1.4792 - val_accuracy: 0.9836\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4755 - accuracy: 0.9866 - val_loss: 1.4792 - val_accuracy: 0.9829\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4743 - accuracy: 0.9877 - val_loss: 1.4771 - val_accuracy: 0.9843\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4735 - accuracy: 0.9882 - val_loss: 1.4805 - val_accuracy: 0.9809\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4727 - accuracy: 0.9890 - val_loss: 1.4775 - val_accuracy: 0.9843\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4723 - accuracy: 0.9895 - val_loss: 1.4768 - val_accuracy: 0.9847\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4709 - accuracy: 0.9908 - val_loss: 1.4760 - val_accuracy: 0.9855\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4704 - accuracy: 0.9915 - val_loss: 1.4759 - val_accuracy: 0.9860\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4710 - accuracy: 0.9905 - val_loss: 1.4759 - val_accuracy: 0.9851\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4693 - accuracy: 0.9923 - val_loss: 1.4752 - val_accuracy: 0.9864\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4691 - accuracy: 0.9926 - val_loss: 1.4754 - val_accuracy: 0.9863\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4684 - accuracy: 0.9931 - val_loss: 1.4754 - val_accuracy: 0.9858\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4690 - accuracy: 0.9925 - val_loss: 1.4757 - val_accuracy: 0.9860\n",
      "current pruning ratio is0.5, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4871 - accuracy: 0.9811 - val_loss: 1.4797 - val_accuracy: 0.9854\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.4747 - accuracy: 0.9892 - val_loss: 1.4803 - val_accuracy: 0.9834\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4718 - accuracy: 0.9914 - val_loss: 1.4748 - val_accuracy: 0.9879\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4704 - accuracy: 0.9924 - val_loss: 1.4746 - val_accuracy: 0.9880\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4694 - accuracy: 0.9933 - val_loss: 1.4743 - val_accuracy: 0.9885\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4685 - accuracy: 0.9938 - val_loss: 1.4737 - val_accuracy: 0.9888\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4677 - accuracy: 0.9945 - val_loss: 1.4738 - val_accuracy: 0.9881\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4675 - accuracy: 0.9946 - val_loss: 1.4742 - val_accuracy: 0.9878\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4670 - accuracy: 0.9949 - val_loss: 1.4747 - val_accuracy: 0.9870\n",
      "current pruning ratio is0.75, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5104 - accuracy: 0.9684 - val_loss: 1.4878 - val_accuracy: 0.9792\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4825 - accuracy: 0.9842 - val_loss: 1.4800 - val_accuracy: 0.9851\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4773 - accuracy: 0.9875 - val_loss: 1.4779 - val_accuracy: 0.9855\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4745 - accuracy: 0.9896 - val_loss: 1.4770 - val_accuracy: 0.9863\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4728 - accuracy: 0.9909 - val_loss: 1.4748 - val_accuracy: 0.9882\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4714 - accuracy: 0.9920 - val_loss: 1.4754 - val_accuracy: 0.9872\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4704 - accuracy: 0.9926 - val_loss: 1.4753 - val_accuracy: 0.9877\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4695 - accuracy: 0.9933 - val_loss: 1.4742 - val_accuracy: 0.9884\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4689 - accuracy: 0.9938 - val_loss: 1.4754 - val_accuracy: 0.9866\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4683 - accuracy: 0.9942 - val_loss: 1.4745 - val_accuracy: 0.9878\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4675 - accuracy: 0.9950 - val_loss: 1.4729 - val_accuracy: 0.9887\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4670 - accuracy: 0.9953 - val_loss: 1.4736 - val_accuracy: 0.9881\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4665 - accuracy: 0.9956 - val_loss: 1.4737 - val_accuracy: 0.9883\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4666 - accuracy: 0.9957 - val_loss: 1.4740 - val_accuracy: 0.9879\n",
      "current pruning ratio is0.875, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5498 - accuracy: 0.9372 - val_loss: 1.5033 - val_accuracy: 0.9698\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4972 - accuracy: 0.9736 - val_loss: 1.4915 - val_accuracy: 0.9773\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4881 - accuracy: 0.9795 - val_loss: 1.4852 - val_accuracy: 0.9809\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4835 - accuracy: 0.9832 - val_loss: 1.4835 - val_accuracy: 0.9814\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4805 - accuracy: 0.9846 - val_loss: 1.4809 - val_accuracy: 0.9842\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4783 - accuracy: 0.9865 - val_loss: 1.4806 - val_accuracy: 0.9834\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4768 - accuracy: 0.9876 - val_loss: 1.4793 - val_accuracy: 0.9837\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4755 - accuracy: 0.9886 - val_loss: 1.4784 - val_accuracy: 0.9849\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4742 - accuracy: 0.9893 - val_loss: 1.4787 - val_accuracy: 0.9849\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4735 - accuracy: 0.9901 - val_loss: 1.4769 - val_accuracy: 0.9865\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4724 - accuracy: 0.9909 - val_loss: 1.4772 - val_accuracy: 0.9860\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4716 - accuracy: 0.9916 - val_loss: 1.4761 - val_accuracy: 0.9868\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4712 - accuracy: 0.9920 - val_loss: 1.4769 - val_accuracy: 0.9855\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4706 - accuracy: 0.9926 - val_loss: 1.4765 - val_accuracy: 0.9860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4700 - accuracy: 0.9931 - val_loss: 1.4762 - val_accuracy: 0.9864\n",
      "current pruning ratio is0.9375, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.7324 - accuracy: 0.7557 - val_loss: 1.5779 - val_accuracy: 0.9077\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5547 - accuracy: 0.9247 - val_loss: 1.5337 - val_accuracy: 0.9403\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5303 - accuracy: 0.9424 - val_loss: 1.5194 - val_accuracy: 0.9505\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5187 - accuracy: 0.9516 - val_loss: 1.5122 - val_accuracy: 0.9566\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5113 - accuracy: 0.9576 - val_loss: 1.5076 - val_accuracy: 0.9588\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5062 - accuracy: 0.9618 - val_loss: 1.5031 - val_accuracy: 0.9634\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5023 - accuracy: 0.9646 - val_loss: 1.5016 - val_accuracy: 0.9649\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4990 - accuracy: 0.9676 - val_loss: 1.4995 - val_accuracy: 0.9656\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4965 - accuracy: 0.9698 - val_loss: 1.4970 - val_accuracy: 0.9686\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.4945 - accuracy: 0.9713 - val_loss: 1.4936 - val_accuracy: 0.9717\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4929 - accuracy: 0.9726 - val_loss: 1.4939 - val_accuracy: 0.9714\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4914 - accuracy: 0.9740 - val_loss: 1.4917 - val_accuracy: 0.9725\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4901 - accuracy: 0.9751 - val_loss: 1.4925 - val_accuracy: 0.9729\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4888 - accuracy: 0.9761 - val_loss: 1.4904 - val_accuracy: 0.9734\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4881 - accuracy: 0.9763 - val_loss: 1.4900 - val_accuracy: 0.9747\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4871 - accuracy: 0.9773 - val_loss: 1.4889 - val_accuracy: 0.9753\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4863 - accuracy: 0.9780 - val_loss: 1.4888 - val_accuracy: 0.9753\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 1.4854 - accuracy: 0.9789 - val_loss: 1.4889 - val_accuracy: 0.9740\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4848 - accuracy: 0.9794 - val_loss: 1.4878 - val_accuracy: 0.9771\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4841 - accuracy: 0.9803 - val_loss: 1.4891 - val_accuracy: 0.9741\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4836 - accuracy: 0.9805 - val_loss: 1.4869 - val_accuracy: 0.9765\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4829 - accuracy: 0.9810 - val_loss: 1.4866 - val_accuracy: 0.9778\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4823 - accuracy: 0.9815 - val_loss: 1.4859 - val_accuracy: 0.9774\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4819 - accuracy: 0.9819 - val_loss: 1.4856 - val_accuracy: 0.9778\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.4812 - accuracy: 0.9827 - val_loss: 1.4875 - val_accuracy: 0.9752\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4809 - accuracy: 0.9830 - val_loss: 1.4859 - val_accuracy: 0.9766\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4804 - accuracy: 0.9832 - val_loss: 1.4851 - val_accuracy: 0.9780\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4802 - accuracy: 0.9834 - val_loss: 1.4858 - val_accuracy: 0.9768\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4796 - accuracy: 0.9844 - val_loss: 1.4853 - val_accuracy: 0.9783\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.4790 - accuracy: 0.9846 - val_loss: 1.4861 - val_accuracy: 0.9775\n",
      "current pruning ratio is0.96875, goal ratio ist 0.984375\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8809 - accuracy: 0.5994 - val_loss: 1.7267 - val_accuracy: 0.7512\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.6998 - accuracy: 0.7757 - val_loss: 1.6601 - val_accuracy: 0.8156\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.6434 - accuracy: 0.8306 - val_loss: 1.6081 - val_accuracy: 0.8691\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.6025 - accuracy: 0.8737 - val_loss: 1.5836 - val_accuracy: 0.8918\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5840 - accuracy: 0.8904 - val_loss: 1.5728 - val_accuracy: 0.8996\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5724 - accuracy: 0.9008 - val_loss: 1.5626 - val_accuracy: 0.9103\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5643 - accuracy: 0.9080 - val_loss: 1.5566 - val_accuracy: 0.9147\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5584 - accuracy: 0.9128 - val_loss: 1.5515 - val_accuracy: 0.9194\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5536 - accuracy: 0.9176 - val_loss: 1.5471 - val_accuracy: 0.9211\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5498 - accuracy: 0.9204 - val_loss: 1.5447 - val_accuracy: 0.9250\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5464 - accuracy: 0.9230 - val_loss: 1.5423 - val_accuracy: 0.9256\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5436 - accuracy: 0.9258 - val_loss: 1.5397 - val_accuracy: 0.9269\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5413 - accuracy: 0.9272 - val_loss: 1.5381 - val_accuracy: 0.9291\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5391 - accuracy: 0.9294 - val_loss: 1.5361 - val_accuracy: 0.9311\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5374 - accuracy: 0.9306 - val_loss: 1.5350 - val_accuracy: 0.9319\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5357 - accuracy: 0.9323 - val_loss: 1.5337 - val_accuracy: 0.9331\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5344 - accuracy: 0.9328 - val_loss: 1.5320 - val_accuracy: 0.9336\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5330 - accuracy: 0.9343 - val_loss: 1.5317 - val_accuracy: 0.9343\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5318 - accuracy: 0.9355 - val_loss: 1.5297 - val_accuracy: 0.9351\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5308 - accuracy: 0.9364 - val_loss: 1.5296 - val_accuracy: 0.9349\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5295 - accuracy: 0.9375 - val_loss: 1.5291 - val_accuracy: 0.9356\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5287 - accuracy: 0.9379 - val_loss: 1.5303 - val_accuracy: 0.9348\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5277 - accuracy: 0.9388 - val_loss: 1.5283 - val_accuracy: 0.9364\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5268 - accuracy: 0.9395 - val_loss: 1.5264 - val_accuracy: 0.9383\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5262 - accuracy: 0.9401 - val_loss: 1.5261 - val_accuracy: 0.9399\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5255 - accuracy: 0.9406 - val_loss: 1.5259 - val_accuracy: 0.9378\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5248 - accuracy: 0.9413 - val_loss: 1.5247 - val_accuracy: 0.9393\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5236 - accuracy: 0.9423 - val_loss: 1.5256 - val_accuracy: 0.9399\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5232 - accuracy: 0.9432 - val_loss: 1.5240 - val_accuracy: 0.9403\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5225 - accuracy: 0.9433 - val_loss: 1.5239 - val_accuracy: 0.9408\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5219 - accuracy: 0.9443 - val_loss: 1.5240 - val_accuracy: 0.9397\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5213 - accuracy: 0.9446 - val_loss: 1.5226 - val_accuracy: 0.9425\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5209 - accuracy: 0.9448 - val_loss: 1.5219 - val_accuracy: 0.9428\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5201 - accuracy: 0.9458 - val_loss: 1.5215 - val_accuracy: 0.9429\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5199 - accuracy: 0.9454 - val_loss: 1.5217 - val_accuracy: 0.9418\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5192 - accuracy: 0.9465 - val_loss: 1.5212 - val_accuracy: 0.9425\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5187 - accuracy: 0.9467 - val_loss: 1.5216 - val_accuracy: 0.9435\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5184 - accuracy: 0.9472 - val_loss: 1.5203 - val_accuracy: 0.9433\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5179 - accuracy: 0.9475 - val_loss: 1.5209 - val_accuracy: 0.9419\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.5176 - accuracy: 0.9478 - val_loss: 1.5209 - val_accuracy: 0.9428\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.5173 - accuracy: 0.9484 - val_loss: 1.5208 - val_accuracy: 0.9425\n",
      "current pruning ratio is0.984375, goal ratio ist 0.984375\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.9841 - accuracy: 0.4849 - val_loss: 1.8784 - val_accuracy: 0.5938\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8655 - accuracy: 0.6046 - val_loss: 1.8495 - val_accuracy: 0.6178\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.8470 - accuracy: 0.6197 - val_loss: 1.8380 - val_accuracy: 0.6277\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8383 - accuracy: 0.6266 - val_loss: 1.8321 - val_accuracy: 0.6321\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.8334 - accuracy: 0.6302 - val_loss: 1.8273 - val_accuracy: 0.6351\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.8299 - accuracy: 0.6329 - val_loss: 1.8251 - val_accuracy: 0.6370\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8271 - accuracy: 0.6353 - val_loss: 1.8217 - val_accuracy: 0.6391\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8245 - accuracy: 0.6375 - val_loss: 1.8187 - val_accuracy: 0.6433\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8223 - accuracy: 0.6396 - val_loss: 1.8168 - val_accuracy: 0.6453\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8207 - accuracy: 0.6409 - val_loss: 1.8164 - val_accuracy: 0.6455\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8192 - accuracy: 0.6425 - val_loss: 1.8154 - val_accuracy: 0.6455\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8180 - accuracy: 0.6439 - val_loss: 1.8144 - val_accuracy: 0.6463\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8171 - accuracy: 0.6447 - val_loss: 1.8132 - val_accuracy: 0.6485\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8162 - accuracy: 0.6457 - val_loss: 1.8134 - val_accuracy: 0.6477\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8153 - accuracy: 0.6462 - val_loss: 1.8127 - val_accuracy: 0.6484\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8146 - accuracy: 0.6467 - val_loss: 1.8117 - val_accuracy: 0.6496\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8140 - accuracy: 0.6472 - val_loss: 1.8113 - val_accuracy: 0.6498\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8133 - accuracy: 0.6480 - val_loss: 1.8115 - val_accuracy: 0.6492\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8128 - accuracy: 0.6485 - val_loss: 1.8107 - val_accuracy: 0.6498\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8124 - accuracy: 0.6487 - val_loss: 1.8112 - val_accuracy: 0.6494\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8120 - accuracy: 0.6491 - val_loss: 1.8101 - val_accuracy: 0.6508\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8114 - accuracy: 0.6498 - val_loss: 1.8099 - val_accuracy: 0.6511\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8110 - accuracy: 0.6499 - val_loss: 1.8096 - val_accuracy: 0.6508\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8106 - accuracy: 0.6502 - val_loss: 1.8092 - val_accuracy: 0.6505\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8103 - accuracy: 0.6507 - val_loss: 1.8091 - val_accuracy: 0.6510\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8100 - accuracy: 0.6511 - val_loss: 1.8083 - val_accuracy: 0.6519\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.8097 - accuracy: 0.6512 - val_loss: 1.8079 - val_accuracy: 0.6525\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8092 - accuracy: 0.6516 - val_loss: 1.8083 - val_accuracy: 0.6527\n",
      "Epoch 29/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8088 - accuracy: 0.6523 - val_loss: 1.8076 - val_accuracy: 0.6522\n",
      "Epoch 30/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8082 - accuracy: 0.6528 - val_loss: 1.8071 - val_accuracy: 0.6530\n",
      "Epoch 31/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8079 - accuracy: 0.6526 - val_loss: 1.8059 - val_accuracy: 0.6541\n",
      "Epoch 32/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8076 - accuracy: 0.6535 - val_loss: 1.8069 - val_accuracy: 0.6536\n",
      "Epoch 33/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8073 - accuracy: 0.6533 - val_loss: 1.8057 - val_accuracy: 0.6553\n",
      "Epoch 34/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8069 - accuracy: 0.6536 - val_loss: 1.8062 - val_accuracy: 0.6539\n",
      "Epoch 35/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8067 - accuracy: 0.6541 - val_loss: 1.8051 - val_accuracy: 0.6555\n",
      "Epoch 36/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8063 - accuracy: 0.6547 - val_loss: 1.8048 - val_accuracy: 0.6550\n",
      "Epoch 37/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8060 - accuracy: 0.6543 - val_loss: 1.8048 - val_accuracy: 0.6558\n",
      "Epoch 38/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8058 - accuracy: 0.6547 - val_loss: 1.8055 - val_accuracy: 0.6551\n",
      "Epoch 39/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8055 - accuracy: 0.6549 - val_loss: 1.8050 - val_accuracy: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8052 - accuracy: 0.6555 - val_loss: 1.8042 - val_accuracy: 0.6563\n",
      "Epoch 41/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8049 - accuracy: 0.6558 - val_loss: 1.8039 - val_accuracy: 0.6572\n",
      "Epoch 42/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8047 - accuracy: 0.6559 - val_loss: 1.8035 - val_accuracy: 0.6575\n",
      "Epoch 43/500\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.8044 - accuracy: 0.6560 - val_loss: 1.8046 - val_accuracy: 0.6560\n",
      "Epoch 44/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8043 - accuracy: 0.6563 - val_loss: 1.8029 - val_accuracy: 0.6576\n",
      "Epoch 45/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8040 - accuracy: 0.6561 - val_loss: 1.8033 - val_accuracy: 0.6573\n",
      "Epoch 46/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8037 - accuracy: 0.6565 - val_loss: 1.8027 - val_accuracy: 0.6577\n",
      "Epoch 47/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8036 - accuracy: 0.6568 - val_loss: 1.8026 - val_accuracy: 0.6582\n",
      "Epoch 48/500\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 1.8035 - accuracy: 0.6566 - val_loss: 1.8026 - val_accuracy: 0.6582\n",
      "Epoch 49/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8031 - accuracy: 0.6571 - val_loss: 1.8032 - val_accuracy: 0.6562\n",
      "Epoch 50/500\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8029 - accuracy: 0.6573 - val_loss: 1.8028 - val_accuracy: 0.6582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [2:32:40, 1308.57s/it]\u001b[A\n",
      "100%|██████████| 3/3 [7:19:37<00:00, 8792.39s/it]  \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved-results/cnn-random-local-unstructured-accuracies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-85b2f47289a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m run_experiment(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unstructured'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'local'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-49f43cb14a57>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(structure, method, scope, iterations)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m#write to csv and json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'saved-results/{experiment_name}-accuracies.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'saved-results/{experiment_name}-accuracies.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             f, handles = get_handle(\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved-results/cnn-random-local-unstructured-accuracies.csv'"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    structure='unstructured', \n",
    "    method='random', \n",
    "    scope='local', \n",
    "    iterations=ITERATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    structure='unstructured', \n",
    "    method='magnitude', \n",
    "    scope='local', \n",
    "    iterations=ITERATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    structure='unstructured', \n",
    "    method='magnitude', \n",
    "    scope='global', \n",
    "    iterations=ITERATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    structure='struct', \n",
    "    method='random', \n",
    "    scope='local', \n",
    "    iterations=ITERATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    structure='struct', \n",
    "    method='magnitude', \n",
    "    scope='local', \n",
    "    iterations=ITERATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(\n",
    "    structure='struct', \n",
    "    method='magnitude', \n",
    "    scope='global', \n",
    "    iterations=ITERATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune, Train Attack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(structure='unstructured', method='random', scope='global', iterations=10):\n",
    "    \n",
    "    experiment_name = f'{ARCHITECTURE}-{method}-{scope}-{structure}'\n",
    "    pgd_success_rates = []\n",
    "    cw_success_rates = []\n",
    "    all_accuracies = []\n",
    "\n",
    "    #compression_rates = [1, 2, 4, 64]\n",
    "    compression_rates = [tf.math.pow(2, x).numpy() for x in range(7)]\n",
    "    pruning_ratios = [1-1/x for x in compression_rates]\n",
    "\n",
    "    for j in tqdm(range(iterations)):\n",
    "        accuracies = []\n",
    "        pgd_success_rate = []\n",
    "        cw_success_rate = []\n",
    "        try: \n",
    "            del model\n",
    "        except:\n",
    "            ;\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        model = initialize_base_model(j, experiment_name=experiment_name, save_weights=True)\n",
    "        for index, pruning_ratio in tqdm(enumerate(pruning_ratios)):\n",
    "\n",
    "            model.load_weights(f'./saved-weights/{experiment_name}-{j}')\n",
    "            #print(f'./saved-weights/{experiment_name}-{j}')\n",
    "\n",
    "            for i in range(index + 1):\n",
    "                print(f'current pruning ratio is{pruning_ratios[i]}, goal ratio ist {pruning_ratio}')\n",
    "                if i != index:\n",
    "\n",
    "                    if  method=='random' and scope=='global' and structure=='unstructured':\n",
    "                        model.prune_random_global_unstruct(pruning_ratios[i])\n",
    "                    if  method=='random' and scope=='global' and structure=='structured':\n",
    "                        model.prune_random_global_struct(pruning_ratios[i])\n",
    "                    if  method=='random' and scope=='local' and structure=='unstructured':\n",
    "                        model.prune_random_local_unstruct(pruning_ratios[i])\n",
    "                    if  method=='random' and scope=='local' and structure=='structured':\n",
    "                        model.prune_random_local_struct(pruning_ratios[i])\n",
    "                    if  method=='magnitude' and scope=='global' and structure=='unstructured':\n",
    "                        model.prune_magnitude_global_unstruct(pruning_ratios[i])\n",
    "                    if  method=='magnitude' and scope=='global' and structure=='structured':\n",
    "                        model.prune_magnitude_global_struct(pruning_ratios[i])\n",
    "                    if  method=='magnitude' and scope=='local' and structure=='unstructured':\n",
    "                        model.prune_magnitude_local_unstruct(pruning_ratios[i])\n",
    "                    if  method=='magnitude' and scope=='local' and structure=='structured':\n",
    "                        model.prune_magnitude_local_struct(pruning_ratios[i])\n",
    "\n",
    "\n",
    "                    # must recompile otherwise pruned weights will get updated\n",
    "                    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                                  metrics=['accuracy'],\n",
    "                                  experimental_run_tf_function=False\n",
    "                                 )\n",
    "                    model = train_model(model, to_convergence=False)\n",
    "                if i == index:\n",
    "                    if  method=='random' and scope=='global' and structure=='unstructured':\n",
    "                        model.prune_random_global_unstruct(pruning_ratios[i])\n",
    "                    if  method=='random' and scope=='global' and structure=='structured':\n",
    "                        model.prune_random_global_struct(pruning_ratios[i])\n",
    "                    if  method=='random' and scope=='local' and structure=='unstructured':\n",
    "                        model.prune_random_local_unstruct(pruning_ratios[i])\n",
    "                    if  method=='random' and scope=='local' and structure=='structured':\n",
    "                        model.prune_random_local_struct(pruning_ratios[i])\n",
    "                    if  method=='magnitude' and scope=='global' and structure=='unstructured':\n",
    "                        model.prune_magnitude_global_unstruct(pruning_ratios[i])\n",
    "                    if  method=='magnitude' and scope=='global' and structure=='structured':\n",
    "                        model.prune_magnitude_global_struct(pruning_ratios[i])\n",
    "                    if  method=='magnitude' and scope=='local' and structure=='unstructured':\n",
    "                        model.prune_magnitude_local_unstruct(pruning_ratios[i])\n",
    "                    if  method=='magnitude' and scope=='local' and structure=='structured':\n",
    "                        model.prune_magnitude_local_struct(pruning_ratios[i])\n",
    "                    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                                  metrics=['accuracy'],\n",
    "                                  experimental_run_tf_function=False\n",
    "                                 )\n",
    "                    model = train_model(model, to_convergence=True)\n",
    "                    accuracies.append(model.evaluate(x_test, y_test, verbose=0))\n",
    "                    pgd_success_rate.append(pgd_attack(model))\n",
    "                    cw_success_rate.append(cw2_attack(model))\n",
    "        all_accuracies.append(accuracies)\n",
    "        pgd_success_rates.append(pgd_success_rate)\n",
    "        cw_success_rates.append(cw_success_rate)\n",
    "    #write to csv and json\n",
    "\n",
    "    #pd.DataFrame(all_accuracies).to_csv(f'saved-results/{experiment_name}-accuracies.csv',index=False)\n",
    "    with open(f'saved-results/{experiment_name}-accuracies.json', 'w') as f:\n",
    "        json.dump(all_accuracies, f)\n",
    "\n",
    "    #pd.DataFrame(pgd_success_rates).to_csv(f'saved-results/{experiment_name}-pgd-success.csv',index=False)\n",
    "    with open(f'saved-results/{experiment_name}-pgd-success.json', 'w') as f:\n",
    "        json.dump(pgd_success_rates, f)\n",
    "    #pd.DataFrame(cw_success_rates).to_csv(f'saved-results/{experiment_name}-cw0-success.csv',index=False)\n",
    "    with open(f'saved-results/{experiment_name}-cw2-success', 'w') as f:\n",
    "        json.dump(cw_success_rates, f)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune, Train Attack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-71e5815d8ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mall_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_accuracies' is not defined"
     ]
    }
   ],
   "source": [
    "for idx,x in enumerate(all_accuracies):\n",
    "    for idy,y in enumerate(x):\n",
    "        all_accuracies[idx][idy] = [float(y[0]), float(y[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zeros_ratio(weights):\n",
    "    layers_to_examine = [0,3,6,9,12]\n",
    "    all_weights = np.array([])\n",
    "    for x in layers_to_examine:\n",
    "\n",
    "        all_weights = np.append(all_weights, weights[x].flatten())\n",
    "    return np.count_nonzero(all_weights)/len(all_weights), np.count_nonzero(all_weights), len(all_weights)\n",
    "\n",
    "def initialize_base_model(index, experiment_name, save_weights=False):\n",
    "\n",
    "    model = CustomConvModel()\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "                 )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=x_train,\n",
    "              y=y_train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n",
    "    if save_weights == True:\n",
    "        model.save_weights(f'./saved-weights/{experiment_name}-{index}')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=500,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=100,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def prune_weights(model, pruning_ratio):\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        \n",
    "        if (index == 9) or (index == 12) :\n",
    "            #print(weight.shape)\n",
    "            #print(index)\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index+2].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            flat_weights_to_prune_df = pd.DataFrame(flat_weights_to_prune)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            #print(len(flat_weights))\n",
    "            #print('no of weights',no_of_weights_to_prune)\n",
    "            #print('weights to prune shape', flat_weights_to_prune.shape)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+2].shape\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            weights_to_prune[index+2] = weights_reshaped\n",
    "    #print(weights_to_prune)\n",
    "    return weights_to_prune\n",
    "\n",
    "def pgd_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.LinfProjectedGradientDescentAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x_to_attack,\n",
    "        y_to_attack,\n",
    "        epsilons=[25/255]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/500\n",
    "\n",
    "def cw2_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x_to_attack,\n",
    "        y_to_attack,\n",
    "        #epsilons=[.5]\n",
    "        epsilons=None\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/len(y)\n",
    "\n",
    "def prune_conv_layers(pruning_ratio):\n",
    "    layer_to_prune = [0, 3]\n",
    "    pruned_weights = model.get_weights()\n",
    "    \n",
    "    for layer in layer_to_prune:\n",
    "        converted_weights = convert_from_hwio_to_iohw(model.get_weights()[layer])\n",
    "        converted_mask = convert_from_hwio_to_iohw(model.get_weights()[layer + 2]).numpy()\n",
    "        for input_index, input_layer in enumerate(converted_weights):\n",
    "\n",
    "            for kernel_index, kernel in enumerate(input_layer):\n",
    "                dims = kernel.shape\n",
    "                flat_weights = kernel.numpy().flatten()\n",
    "                flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "                #print(no_of_weights_to_prune)\n",
    "                indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    flat_masks[idx_to_delete] = 0\n",
    "\n",
    "                converted_mask[input_index][kernel_index] = flat_masks.reshape(dims)\n",
    "        back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "        pruned_weights[layer+2] = back_converted_mask\n",
    "    \n",
    "    return pruned_weights\n",
    "\n",
    "def convert_from_hwio_to_iohw(weights_nchw):\n",
    "    return tf.transpose(weights_nchw, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def convert_from_iohw_to_hwio(weights_nhwc):\n",
    "    return tf.transpose(weights_nhwc, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "def get_average_accuracies(all_accuracies):\n",
    "    acc_per_pruning_rate=[]\n",
    "    for i in range(len(all_accuracies)):\n",
    "        for j in range(len(all_accuracies[i])):\n",
    "\n",
    "            try:\n",
    "                acc_per_pruning_rate[j].append(all_accuracies[i][j][1])\n",
    "            except:\n",
    "                acc_per_pruning_rate.append([])\n",
    "                acc_per_pruning_rate[j].append(all_accuracies[i][j][1])\n",
    "    avg_acc_per_pruning_rate = [sum(x)/len(x) for x in acc_per_pruning_rate]; avg_acc_per_pruning_rate\n",
    "    return avg_acc_per_pruning_rate\n",
    "\n",
    "def get_average_success_rates(all_success_rates):\n",
    "    success_per_pruning_rate=[]\n",
    "    for i in range(len(all_success_rates)):\n",
    "        for j in range(len(all_success_rates[i])):\n",
    "\n",
    "            try:\n",
    "                success_per_pruning_rate[j].append(all_success_rates[i][j])\n",
    "            except:\n",
    "                success_per_pruning_rate.append([])\n",
    "                success_per_pruning_rate[j].append(all_success_rates[i][j])\n",
    "    avg_success_per_pruning_rate = [sum(x)/len(x) for x in success_per_pruning_rate];avg_success_per_pruning_rate\n",
    "    return avg_success_per_pruning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x_to_attack = tf.convert_to_tensor(x_train[:1000].reshape(1000,28*28))\n",
    "y_to_attack = tf.convert_to_tensor([y_train[:1000]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'conv_1': (5, 5, 1, 6),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'conv_2': (5, 5, 6, 16),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'conv_3': (1, 1, 16, 120),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'dense_1': (5*5*16, 120),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'dense_2': (120, 84),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'dense_3': (84, 10),\n",
    "}\n",
    "bias_shapes = {\n",
    "    #output depth\n",
    "    'conv_1': (6),\n",
    "    'conv_2': (16),\n",
    "    'dense_1': (120),\n",
    "    'dense_2': (84),\n",
    "    'dense_3': (10),\n",
    "}\n",
    "\n",
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='valid'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "#        return tf.keras.layers.AveragePooling2D(pool_size=(self.k, self.k), strides=None, padding=self.p, data_format='channels_first')(inputs)\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p,)# data_format='NCHW')\n",
    "    \n",
    "\n",
    "        \n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, shape, bias, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape=shape,\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "            name='w'\n",
    "        )\n",
    "        self.m = self.add_weight(\n",
    "            shape=shape,\n",
    "            initializer='ones',\n",
    "            trainable=False,\n",
    "            name='m'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape = (shape[-1]),\n",
    "            initializer = 'zeros',\n",
    "            trainable = True,\n",
    "            name='b'\n",
    "        )\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "\n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    def __init__(self, shape, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape = shape,\n",
    "            initializer='random_normal',\n",
    "            trainable = True,\n",
    "            name='w'\n",
    "        )\n",
    "        self.m = self.add_weight(\n",
    "            shape = shape,\n",
    "            initializer='ones',\n",
    "            trainable = False,\n",
    "            name='m'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape = (shape[-1]),\n",
    "            initializer = 'zeros',\n",
    "            trainable = True,\n",
    "            name='b'\n",
    "        )\n",
    "        self.a = activation\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        \n",
    "        \n",
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(shapes['conv_1'], True, 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(shapes['conv_2'], True, 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "\n",
    "        self.dense1 = CustomDenseLayer(shapes['dense_1'], True, 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(shapes['dense_2'], True, 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(shapes['dense_3'], True, 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, shape=[-1,28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x =  self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    def prune_random_local_unstruct(self, ratio):\n",
    "        def prune_conv_layers_locally(self, ratio):\n",
    "            conv_layer_to_prune = [0, 3]\n",
    "            weights = self.get_weights()\n",
    "            for layer in conv_layer_to_prune:\n",
    "                converted_weights = convert_from_hwio_to_iohw(weights[layer]).numpy()\n",
    "                converted_mask = convert_from_hwio_to_iohw(weights[layer + 2]).numpy()\n",
    "                for input_index, input_layer in enumerate(converted_weights):\n",
    "                    for kernel_index, kernel in enumerate(input_layer):\n",
    "                        shape = kernel.shape\n",
    "                        flat_weights = kernel.flatten()\n",
    "                        flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                        \n",
    "                        no_of_weighs_to_prune = ratio * len(flat_weights)\n",
    "                        # find unpruned weights\n",
    "                        non_zero_weights = np.nonzero(flat_masks)[0]\n",
    "                        # calculate the amount of weights to be pruned this round\n",
    "                        no_of_weights_to_prune_left = int(no_of_weighs_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "                        # shuffle all non-zero weights\n",
    "                        random.shuffle(non_zero_weights)\n",
    "                        # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "                        indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "                        \n",
    "                        for idx_to_delete in indices_to_delete:\n",
    "                            flat_masks[idx_to_delete] = 0\n",
    "                            flat_weights[idx_to_delete] = 0\n",
    "                        converted_mask[input_index][kernel_index] = flat_masks.reshape(shape)\n",
    "                        converted_weights[input_index][kernel_index] = flat_weights.reshape(shape)\n",
    "                back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "                back_converted_weights = convert_from_iohw_to_hwio(converted_weights)\n",
    "                weights[layer] = back_converted_weights\n",
    "                weights[layer+2] = back_converted_mask\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        \n",
    "        def prune_dense_layers_locally(self, ratio):\n",
    "            dense_layer_to_prune = [6, 9, 12]\n",
    "            weights = self.get_weights()\n",
    "            for index, weight in enumerate(weights):\n",
    "                if index in dense_layer_to_prune:\n",
    "                    shape = weight.shape\n",
    "                    flat_weights = weight.flatten()\n",
    "                    flat_mask = weights[index+2].flatten()\n",
    "                    no_of_weighs_to_prune = ratio * len(flat_weights)\n",
    "                    # find unpruned weights\n",
    "                    non_zero_weights = np.nonzero(flat_mask)[0]\n",
    "                    # calculate the amount of weights to be pruned this round\n",
    "                    no_of_weights_to_prune_left = int(no_of_weighs_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "                    # shuffle all non-zero weights\n",
    "                    random.shuffle(non_zero_weights)\n",
    "                    # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "                    indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "                    for idx_to_delete in indices_to_delete:\n",
    "                        flat_mask[idx_to_delete] = 0\n",
    "                        flat_weights[idx_to_delete] = 0\n",
    "\n",
    "                    mask_reshaped = flat_mask.reshape(shape)\n",
    "                    weights_reshaped = flat_weights.reshape(shape)\n",
    "                    weights[index+2] = mask_reshaped\n",
    "                    weights[index] = weights_reshaped\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        prune_conv_layers_locally(self, ratio)\n",
    "        prune_dense_layers_locally(self,ratio)\n",
    "    \n",
    "    def prune_magnitude_global_unstruct(self, ratio):\n",
    "        #flat out all weights:\n",
    "        conv_layer_to_prune = [0, 3]\n",
    "        dense_layer_to_prune = [6, 9, 12]\n",
    "        weights = self.get_weights()\n",
    "        flat_weights = []\n",
    "        flat_mask = []\n",
    "        for x in conv_layer_to_prune + dense_layer_to_prune:\n",
    "            flat_weights = np.append(flat_weights, weights[x])\n",
    "            flat_mask = np.append(flat_mask, weights[x+2])\n",
    "            \n",
    "        no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "        indices_to_delete = np.abs(flat_weights).argsort(0)[:no_of_weights_to_prune]\n",
    "        \n",
    "        for idx_to_delete in indices_to_delete:\n",
    "            flat_mask[idx_to_delete] = 0\n",
    "            flat_weights[idx_to_delete] = 0\n",
    "        z = 0\n",
    "        for x in conv_layer_to_prune + dense_layer_to_prune:\n",
    "            weights[x] = flat_weights[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            weights[x + 2] = flat_mask[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            z = z + np.prod(weights[x].shape)            \n",
    "        self.set_weights(weights)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    def prune_magnitude_local_unstruct(self, ratio):\n",
    "        def prune_conv_layers_locally(self, ratio):\n",
    "            conv_layer_to_prune = [0, 3]\n",
    "            #print('inside conv prune func',get_zeros_ratio(self.get_weights()))\n",
    "            weights = self.get_weights()\n",
    "            \n",
    "            for layer in conv_layer_to_prune:\n",
    "                converted_weights = convert_from_hwio_to_iohw(weights[layer]).numpy()\n",
    "                converted_mask = convert_from_hwio_to_iohw(weights[layer + 2]).numpy()\n",
    "                for input_index, input_layer in enumerate(converted_weights):\n",
    "                    for kernel_index, kernel in enumerate(input_layer):\n",
    "                        shape = kernel.shape\n",
    "                        flat_weights = kernel.flatten()\n",
    "                        flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                        #flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                        #flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                        no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                        #print(no_of_weights_to_prune)\n",
    "                        #indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                        indices_to_delete = np.abs(flat_weights).argsort(0)[:no_of_weights_to_prune]\n",
    "\n",
    "\n",
    "                        for idx_to_delete in indices_to_delete:\n",
    "                            flat_masks[idx_to_delete] = 0\n",
    "                            flat_weights[idx_to_delete] = 0\n",
    "\n",
    "                        converted_mask[input_index][kernel_index] = flat_masks.reshape(shape)\n",
    "                        converted_weights[input_index][kernel_index] = flat_weights.reshape(shape)\n",
    "                back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "                back_converted_weights = convert_from_iohw_to_hwio(converted_weights)\n",
    "                weights[layer] = back_converted_weights\n",
    "                weights[layer+2] = back_converted_mask\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        \n",
    "        def prune_dense_layers_locally(self, ratio):\n",
    "            \n",
    "            dense_layer_to_prune = [6, 9, 12]\n",
    "            weights = self.get_weights()\n",
    "            for index, weight in enumerate(weights):\n",
    "                if index in dense_layer_to_prune:\n",
    "                    shape = weight.shape\n",
    "                    flat_weights = weight.flatten()\n",
    "                    flat_mask = weights[index+2].flatten()\n",
    "\n",
    "                    no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                    indices_to_delete = np.abs(flat_weights).argsort()[:no_of_weights_to_prune]\n",
    "                    for idx_to_delete in indices_to_delete:\n",
    "                        flat_mask[idx_to_delete] = 0\n",
    "                        flat_weights[idx_to_delete] = 0\n",
    "                    mask_reshaped = flat_mask.reshape(shape)\n",
    "                    weights_reshaped = flat_weights.reshape(shape)\n",
    "                    weights[index+2] = mask_reshaped\n",
    "                    weights[index] = weights_reshaped\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        prune_conv_layers_locally(self,ratio)\n",
    "        prune_dense_layers_locally(self,ratio)\n",
    "        return\n",
    "    \n",
    "    def prune_random_local_struct(self, ratio):\n",
    "        def prune_conv_layers(conv_layers_to_prune, weights):\n",
    "            for x in conv_layers_to_prune:\n",
    "\n",
    "                vals = []\n",
    "                iohw_weights = convert_from_hwio_to_iohw(weights[x])\n",
    "                iohw_mask = convert_from_hwio_to_iohw(weights[x+2])\n",
    "                converted_shape = iohw_weights.shape\n",
    "                no_of_channels = converted_shape[0]*converted_shape[1]\n",
    "                no_of_channels_to_prune = int(np.round(ratio * no_of_channels))\n",
    "                channels = tf.reshape(iohw_weights, (no_of_channels,converted_shape[2],converted_shape[3])).numpy()\n",
    "                #print(channels)\n",
    "                non_zero_channels = np.nonzero([np.sum(channel) for channel in channels])[0]\n",
    "                #print(non_zero_channels)\n",
    "                no_of_channels_to_prune_left = no_of_channels_to_prune - (len(channels) - len(non_zero_channels))\n",
    "                random.shuffle(non_zero_channels)\n",
    "                channels_to_prune = non_zero_channels[:no_of_channels_to_prune_left]\n",
    "                mask = tf.reshape(iohw_mask, (no_of_channels,converted_shape[2],converted_shape[3])).numpy()\n",
    "\n",
    "                for channel_to_prune in channels_to_prune:\n",
    "                    channels[channel_to_prune] = tf.zeros([converted_shape[2],converted_shape[3]])\n",
    "                    mask[channel_to_prune] = tf.zeros([converted_shape[2],converted_shape[3]])\n",
    "\n",
    "                reshaped_mask = tf.reshape(mask, converted_shape)\n",
    "                reshaped_weights = tf.reshape(channels, converted_shape)\n",
    "                weights[x] = convert_from_iohw_to_hwio(reshaped_weights)\n",
    "                weights[x+2] = convert_from_iohw_to_hwio(reshaped_mask)\n",
    "            #self.set_weights(weights)\n",
    "            return True\n",
    "        def prune_dense_layers(dense_layers_to_prune, weights):\n",
    "            for layer_to_prune in dense_layers_to_prune:\n",
    "                rows = weights[layer_to_prune]\n",
    "                no_of_rows_to_prune = int(ratio * len(weights[layer_to_prune]))\n",
    "                non_zero_rows = np.nonzero([np.sum(row) for row in rows])[0]\n",
    "                no_of_rows_to_prune_left = no_of_rows_to_prune - (len(rows) - len(non_zero_rows))\n",
    "                random.shuffle(non_zero_rows)\n",
    "                rows_to_prune = non_zero_rows[:no_of_rows_to_prune_left]\n",
    "                \n",
    "                for row_to_prune in rows_to_prune:\n",
    "                    weights[layer_to_prune][row_to_prune] = tf.zeros(len(weights[layer_to_prune][row_to_prune]))\n",
    "                    weights[layer_to_prune+2][row_to_prune] = tf.zeros(len(weights[layer_to_prune][row_to_prune]))\n",
    "            return True\n",
    "        weights = self.get_weights()\n",
    "        conv_layers_to_prune = [0,3]\n",
    "        dense_layers_to_prune = [6,9,12]\n",
    "        prune_conv_layers(conv_layers_to_prune, weights)\n",
    "        prune_dense_layers(dense_layers_to_prune, weights)\n",
    "        self.set_weights(weights)\n",
    "        return True\n",
    "\n",
    "    def prune_random_global_struct(self, ratio):\n",
    "        raise Warning('Not yet implemented')\n",
    "        return False\n",
    "    def prune_magnitude_local_struct(self, ratio):\n",
    "        def prune_conv_layers(conv_layers_to_prune, weights):\n",
    "            for x in conv_layers_to_prune:\n",
    "\n",
    "                vals = []\n",
    "                iohw_weights = convert_from_hwio_to_iohw(weights[x])\n",
    "                iohw_mask = convert_from_hwio_to_iohw(weights[x+2])\n",
    "                converted_shape = iohw_weights.shape\n",
    "                no_of_channels = converted_shape[0]*converted_shape[1]\n",
    "                no_of_channels_to_prune = int(np.round(ratio * no_of_channels))\n",
    "                channels = tf.reshape(iohw_weights, (no_of_channels,converted_shape[2],converted_shape[3])).numpy()\n",
    "                \n",
    "                mask = tf.reshape(iohw_mask, (no_of_channels,converted_shape[2],converted_shape[3])).numpy()\n",
    "                for channel in channels:\n",
    "                    vals.append(tf.math.reduce_sum(tf.math.abs(channel)))\n",
    "                channels_to_prune = np.argsort(vals)[:no_of_channels_to_prune]\n",
    "\n",
    "                for channel_to_prune in channels_to_prune:\n",
    "                    channels[channel_to_prune] = tf.zeros([converted_shape[2],converted_shape[3]])\n",
    "                    mask[channel_to_prune] = tf.zeros([converted_shape[2],converted_shape[3]])\n",
    "\n",
    "                reshaped_mask = tf.reshape(mask, converted_shape)\n",
    "                reshaped_weights = tf.reshape(channels, converted_shape)\n",
    "                weights[x] = convert_from_iohw_to_hwio(reshaped_weights)\n",
    "                weights[x+2] = convert_from_iohw_to_hwio(reshaped_mask)\n",
    "            #self.set_weights(weights)\n",
    "            return weights\n",
    "        def prune_dense_layers(dense_layers_to_prune, weights):\n",
    "            for layer_to_prune in dense_layers_to_prune:\n",
    "                no_of_rows_to_prune = int(ratio * len(weights[layer_to_prune]))\n",
    "                vals = []\n",
    "                for row in weights[layer_to_prune]:\n",
    "                    vals.append(np.sum(np.abs(row)))\n",
    "                rows_to_prune = np.argsort(vals)[:no_of_rows_to_prune]\n",
    "                for row_to_prune in rows_to_prune:\n",
    "\n",
    "                    weights[layer_to_prune][row_to_prune] = tf.zeros(len(weights[layer_to_prune][row_to_prune]))\n",
    "                    weights[layer_to_prune+2][row_to_prune] = tf.zeros(len(weights[layer_to_prune][row_to_prune]))\n",
    "            return weights\n",
    "        weights = self.get_weights()\n",
    "        conv_layers_to_prune = [0,3]\n",
    "        dense_layers_to_prune = [6,9,12]\n",
    "        weights = prune_conv_layers(conv_layers_to_prune, weights)\n",
    "        weights = prune_dense_layers(dense_layers_to_prune, weights)\n",
    "        self.set_weights(weights)\n",
    "        return True\n",
    "        \n",
    "    def prune_magnitude_global_struct(self, ratio):\n",
    "        def prune_conv_layers(conv_layers_to_prune, weights):\n",
    "            all_channels = np.empty((0,5,5))\n",
    "            original_shapes = []\n",
    "            for layer_to_prune in conv_layers_to_prune:\n",
    "                iohw_weights = convert_from_hwio_to_iohw(weights[layer_to_prune])\n",
    "                converted_shape = iohw_weights.shape\n",
    "                no_of_channels = converted_shape[0]*converted_shape[1]\n",
    "                channels = tf.reshape(iohw_weights, (no_of_channels,converted_shape[2],converted_shape[3])).numpy()\n",
    "                all_channels = np.concatenate((all_channels, channels))\n",
    "            mask = np.ones(all_channels.shape)\n",
    "            vals = [np.sum(np.abs(channel)) for channel in all_channels]\n",
    "            no_of_channels_to_prune = int(ratio * len(vals))\n",
    "            channels_to_prune = np.argsort(vals)[:no_of_channels_to_prune]\n",
    "\n",
    "            for channel_to_prune in channels_to_prune:\n",
    "                all_channels[channel_to_prune] = tf.zeros((5,5))\n",
    "                mask[channel_to_prune] = tf.zeros((5,5))\n",
    "            z = 0\n",
    "            for i, layer_to_prune in enumerate(conv_layers_to_prune):\n",
    "                original_shape = convert_from_hwio_to_iohw(weights[layer_to_prune]).shape\n",
    "                pruned_layer = tf.reshape(all_channels[z:z + original_shape[0]*original_shape[1]], original_shape)\n",
    "                pruned_mask = tf.reshape(mask[z:z + original_shape[0]*original_shape[1]], original_shape)\n",
    "                weights[layer_to_prune] = convert_from_iohw_to_hwio(pruned_layer)\n",
    "                weights[layer_to_prune + 2] = convert_from_iohw_to_hwio(pruned_mask)\n",
    "                z = original_shape[0]*original_shape[1]    \n",
    "            return weights\n",
    "        \n",
    "        def prune_dense_layers(dense_layers_to_prune, weights):\n",
    "            vals = []\n",
    "            lengths = []\n",
    "            for layer_to_prune in dense_layers_to_prune:\n",
    "                lengths.append(weights[layer_to_prune].shape[0])\n",
    "                vals = vals + [np.sum(np.abs(row)) / len(row) for row in weights[layer_to_prune]]\n",
    "            no_of_rows_to_prune = int(ratio * len(vals))\n",
    "            rows_to_prune = np.argsort(vals)[:no_of_rows_to_prune]\n",
    "            for i, layer_to_prune in enumerate(dense_layers_to_prune):\n",
    "                for row_to_prune in rows_to_prune:\n",
    "                    if row_to_prune in range(int(np.sum(lengths[:i])), int(np.sum(lengths[:i+1]))):\n",
    "                        weights[layer_to_prune][row_to_prune - int(np.sum(lengths[:i]))] = tf.zeros(weights[layer_to_prune][row_to_prune - int(np.sum(lengths[:i]))].shape)\n",
    "                        weights[layer_to_prune + 2][row_to_prune - int(np.sum(lengths[:i]))] = tf.zeros(weights[layer_to_prune][row_to_prune - int(np.sum(lengths[:i]))].shape)                \n",
    "            return weights\n",
    "        weights = self.get_weights()\n",
    "        conv_layers_to_prune = [0,3]\n",
    "        dense_layers_to_prune = [6,9,12]\n",
    "        weights = prune_conv_layers(conv_layers_to_prune, weights)\n",
    "        weights = prune_dense_layers(dense_layers_to_prune, weights)\n",
    "        self.set_weights(weights)\n",
    "        return False\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 18s 38ms/step - loss: 1.6374 - accuracy: 0.8581 - val_loss: 1.5225 - val_accuracy: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16875ce80>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomConvModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "              \n",
    "             )\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(x_test, y_test),\n",
    "         )\n",
    "#model.save('./saved-models/mini-pipeline-CNN-baseline-model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.055078713099161784, 0.05194876194000244, 0.05243547757466634, 0.05825615326563517, 0.058940446376800536, 0.054818495114644365, 0.05182290474573771, 0.05950473546981812, 0.05782819588979085, 0.05222630500793457, 0.044928797086079914, 0.06369850635528565, 0.07096808751424154, 0.052987829844156904, 0.051033949851989745, 0.05110149383544922, 0.05787749290466308, 0.058394261201222736, 0.04840754270553589, 0.07032877604166667, 0.0569369117418925, 0.048041065533955894, 0.054148324330647785, 0.054701709747314455, 0.06016249656677246, 0.053537468115488686, 0.06361176172892252, 0.05273702144622803, 0.052713934580485025, 0.057096306482950845, 0.05192641814549764, 0.05094271500905355, 0.051139338811238604, 0.06254170735677084, 0.04987547397613525, 0.05601600408554077, 0.05014275312423706, 0.055619581540425615, 0.05105504989624023, 0.05408846139907837, 0.056754199663798015, 0.06746216615041097, 0.056343328952789304, 0.06914838949839273, 0.06787993907928466, 0.04632422924041748, 0.06881059010823568, 0.05366703669230143, 0.0447201132774353, 0.06684943834940592, 0.05260312557220459, 0.05803537368774414, 0.047215716044108076, 0.06395613352457682, 0.05232075055440267, 0.052578314145406084, 0.05686047871907552, 0.0653207500775655, 0.06544831593831381, 0.06963222026824951, 0.06749451160430908, 0.05816073815027873, 0.05811443328857422, 0.05178589820861816, 0.060254422823588054, 0.058175428708394365, 0.06562473773956298, 0.05247944196065267, 0.04900306065877279, 0.055110673109690346, 0.05965835650761922, 0.0469368855158488, 0.04925942023595174, 0.054779303073883054, 0.0698915958404541, 0.06427746216456096, 0.06498010158538818, 0.06517197688420613, 0.055704041322072344, 0.05549939473470052, 0.07210721969604492, 0.06275705496470134, 0.059113856156667074, 0.06495473384857178, 0.05308109919230143, 0.05296398003896077, 0.0581103523572286, 0.04686037302017212, 0.05241897503534953, 0.047505974769592285, 0.06345520814259847, 0.05715783437093099, 0.06840929985046387, 0.07083730697631836, 0.05745824178059896, 0.04291355609893799, 0.07178994019826253, 0.0724952220916748, 0.059722089767456056, 0.051892884572347, 0.05695850849151611, 0.04762712319691976, 0.06460550626118979, 0.060939133167266846, 0.041621128718058266, 0.05255930821100871, 0.072585129737854, 0.05388139883677165, 0.07484761079152426, 0.0587425708770752, 0.05206678708394368, 0.05544909636179606, 0.08411428133646646, 0.056371275583902994, 0.05144882996877034, 0.04954641660054525, 0.0771162192026774, 0.05950926542282105, 0.06010928948720296, 0.056999492645263675, 0.04504451751708984, 0.048413753509521484, 0.07645088831583659, 0.06890880266825358, 0.06700634161631266, 0.06364030440648397, 0.07192869981129964, 0.06143385569254557, 0.0712620496749878, 0.0649619738260905, 0.06159274578094483, 0.04063862959543864, 0.04869121313095093, 0.05686709880828857, 0.08413381576538086, 0.0469531774520874, 0.05334761142730713, 0.04688280423482259, 0.08096752166748047, 0.06225650707880656, 0.06055601437886556, 0.061425638198852536, 0.06327190399169921, 0.04801090558369955, 0.06312602361043294, 0.057286985715230304, 0.06147128740946452, 0.054673806826273603, 0.05745499928792318, 0.0588830312093099, 0.06626944541931153, 0.05116174221038818, 0.07510643005371094, 0.053459604581197105, 0.05680093765258789, 0.06471570332845052, 0.05190703868865967, 0.060790054003397626, 0.06124189297358195, 0.055684566497802734, 0.054410072167714436, 0.05912950833638509, 0.0451172669728597, 0.054558181762695314, 0.0478888193766276, 0.04732500712076823, 0.056560428937276204, 0.04896640380223592, 0.056029987335205075, 0.04568184614181518, 0.06157396634419759, 0.06399752298990885, 0.060004806518554686, 0.059908239046732585, 0.05434439182281494, 0.04745616912841797, 0.06339506308237712, 0.07237441539764404, 0.043310240904490156, 0.0664576013882955, 0.06545406182607015, 0.043048731486002606, 0.058545462290445965, 0.05554872751235962, 0.04846954345703125, 0.057882467905680336, 0.04614519278208415, 0.05306451718012492, 0.05958841244379679, 0.06650102138519287, 0.06312286853790283, 0.05497411092122396, 0.06571104129155476, 0.06412223974863689, 0.04594673315684001, 0.05199726422627767, 0.06638394196828207, 0.05085185368855794, 0.05924302339553833, 0.07041230201721191, 0.053628687063852945, 0.07087890307108562, 0.05686306158701579, 0.07152881622314453, 0.06093360582987468, 0.06396986643473307, 0.06668790181477864, 0.05864423910776774, 0.05739057461420695, 0.06430946985880534, 0.054283873240153, 0.045264116923014325, 0.04890351295471192, 0.058861184120178225, 0.07246827284495036, 0.04778350194295247, 0.05364943742752075, 0.05390397707621256, 0.07346395651499431, 0.06379994551340738, 0.04712309837341309, 0.04782665967941284, 0.0506659189860026, 0.04614240328470866, 0.06354244550069173, 0.05171395142873128, 0.06458350817362467, 0.0622294823328654, 0.054185891151428224, 0.05369322299957276, 0.06368595361709595, 0.05829694668451945, 0.06507161060969034, 0.05116614898045858, 0.05133272012074788, 0.05984498659769694, 0.05236918528874715, 0.05608059167861938, 0.04653769334157308, 0.04888722499211629, 0.0681822935740153, 0.05260227123896281, 0.055081995328267415, 0.0516875425974528, 0.05897382895151774, 0.05254035790761312, 0.06883346239725749, 0.058659827709198, 0.050849982102711994, 0.04077288309733073, 0.0630385398864746, 0.06365791161855062, 0.05754736264546712, 0.05911573568979899, 0.06049004395802816, 0.056157890955607095, 0.06125795841217041, 0.06800165971120199, 0.05925054947535197, 0.050200764338175455, 0.059955906867980954, 0.0477825403213501, 0.04620467821756999, 0.04978048801422119, 0.05161726474761963, 0.056878193219502764, 0.0474017858505249, 0.06602279742558798, 0.0708399772644043, 0.062257758776346844, 0.060464914639790854, 0.05392361084620158, 0.060351896286010745, 0.06184778610865275, 0.04753318230311076, 0.042318673928578694, 0.044749343395233156, 0.04412382046381633, 0.0582806666692098, 0.04927563667297363, 0.056112051010131836, 0.05859185854593913, 0.056745203336079915, 0.050914200146993, 0.06140833695729574, 0.05628443956375122, 0.06136652231216431, 0.0584014892578125, 0.06784617106119792, 0.057416848341623944, 0.0559612234433492, 0.05663132667541504, 0.04788493315378825, 0.047804145018259685, 0.05600146849950154, 0.04204392433166504, 0.06066723267237346, 0.04627486864725749, 0.05743362903594971, 0.06529637575149536, 0.04711243708928426, 0.0564091165860494, 0.05093507766723633, 0.04375489155451457, 0.06598176558812459, 0.06162694692611694, 0.06889858245849609, 0.06930123170216879, 0.0540785551071167, 0.05006047089894613, 0.060812540849049884, 0.05159307320912679, 0.07354849974314372, 0.045570119222005205, 0.05043551921844482, 0.05544602870941162, 0.04731506506601969, 0.05437928835550944, 0.05091630617777507, 0.05861569245656331, 0.05384891033172608, 0.061890141169230146, 0.06068418025970459, 0.05810839335123698, 0.05429731210072835, 0.05510973930358887, 0.05916963418324788, 0.055414708455403645, 0.061358869075775146, 0.05248080889383952, 0.06546881198883056, 0.0614982803662618, 0.04921460151672363, 0.05420010089874268, 0.05263833204905192, 0.054887795448303224, 0.05220687389373779, 0.060624345143636064, 0.0681302785873413, 0.05458854039510091, 0.04225911299387614, 0.06568989753723145, 0.06420389811197917, 0.04498190482457479, 0.058066948254903154, 0.05206499099731445, 0.05532185633977254, 0.06452687581380208, 0.047113196055094404, 0.055017558733622234, 0.051112580299377444, 0.049593889713287355, 0.051191937923431394, 0.05714641412099202, 0.061966562271118165, 0.05146946509679159, 0.056975142161051436, 0.04980399608612061, 0.058541738986968996, 0.050432928403218585, 0.04004480044047038, 0.052089524269104, 0.04531383514404297, 0.050792221228281656, 0.0524101734161377, 0.05664541721343994, 0.042795991897583006, 0.04975115458170573, 0.057105088233947755, 0.061775847276051836, 0.05638496081034342, 0.056110866864522296, 0.06846693356831869, 0.052163036664326985, 0.04813025792439778, 0.06078306039174398, 0.054391602675120033, 0.05077661673227946, 0.044714800516764325, 0.05036328633626302, 0.04566996494928996, 0.062426984310150146, 0.06188247203826904, 0.05394398768742879, 0.05480713446935018, 0.059658360481262204, 0.04998650948206584, 0.05921049118041992, 0.055863690376281736, 0.05586017370223999, 0.06270969708760579, 0.04960085948308309, 0.07458977699279785, 0.05274856090545654, 0.051586302121480306, 0.058330762386322024, 0.04647241433461507, 0.051125343640645346, 0.05855692227681478, 0.053492188453674316, 0.07701630251748222, 0.06940721330188569, 0.07213068008422852, 0.07192413012186687, 0.05928818384806315, 0.07627068814777192, 0.07577900659470331, 0.0789177417755127, 0.07959262530008952, 0.06279925505320232, 0.08290412312462217, 0.080645828020005, 0.06900299730755034, 0.059578600383940195, 0.07378532205309186, 0.07753674756912958, 0.07254951340811593, 0.07854158537728446, 0.08401945659092494, 0.08810278347560338, 0.08303081421625047, 0.06467645508902413, 0.07645245960780553, 0.058319750286283945, 0.05978531496865409, 0.05448582058861142, 0.07544843355814616, 0.08602751436687651, 0.07182109355926514, 0.07733259314582461, 0.08517364660898845, 0.07958304314386278, 0.07807636260986328, 0.08173151243300665, 0.07753071330842518, 0.07750985735938662, 0.0820005734761556, 0.06518488838559106, 0.07635272684551421, 0.07063827628181094, 0.06254244986034575, 0.071652542977106, 0.08015562239147368, 0.07005204473223005, 0.0691096271787371, 0.06550317718869164, 0.08063943613143194, 0.06910788445245653, 0.07025720959617979, 0.07515694413866315, 0.07900433313278925, 0.0643044596626645, 0.05748727208092099, 0.07646960871560234, 0.07147430805932908, 0.07562434105646043, 0.08785228502182733, 0.07741665272485643, 0.07048154444921584, 0.069190399987357, 0.06581100395747594, 0.07536483378637404, 0.1010547365461077, 0.06979607400440034, 0.07148370288667225, 0.07810509772527785, 0.0777433713277181, 0.06561909403119769, 0.08224674065907796, 0.07068746998196557, 0.06371923855372838, 0.07394345033736456, 0.07057795070466541, 0.0888528823852539, 0.0737112703777495, 0.08586901142483666, 0.06676046053568523, 0.06267674196334112, 0.06152905736650739, 0.06201518149602981, 0.08211844308035714, 0.09022619610741026, 0.07416590054829915, 0.07066768691653297, 0.08314341590518043, 0.08480729375566755, 0.0733003162202381, 0.07900675705501012, 0.0738890568415324, 0.0766037248429798, 0.0837302945909046, 0.08380507287524995, 0.06747650532495408, 0.07246248495011103, 0.06837302730196998, 0.06347220284598214, 0.07504643712724958, 0.07652009101141066, 0.06980493522825695, 0.06013166336786179, 0.08584430671873547, 0.08643993877229236, 0.07856392860412598, 0.06547925585792178, 0.07659715697878883, 0.07324164254324776, 0.07749851544698079, 0.07274318309057326, 0.08388322307949975, 0.07659414836338588, 0.059494881402878536, 0.07632791428338914, 0.07205147402627128, 0.06874983651297432, 0.07170794691358294, 0.07926359063103086, 0.06588058812277657, 0.07226480188823882, 0.08361174946739561, 0.0705243916738601, 0.1353389024734497, 0.1433386445045471, 0.12849869728088378, 0.14186737537384034, 0.134263014793396, 0.13495641946792603, 0.12477223873138428, 0.14003410339355468, 0.14326834678649902, 0.15396561622619628, 0.13178321123123168, 0.14001322984695436, 0.1386794328689575, 0.1374420166015625, 0.10855714082717896, 0.12660821676254272, 0.12693560123443604, 0.10992048978805542, 0.11234687566757202, 0.13216265439987182, 0.12820167541503907, 0.1498160719871521, 0.15097471475601196, 0.16673924922943115, 0.13539252281188965, 0.14689066410064697, 0.12827643156051635, 0.13938409090042114, 0.13538000583648682, 0.1452454686164856, 0.16708898544311523, 0.15304869413375854, 0.12439559698104859, 0.14201682806015015, 0.15938248634338378, 0.13755136728286743, 0.14796888828277588, 0.14349617958068847, 0.11003379821777344, 0.1200607419013977, 0.13225327730178832, 0.15248850584030152, 0.15221941471099854, 0.15396227836608886, 0.16755188703536988, 0.15473860502243042, 0.13973373174667358, 0.1420575976371765, 0.13338245153427125, 0.11750253438949584, 0.17342605590820312, 0.14209387302398682, 0.10954296588897705, 0.15661829710006714, 0.13633058071136475, 0.1378672242164612, 0.10097291469573974, 0.13960373401641846, 0.14245359897613524, 0.14572972059249878, 0.12326183319091796, 0.15058062076568604, 0.1258089542388916, 0.1426430344581604, 0.13456077575683595, 0.11941975355148315, 0.16122665405273437, 0.13208208084106446, 0.13738857507705687, 0.11777405738830567, 0.14425302743911744, 0.10919559001922607, 0.16679415702819825, 0.139176607131958, 0.1433345317840576, 0.1514446496963501, 0.1525279998779297, 0.12522008419036865, 0.142475688457489, 0.16985340118408204, 0.13683729171752929, 0.14586790800094604, 0.14368301630020142, 0.14045403003692628]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.014397266959492436, 885, 61470)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_zeros_ratio(model.get_weights())\n",
    "model.prune_magnitude_global_struct(.9)\n",
    "get_zeros_ratio(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 150\n",
      "6 6\n",
      "50 150\n",
      "225 2400\n",
      "16 16\n",
      "225 2400\n",
      "6960 48000\n",
      "120 120\n",
      "6960 48000\n",
      "252 10080\n",
      "84 84\n",
      "252 10080\n",
      "0 840\n",
      "10 10\n",
      "0 840\n"
     ]
    }
   ],
   "source": [
    "xx = model.get_weights()\n",
    "for layer in xx:\n",
    "    print(np.count_nonzero(layer),len(layer.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "              \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3025097846984863, 0.10320000350475311]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 2.3023 - accuracy: 0.1118 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 2.3020 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x167f71ee0>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(x_test, y_test),\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014397266959492436, 885, 61470)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_zeros_ratio(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 150\n",
      "6 6\n",
      "125 150\n",
      "150 2400\n",
      "16 16\n",
      "150 2400\n",
      "0 48000\n",
      "120 120\n",
      "0 48000\n",
      "0 10080\n",
      "84 84\n",
      "0 10080\n",
      "610 840\n",
      "10 10\n",
      "610 840\n"
     ]
    }
   ],
   "source": [
    "xx = model.get_weights()\n",
    "for layer in xx:\n",
    "    print(np.count_nonzero(layer),len(layer.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
