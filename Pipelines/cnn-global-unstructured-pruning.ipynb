{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Pruning implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import foolbox as fb\n",
    "import random\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune, Train Attack Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_success_rates = []\n",
    "cw_success_rates = []\n",
    "all_accuracies = []\n",
    "ITERATIONS = 2\n",
    "compression_rates = [1, 2, 4, 8, 16, 32, 64]\n",
    "pruning_ratios = [1-1/x for x in compression_rates]\n",
    "    \n",
    "for j in tqdm(range(ITERATIONS)):\n",
    "    accuracies = []\n",
    "    pgd_success_rate = []\n",
    "    cw_success_rate = []\n",
    "    model = initialize_base_model(j, save_weights=True)\n",
    "    for index, pruning_ratio in tqdm(enumerate(pruning_ratios)):\n",
    "        model.load_weights(f'./saved-weights/base-model-weights-cnn-glob-{j}')\n",
    "        for i in range(index + 1):\n",
    "            if i != index:\n",
    "                model.prune_globally(pruning_ratios[i])\n",
    "                model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                              metrics=['accuracy'],\n",
    "                              experimental_run_tf_function=False\n",
    "                             )\n",
    "                model = train_model(model, to_convergence=False)\n",
    "            if i == index:\n",
    "                print('final pruning and eval')\n",
    "                model.prune_globally(pruning_ratios[i])\n",
    "                model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                              metrics=['accuracy'],\n",
    "                              experimental_run_tf_function=False\n",
    "                             )\n",
    "                model = train_model(model, to_convergence=True)\n",
    "                accuracies.append(model.evaluate(x_test, y_test, verbose=0))\n",
    "                pgd_success_rate.append(pgd_attack(model))\n",
    "                #cw_success_rate.append(cw2_attack(model))\n",
    "                \n",
    "    all_accuracies.append(accuracies)\n",
    "    pgd_success_rates.append(pgd_success_rate)\n",
    "    cw_success_rates.append(cw_success_rate)\n",
    "#write to csv and json\n",
    "\n",
    "pd.DataFrame(all_accuracies).to_csv('saved-results/cnn-accuracies-glob-prunning.csv',index=False)\n",
    "with open('saved-results/cnn-accuracies-glob-prunning.json', 'w') as f:\n",
    "    json.dump(all_accuracies, f)\n",
    "    \n",
    "pd.DataFrame(pgd_success_rates).to_csv('saved-results/cnn-pgd-success-glob-prunning.csv',index=False)\n",
    "with open('saved-results/cnn-pgd-success-glob-prunning.json', 'w') as f:\n",
    "    json.dump(pgd_success_rates, f)\n",
    "pd.DataFrame(cw_success_rates).to_csv('saved-results/cnn-cw-success-glob-prunning.csv',index=False)\n",
    "with open('saved-results/cnn-cw-success-glob-prunning.json', 'w') as f:\n",
    "    json.dump(cw_success_rates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(compression_rates, avg_success_rates)\n",
    "plt.axis([0,100,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(compression_rates, avg_accuracies)\n",
    "plt.axis([0,100,0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_base_model(index, save_weights=False):\n",
    "    model = CustomConvModel()\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "\n",
    "                 )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=x_train,\n",
    "              y=y_train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n",
    "    if save_weights == True:\n",
    "        model.save_weights(f'./saved-weights/base-model-weights-cnn-glob-{index}')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=100,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=5,\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def prune_weights(model, pruning_ratio):\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        \n",
    "        if (index == 9) or (index == 12) :\n",
    "            #print(weight.shape)\n",
    "            #print(index)\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index+2].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            flat_weights_to_prune_df = pd.DataFrame(flat_weights_to_prune)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            #print(len(flat_weights))\n",
    "            #print('no of weights',no_of_weights_to_prune)\n",
    "            #print('weights to prune shape', flat_weights_to_prune.shape)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+2].shape\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            weights_to_prune[index+2] = weights_reshaped\n",
    "    #print(weights_to_prune)\n",
    "    return weights_to_prune\n",
    "\n",
    "def pgd_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.LinfProjectedGradientDescentAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[25/255]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/500\n",
    "\n",
    "def cw2_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.L2CarliniWagnerAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        #epsilons=[.5]\n",
    "        epsilons=None\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/len(y)\n",
    "\n",
    "def prune_conv_layers(pruning_ratio):\n",
    "    layer_to_prune = [0, 3]\n",
    "    pruned_weights = model.get_weights()\n",
    "    \n",
    "    for layer in layer_to_prune:\n",
    "        converted_weights = convert_from_hwio_to_iohw(model.get_weights()[layer])\n",
    "        converted_mask = convert_from_hwio_to_iohw(model.get_weights()[layer + 2]).numpy()\n",
    "        for input_index, input_layer in enumerate(converted_weights):\n",
    "\n",
    "            for kernel_index, kernel in enumerate(input_layer):\n",
    "                dims = kernel.shape\n",
    "                flat_weights = kernel.numpy().flatten()\n",
    "                flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "                #print(no_of_weights_to_prune)\n",
    "                indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    flat_masks[idx_to_delete] = 0\n",
    "\n",
    "                converted_mask[input_index][kernel_index] = flat_masks.reshape(dims)\n",
    "        back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "        pruned_weights[layer+2] = back_converted_mask\n",
    "    \n",
    "    return pruned_weights\n",
    "\n",
    "def convert_from_hwio_to_iohw(weights_nchw):\n",
    "    return tf.transpose(weights_nchw, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def convert_from_iohw_to_hwio(weights_nhwc):\n",
    "    return tf.transpose(weights_nhwc, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "def get_average_accuracies(all_accuracies):\n",
    "    acc_per_pruning_rate=[]\n",
    "    for i in range(len(all_accuracies)):\n",
    "        for j in range(len(all_accuracies[i])):\n",
    "\n",
    "            try:\n",
    "                acc_per_pruning_rate[j].append(all_accuracies[i][j][1])\n",
    "            except:\n",
    "                acc_per_pruning_rate.append([])\n",
    "                acc_per_pruning_rate[j].append(all_accuracies[i][j][1])\n",
    "    avg_acc_per_pruning_rate = [sum(x)/len(x) for x in acc_per_pruning_rate]; avg_acc_per_pruning_rate\n",
    "    return avg_acc_per_pruning_rate\n",
    "\n",
    "def get_average_success_rates(all_success_rates):\n",
    "    success_per_pruning_rate=[]\n",
    "    for i in range(len(all_success_rates)):\n",
    "        for j in range(len(all_success_rates[i])):\n",
    "\n",
    "            try:\n",
    "                success_per_pruning_rate[j].append(all_success_rates[i][j])\n",
    "            except:\n",
    "                success_per_pruning_rate.append([])\n",
    "                success_per_pruning_rate[j].append(all_success_rates[i][j])\n",
    "    avg_success_per_pruning_rate = [sum(x)/len(x) for x in success_per_pruning_rate];avg_success_per_pruning_rate\n",
    "    return avg_success_per_pruning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x = tf.convert_to_tensor(x_train[:500].reshape(500,28*28))\n",
    "y = tf.convert_to_tensor([y_train[:500]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'weights_conv_1': tf.Variable(tf.random.normal([5, 5, 1, 6])),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'weights_conv_2': tf.Variable(tf.random.normal([5, 5, 6, 16])),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'weights_conv_3': tf.Variable(tf.random.normal([1, 1, 16, 120])),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'weights_dense_1': tf.Variable(tf.random.normal([5*5*16, 120])),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'weights_dense_2': tf.Variable(tf.random.normal([120, 84])),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'weights_dense_3': tf.Variable(tf.random.normal([84, 10])),\n",
    "}\n",
    "\n",
    "masks = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'mask_conv_1': tf.Variable(tf.ones([5, 5, 1, 6]), trainable=False),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'mask_conv_2': tf.Variable(tf.ones([5, 5, 6, 16]), trainable=False),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'mask_conv_3': tf.Variable(tf.ones([1, 1, 16, 120]), trainable=False),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'mask_dense_1': tf.Variable(tf.ones([5*5*16, 120]), trainable=False),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'mask_dense_2': tf.Variable(tf.ones([120, 84]), trainable=False),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'mask_dense_3': tf.Variable(tf.ones([84, 10]), trainable=False),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    #output depth\n",
    "    'bias_conv_1': tf.Variable(tf.random.normal([6])),\n",
    "    'bias_conv_2': tf.Variable(tf.random.normal([16])),\n",
    "    'bias_dense_1': tf.Variable(tf.random.normal([120])),\n",
    "    'bias_dense_2': tf.Variable(tf.random.normal([84])),\n",
    "    'bias_dense_3': tf.Variable(tf.random.normal([10])),\n",
    "}\n",
    "\n",
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='valid'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "#        return tf.keras.layers.AveragePooling2D(pool_size=(self.k, self.k), strides=None, padding=self.p, data_format='channels_first')(inputs)\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p,)# data_format='NCHW')\n",
    "    \n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, weights, mask, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        self.a = activation\n",
    "        self.m = mask\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        \n",
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(weights['weights_conv_1'], masks['mask_conv_1'], biases['bias_conv_1'], 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(weights['weights_conv_2'], masks['mask_conv_2'], biases['bias_conv_2'], 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "        #self.conv3 = CustomConvLayer(weights['weights_conv_3'], masks['mask_conv_3'], biases['bias_dense_1'], 1, 'VALID')\n",
    "        self.dense1 = CustomDenseLayer(weights['weights_dense_1'], masks['mask_dense_1'], biases['bias_dense_1'], 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(weights['weights_dense_2'], masks['mask_dense_2'], biases['bias_dense_2'], 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(weights['weights_dense_3'], masks['mask_dense_3'], biases['bias_dense_3'], 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, shape=[-1,28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x =  self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    def prune_randomly(self, ratio):\n",
    "        def prune_conv_layers_locally(self, ratio):\n",
    "            conv_layer_to_prune = [0, 3]\n",
    "            weights = model.get_weights()\n",
    "            for layer in conv_layer_to_prune:\n",
    "                converted_weights = convert_from_hwio_to_iohw(weights[layer]).numpy()\n",
    "                converted_mask = convert_from_hwio_to_iohw(weights[layer + 2]).numpy()\n",
    "                for input_index, input_layer in enumerate(converted_weights):\n",
    "                    for kernel_index, kernel in enumerate(input_layer):\n",
    "                        shape = kernel.shape\n",
    "                        flat_weights = kernel.flatten()\n",
    "                        flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                        \n",
    "                        no_of_weighs_to_prune = ratio * len(flat_weights)\n",
    "                        # find unpruned weights\n",
    "                        non_zero_weights = np.nonzero(flat_masks)[0]\n",
    "                        # calculate the amount of weights to be pruned this round\n",
    "                        no_of_weights_to_prune_left = int(no_of_weighs_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "                        # shuffle all non-zero weights\n",
    "                        random.shuffle(non_zero_weights)\n",
    "                        # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "                        indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "                        \n",
    "                        for idx_to_delete in indices_to_delete:\n",
    "                            flat_masks[idx_to_delete] = 0\n",
    "                            flat_weights[idx_to_delete] = 0\n",
    "                        converted_mask[input_index][kernel_index] = flat_masks.reshape(shape)\n",
    "                        converted_weights[input_index][kernel_index] = flat_weights.reshape(shape)\n",
    "                back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "                back_converted_weights = convert_from_iohw_to_hwio(converted_weights)\n",
    "                weights[layer] = back_converted_weights\n",
    "                weights[layer+2] = back_converted_mask\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        \n",
    "        def prune_dense_layers_locally(self, ratio):\n",
    "            dense_layer_to_prune = [6, 9, 12]\n",
    "            weights = model.get_weights()\n",
    "            for index, weight in enumerate(weights):\n",
    "                if index in dense_layer_to_prune:\n",
    "                    shape = weight.shape\n",
    "                    flat_weights = weight.flatten()\n",
    "                    flat_mask = weights[index+2].flatten()\n",
    "                    no_of_weighs_to_prune = ratio * len(flat_weights)\n",
    "                    # find unpruned weights\n",
    "                    non_zero_weights = np.nonzero(flat_mask)[0]\n",
    "                    # calculate the amount of weights to be pruned this round\n",
    "                    no_of_weights_to_prune_left = int(no_of_weighs_to_prune - (len(flat_weights) - len(non_zero_weights)) )\n",
    "                    # shuffle all non-zero weights\n",
    "                    random.shuffle(non_zero_weights)\n",
    "                    # and take the indices of the first x weights where x is the number of weights to be pruned this round\n",
    "                    indices_to_delete = non_zero_weights[:no_of_weights_to_prune_left]\n",
    "                    for idx_to_delete in indices_to_delete:\n",
    "                        flat_mask[idx_to_delete] = 0\n",
    "                        flat_weights[idx_to_delete] = 0\n",
    "\n",
    "                    mask_reshaped = flat_mask.reshape(shape)\n",
    "                    weights_reshaped = flat_weights.reshape(shape)\n",
    "                    weights[index+2] = mask_reshaped\n",
    "                    weights[index] = weights_reshaped\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        prune_conv_layers_locally(self, ratio)\n",
    "        prune_dense_layers_locally(self,ratio)\n",
    "    \n",
    "    def prune_globally(self, ratio):\n",
    "        #flat out all weights:\n",
    "        conv_layer_to_prune = [0, 3]\n",
    "        dense_layer_to_prune = [6, 9, 12]\n",
    "        weights = self.get_weights()\n",
    "        flat_weights = []\n",
    "        flat_mask = []\n",
    "        for x in conv_layer_to_prune + dense_layer_to_prune:\n",
    "            flat_weights = np.append(flat_weights, weights[x])\n",
    "            flat_mask = np.append(flat_mask, weights[x+2])\n",
    "            \n",
    "        no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "        indices_to_delete = np.abs(flat_weights).argsort(0)[:no_of_weights_to_prune]\n",
    "        \n",
    "        for idx_to_delete in indices_to_delete:\n",
    "            flat_mask[idx_to_delete] = 0\n",
    "            flat_weights[idx_to_delete] = 0\n",
    "        z = 0\n",
    "        for x in conv_layer_to_prune + dense_layer_to_prune:\n",
    "            weights[x] = flat_weights[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            weights[x + 2] = flat_mask[z:z + np.prod(weights[x].shape)].reshape(weights[x].shape)\n",
    "            z = z + np.prod(weights[x].shape)            \n",
    "        self.set_weights(weights)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    def prune_locally(self, ratio):\n",
    "        def prune_conv_layers_locally(self, ratio):\n",
    "            conv_layer_to_prune = [0, 3]\n",
    "            weights = model.get_weights()\n",
    "            for layer in conv_layer_to_prune:\n",
    "                converted_weights = convert_from_hwio_to_iohw(weights[layer]).numpy()\n",
    "                converted_mask = convert_from_hwio_to_iohw(weights[layer + 2]).numpy()\n",
    "                for input_index, input_layer in enumerate(converted_weights):\n",
    "                    for kernel_index, kernel in enumerate(input_layer):\n",
    "                        shape = kernel.shape\n",
    "                        flat_weights = kernel.flatten()\n",
    "                        flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                        #flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                        #flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                        no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                        #print(no_of_weights_to_prune)\n",
    "                        #indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                        indices_to_delete = np.abs(flat_weights).argsort(0)[:no_of_weights_to_prune]\n",
    "\n",
    "\n",
    "                        for idx_to_delete in indices_to_delete:\n",
    "                            flat_masks[idx_to_delete] = 0\n",
    "                            flat_weights[idx_to_delete] = 0\n",
    "\n",
    "                        converted_mask[input_index][kernel_index] = flat_masks.reshape(shape)\n",
    "                        converted_weights[input_index][kernel_index] = flat_weights.reshape(shape)\n",
    "                back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "                back_converted_weights = convert_from_iohw_to_hwio(converted_weights)\n",
    "                weights[layer] = back_converted_weights\n",
    "                weights[layer+2] = back_converted_mask\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        \n",
    "        def prune_dense_layers_locally(self, ratio):\n",
    "            dense_layer_to_prune = [6, 9, 12]\n",
    "            weights = model.get_weights()\n",
    "            for index, weight in enumerate(weights):\n",
    "                if index in dense_layer_to_prune:\n",
    "                    shape = weight.shape\n",
    "                    flat_weights = weight.flatten()\n",
    "                    flat_mask = weights[index+2].flatten()\n",
    "\n",
    "                    no_of_weights_to_prune = int(len(flat_weights)*ratio)\n",
    "                    indices_to_delete = np.abs(flat_weights).argsort()[:no_of_weights_to_prune]\n",
    "                    for idx_to_delete in indices_to_delete:\n",
    "                        flat_mask[idx_to_delete] = 0\n",
    "                        flat_weights[idx_to_delete] = 0\n",
    "\n",
    "                    mask_reshaped = flat_mask.reshape(shape)\n",
    "                    weights_reshaped = flat_weights.reshape(shape)\n",
    "                    weights[index+2] = mask_reshaped\n",
    "                    weights[index] = weights_reshaped\n",
    "            self.set_weights(weights)\n",
    "            return True\n",
    "        prune_conv_layers_locally(self,ratio)\n",
    "        prune_dense_layers_locally(self,ratio)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 291ms/step - loss: 2.3692 - accuracy: 0.0840 - val_loss: 2.3462 - val_accuracy: 0.1057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15e6b2af0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomConvModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "              \n",
    "             )\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(x=x_train[:500],\n",
    "          y=y_train[:500],\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(x_test, y_test),\n",
    "         )\n",
    "#model.save('./saved-models/mini-pipeline-CNN-baseline-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./saved-models/mini-pipeline-CNN-baseline-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/florianmerkle/dev/foolbox/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pgd_attack(model_to_attack):\n",
    "    fmodel = fb.models.TensorFlowModel(model_to_attack, bounds=(0,1))\n",
    "    attack = fb.attacks.LinfProjectedGradientDescentAttack()\n",
    "    adversarials = attack(\n",
    "        fmodel,\n",
    "        x,\n",
    "        y,\n",
    "        epsilons=[25/255]\n",
    "    )\n",
    "    return np.count_nonzero(adversarials[2])/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
