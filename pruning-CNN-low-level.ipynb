{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "#tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'weights_conv_1': tf.Variable(tf.random.normal([5, 5, 1, 6])),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'weights_conv_2': tf.Variable(tf.random.normal([5, 5, 6, 16])),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'weights_conv_3': tf.Variable(tf.random.normal([1, 1, 16, 120])),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'weights_dense_1': tf.Variable(tf.random.normal([5*5*16, 120])),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'weights_dense_2': tf.Variable(tf.random.normal([120, 84])),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'weights_dense_3': tf.Variable(tf.random.normal([84, 10])),\n",
    "}\n",
    "\n",
    "masks = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'mask_conv_1': tf.Variable(tf.ones([5, 5, 1, 6]), trainable=False),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'mask_conv_2': tf.Variable(tf.ones([5, 5, 6, 16]), trainable=False),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'mask_conv_3': tf.Variable(tf.ones([1, 1, 16, 120]), trainable=False),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'mask_dense_1': tf.Variable(tf.ones([5*5*16, 120]), trainable=False),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'mask_dense_2': tf.Variable(tf.ones([120, 84]), trainable=False),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'mask_dense_3': tf.Variable(tf.ones([84, 10]), trainable=False),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    #output depth\n",
    "    'bias_conv_1': tf.Variable(tf.random.normal([6])),\n",
    "    'bias_conv_2': tf.Variable(tf.random.normal([16])),\n",
    "    'bias_dense_1': tf.Variable(tf.random.normal([120])),\n",
    "    'bias_dense_2': tf.Variable(tf.random.normal([84])),\n",
    "    'bias_dense_3': tf.Variable(tf.random.normal([10])),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        print('inputs',inputs)\n",
    "        #print('weights', self.w)\n",
    "        #print('masks', self.m)\n",
    "        print('weights * masks',tf.multiply(self.w, self.m))\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        print('x', x)\n",
    "        #print('bias', self.b)\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        #print('x', x)\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='valid'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "#        return tf.keras.layers.AveragePooling2D(pool_size=(self.k, self.k), strides=None, padding=self.p, data_format='channels_first')(inputs)\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p,)# data_format='NCHW')\n",
    "    \n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, weights, mask, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        self.a = activation\n",
    "        self.m = mask\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print('dense w',self.w)\n",
    "        #print('dense i',inputs)\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        print('bias ',self.b)\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(weights['weights_conv_1'], masks['mask_conv_1'], biases['bias_conv_1'], 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(weights['weights_conv_2'], masks['mask_conv_2'], biases['bias_conv_2'], 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "        #self.conv3 = CustomConvLayer(weights['weights_conv_3'], masks['mask_conv_3'], biases['bias_dense_1'], 1, 'VALID')\n",
    "        self.dense1 = CustomDenseLayer(weights['weights_dense_1'], masks['mask_dense_1'], biases['bias_dense_1'], 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(weights['weights_dense_2'], masks['mask_dense_2'], biases['bias_dense_2'], 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(weights['weights_dense_3'], masks['mask_dense_3'], biases['bias_dense_3'], 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        print('input shape', inputs.shape)\n",
    "        x = tf.reshape(inputs, shape=[-1,28, 28, 1])\n",
    "        print('after reshape',x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print('after conv1', x.shape)\n",
    "        x = self.maxpool1(x)\n",
    "        print('after pool1',x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print('after conv2',x.shape)\n",
    "        x = self.maxpool2(x)\n",
    "        #print('yo',x.shape)\n",
    "        #x = layers.Flatten()(x)\n",
    "        print('after pool2',x.shape)\n",
    "        #x = self.conv3(x)\n",
    "        \n",
    "        print('after conv3',x.shape)\n",
    "        x = layers.Flatten()(x)\n",
    "        #print('after flatten',x.shape)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        print(x.shape)\n",
    "        x =  self.dense3(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomConvModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "input shape (None, 784)\n",
      "after reshape (None, 28, 28, 1)\n",
      "inputs Tensor(\"custom_conv_model_16/Reshape:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
      "weights * masks Tensor(\"custom_conv_model_16/custom_conv_layer_47/Mul:0\", shape=(5, 5, 1, 6), dtype=float32)\n",
      "x Tensor(\"custom_conv_model_16/custom_conv_layer_47/Conv2D:0\", shape=(None, 28, 28, 6), dtype=float32)\n",
      "after conv1 (None, 28, 28, 6)\n",
      "after pool1 (None, 14, 14, 6)\n",
      "inputs Tensor(\"custom_conv_model_16/custom_pool_layer_32/AvgPool2D:0\", shape=(None, 14, 14, 6), dtype=float32)\n",
      "weights * masks Tensor(\"custom_conv_model_16/custom_conv_layer_48/Mul:0\", shape=(5, 5, 6, 16), dtype=float32)\n",
      "x Tensor(\"custom_conv_model_16/custom_conv_layer_48/Conv2D:0\", shape=(None, 10, 10, 16), dtype=float32)\n",
      "after pool2 (None, 5, 5, 16)\n",
      "after conv3 (None, 5, 5, 16)\n",
      "bias  <tf.Variable 'Variable:0' shape=(120,) dtype=float32>\n",
      "bias  <tf.Variable 'Variable:0' shape=(84,) dtype=float32>\n",
      "(None, 84)\n",
      "bias  <tf.Variable 'Variable:0' shape=(10,) dtype=float32>\n",
      "(None, 10)\n",
      "input shape (None, 784)\n",
      "after reshape (None, 28, 28, 1)\n",
      "inputs Tensor(\"custom_conv_model_16/Reshape:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
      "weights * masks Tensor(\"custom_conv_model_16/custom_conv_layer_47/Mul:0\", shape=(5, 5, 1, 6), dtype=float32)\n",
      "x Tensor(\"custom_conv_model_16/custom_conv_layer_47/Conv2D:0\", shape=(None, 28, 28, 6), dtype=float32)\n",
      "after conv1 (None, 28, 28, 6)\n",
      "after pool1 (None, 14, 14, 6)\n",
      "inputs Tensor(\"custom_conv_model_16/custom_pool_layer_32/AvgPool2D:0\", shape=(None, 14, 14, 6), dtype=float32)\n",
      "weights * masks Tensor(\"custom_conv_model_16/custom_conv_layer_48/Mul:0\", shape=(5, 5, 6, 16), dtype=float32)\n",
      "x Tensor(\"custom_conv_model_16/custom_conv_layer_48/Conv2D:0\", shape=(None, 10, 10, 16), dtype=float32)\n",
      "after pool2 (None, 5, 5, 16)\n",
      "after conv3 (None, 5, 5, 16)\n",
      "bias  <tf.Variable 'Variable:0' shape=(120,) dtype=float32>\n",
      "bias  <tf.Variable 'Variable:0' shape=(84,) dtype=float32>\n",
      "(None, 84)\n",
      "bias  <tf.Variable 'Variable:0' shape=(10,) dtype=float32>\n",
      "(None, 10)\n",
      "937/938 [============================>.] - ETA: 0s - loss: 2.0727 - accuracy: 0.3828input shape (None, 784)\n",
      "after reshape (None, 28, 28, 1)\n",
      "inputs Tensor(\"custom_conv_model_16/Reshape:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
      "weights * masks Tensor(\"custom_conv_model_16/custom_conv_layer_47/Mul:0\", shape=(5, 5, 1, 6), dtype=float32)\n",
      "x Tensor(\"custom_conv_model_16/custom_conv_layer_47/Conv2D:0\", shape=(None, 28, 28, 6), dtype=float32)\n",
      "after conv1 (None, 28, 28, 6)\n",
      "after pool1 (None, 14, 14, 6)\n",
      "inputs Tensor(\"custom_conv_model_16/custom_pool_layer_32/AvgPool2D:0\", shape=(None, 14, 14, 6), dtype=float32)\n",
      "weights * masks Tensor(\"custom_conv_model_16/custom_conv_layer_48/Mul:0\", shape=(5, 5, 6, 16), dtype=float32)\n",
      "x Tensor(\"custom_conv_model_16/custom_conv_layer_48/Conv2D:0\", shape=(None, 10, 10, 16), dtype=float32)\n",
      "after pool2 (None, 5, 5, 16)\n",
      "after conv3 (None, 5, 5, 16)\n",
      "bias  <tf.Variable 'Variable:0' shape=(120,) dtype=float32>\n",
      "bias  <tf.Variable 'Variable:0' shape=(84,) dtype=float32>\n",
      "(None, 84)\n",
      "bias  <tf.Variable 'Variable:0' shape=(10,) dtype=float32>\n",
      "(None, 10)\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 2.0725 - accuracy: 0.3830 - val_loss: 1.9135 - val_accuracy: 0.5449\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 1.8731 - accuracy: 0.5859 - val_loss: 1.7693 - val_accuracy: 0.6911\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.7478 - accuracy: 0.7122 - val_loss: 1.7185 - val_accuracy: 0.7422\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 20s 22ms/step - loss: 1.6665 - accuracy: 0.7952 - val_loss: 1.6265 - val_accuracy: 0.8357\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.6166 - accuracy: 0.8451 - val_loss: 1.5955 - val_accuracy: 0.8656\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 1.5921 - accuracy: 0.8696 - val_loss: 1.5820 - val_accuracy: 0.8778\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5801 - accuracy: 0.8818 - val_loss: 1.5664 - val_accuracy: 0.8949\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5700 - accuracy: 0.8914 - val_loss: 1.5665 - val_accuracy: 0.8950\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5650 - accuracy: 0.8964 - val_loss: 1.5603 - val_accuracy: 0.9003\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.5574 - accuracy: 0.9039 - val_loss: 1.5488 - val_accuracy: 0.9136\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5543 - accuracy: 0.9069 - val_loss: 1.5511 - val_accuracy: 0.9105\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5466 - accuracy: 0.9151 - val_loss: 1.5428 - val_accuracy: 0.9187\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5456 - accuracy: 0.9158 - val_loss: 1.5450 - val_accuracy: 0.9170\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.5416 - accuracy: 0.9195 - val_loss: 1.5378 - val_accuracy: 0.9235\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.5395 - accuracy: 0.9219 - val_loss: 1.5359 - val_accuracy: 0.9256\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.5344 - accuracy: 0.9271 - val_loss: 1.5307 - val_accuracy: 0.9310\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5312 - accuracy: 0.9301 - val_loss: 1.5341 - val_accuracy: 0.9264\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5306 - accuracy: 0.9306 - val_loss: 1.5271 - val_accuracy: 0.9336\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.5274 - accuracy: 0.9340 - val_loss: 1.5276 - val_accuracy: 0.9328\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 1.5275 - accuracy: 0.9338 - val_loss: 1.5287 - val_accuracy: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15469fb50>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          validation_data=(x_test, y_test),\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 6)\n",
      "(6,)\n",
      "(5, 5, 1, 6)\n",
      "(5, 5, 6, 16)\n",
      "(16,)\n",
      "(5, 5, 6, 16)\n",
      "(400, 120)\n",
      "(120,)\n",
      "(400, 120)\n",
      "(120, 84)\n",
      "(84,)\n",
      "(120, 84)\n",
      "(84, 10)\n",
      "(10,)\n",
      "(84, 10)\n",
      "[[ 1.6544837  -1.2155174  -0.01104877 ... -1.4212358  -0.69011974\n",
      "   0.7736215 ]\n",
      " [ 1.304302   -0.36460733  0.52945864 ...  2.3375378   1.7216002\n",
      "  -0.23331481]\n",
      " [-0.42149517 -0.97565067  1.5907264  ... -0.33470914  1.1034594\n",
      "  -0.4771902 ]\n",
      " ...\n",
      " [-1.4904262  -0.85657346 -1.2877682  ...  0.26765004  0.20881368\n",
      "  -0.6255907 ]\n",
      " [-0.4263792   0.06906602 -0.01037085 ... -0.3516376   0.37083548\n",
      "  -0.58330184]\n",
      " [ 0.85798514 -0.31575802 -1.3953352  ... -0.66209424 -1.23648\n",
      "  -0.7591743 ]]\n"
     ]
    }
   ],
   "source": [
    "all_layers = model.get_weights()\n",
    "for layer in all_layers:\n",
    "    print(layer.shape)\n",
    "    \n",
    "print(all_layers[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_conv_layers(pruning_ratio):\n",
    "    layer_to_prune = [0, 3]\n",
    "    pruned_weights = model.get_weights()\n",
    "    \n",
    "    for layer in layer_to_prune:\n",
    "        converted_weights = convert_from_hwio_to_iohw(model.get_weights()[layer])\n",
    "        converted_mask = convert_from_hwio_to_iohw(model.get_weights()[layer + 2]).numpy()\n",
    "        for input_index, input_layer in enumerate(converted_weights):\n",
    "\n",
    "            for kernel_index, kernel in enumerate(input_layer):\n",
    "                dims = kernel.shape\n",
    "                flat_weights = kernel.numpy().flatten()\n",
    "                flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "                #print(no_of_weights_to_prune)\n",
    "                indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    flat_masks[idx_to_delete] = 0\n",
    "\n",
    "                converted_mask[input_index][kernel_index] = flat_masks.reshape(dims)\n",
    "        back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "        pruned_weights[layer+2] = back_converted_mask\n",
    "    \n",
    "    return pruned_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 84)\n",
      "9\n",
      "10080\n",
      "no of weights 0\n",
      "weights to prune shape (10080,)\n",
      "(84, 10)\n",
      "12\n",
      "840\n",
      "no of weights 0\n",
      "weights to prune shape (840,)\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 1.5278 - accuracy: 0.9336 - val_loss: 1.5251 - val_accuracy: 0.9365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:33<01:40, 33.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 84)\n",
      "9\n",
      "10080\n",
      "no of weights 5040\n",
      "weights to prune shape (10080,)\n",
      "(84, 10)\n",
      "12\n",
      "840\n",
      "no of weights 420\n",
      "weights to prune shape (840,)\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.5558 - accuracy: 0.9060 - val_loss: 1.5326 - val_accuracy: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:53<00:59, 29.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 84)\n",
      "9\n",
      "10080\n",
      "no of weights 8064\n",
      "weights to prune shape (10080,)\n",
      "(84, 10)\n",
      "12\n",
      "840\n",
      "no of weights 672\n",
      "weights to prune shape (840,)\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.9076 - accuracy: 0.5530 - val_loss: 1.7797 - val_accuracy: 0.6841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [01:15<00:27, 27.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 84)\n",
      "9\n",
      "10080\n",
      "no of weights 9072\n",
      "weights to prune shape (10080,)\n",
      "(84, 10)\n",
      "12\n",
      "840\n",
      "no of weights 756\n",
      "weights to prune shape (840,)\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 1.8078 - accuracy: 0.6611 - val_loss: 1.6771 - val_accuracy: 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:33<00:00, 23.30s/it]\n"
     ]
    }
   ],
   "source": [
    "pruning_ratios = [0.0, .5, 0.8, 0.9]\n",
    "pre_pruning_weight_archive = []\n",
    "post_pruning_weight_archive = []\n",
    "post_fine_tune_weight_archive = []\n",
    "pre_fine_tune_results = []\n",
    "post_fine_tune_results = []\n",
    "\n",
    "for pruning_ratio in tqdm(pruning_ratios):\n",
    "    pre_pruning_weight_archive.append(model.get_weights())\n",
    "    pruned_weights = prune_conv_layers(pruning_ratio)\n",
    "    model.set_weights(pruned_weights)\n",
    "    pruned_weights = prune_weights(model, pruning_ratio)\n",
    "    model.set_weights(pruned_weights)\n",
    "    post_pruning_weight_archive.append(model.get_weights())\n",
    "    pre_fine_tune_results.append(model.evaluate(x_test, y_test, verbose=0))\n",
    "    model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          batch_size=64,\n",
    "          epochs=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "         )\n",
    "    post_fine_tune_results.append(model.evaluate(x_test, y_test, verbose=0))\n",
    "    post_fine_tune_weight_archive.append(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weights(model, pruning_ratio):\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        \n",
    "        if (index == 9) or (index == 12) :\n",
    "            print(weight.shape)\n",
    "            print(index)\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index+2].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            flat_weights_to_prune_df = pd.DataFrame(flat_weights_to_prune)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            print(len(flat_weights))\n",
    "            print('no of weights',no_of_weights_to_prune)\n",
    "            print('weights to prune shape', flat_weights_to_prune.shape)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+2].shape\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            weights_to_prune[index+2] = weights_reshaped\n",
    "    #print(weights_to_prune)\n",
    "    return weights_to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning ratio:  0.0 accuracy before fine tuning:  0.9325000047683716 accuracy after fine tuning:  0.9365000128746033\n",
      "pruning ratio:  0.5 accuracy before fine tuning:  0.7851999998092651 accuracy after fine tuning:  0.9301999807357788\n",
      "pruning ratio:  0.8 accuracy before fine tuning:  0.16220000386238098 accuracy after fine tuning:  0.6840999722480774\n",
      "pruning ratio:  0.9 accuracy before fine tuning:  0.20149999856948853 accuracy after fine tuning:  0.7943999767303467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index,res in enumerate(pruning_ratios):\n",
    "    print('pruning ratio: ', \n",
    "          res, \n",
    "          'accuracy before fine tuning: ',\n",
    "          pre_fine_tune_results[index][1],\n",
    "          'accuracy after fine tuning: ',\n",
    "          post_fine_tune_results[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(convert_from_hwio_to_iohw(model.get_weights()[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_hwio_to_iohw(weights_nchw):\n",
    "    return tf.transpose(weights_nchw, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def convert_from_iohw_to_hwio(weights_nhwc):\n",
    "    return tf.transpose(weights_nhwc, [2, 3, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = map (lambda pred: np.argmax(pred), model.predict(x_test[:30]))\n",
    "preds = list(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    img = tf.reshape(x_test[i], shape=[28, 28])\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.xlabel(preds[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_mask_variable(var, scope):\n",
    "\n",
    "    mask = tf.Variable(initial_value = tf.ones(var.shape),\n",
    "                       trainable=False\n",
    "                      )\n",
    "    return mask\n",
    "\n",
    "def apply_mask(x, scope=''):\n",
    "    #print(x.shape)\n",
    "    mask = weight_mask_variable(x, scope)\n",
    "    #threshold = weight_threshold_variable(x, scope)\n",
    "\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    masked_weights = tf.multiply(mask, x)\n",
    "    \n",
    "\n",
    "    return masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
