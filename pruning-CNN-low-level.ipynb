{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "#tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'weights_conv_1': tf.Variable(tf.random.normal([5, 5, 1, 6])),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'weights_conv_2': tf.Variable(tf.random.normal([5, 5, 6, 16])),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'weights_conv_3': tf.Variable(tf.random.normal([5, 5, 16, 120])),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'weights_dense_1': tf.Variable(tf.random.normal([5*5*16, 120])),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'weights_dense_2': tf.Variable(tf.random.normal([120, 84])),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'weights_dense_3': tf.Variable(tf.random.normal([84, 10])),\n",
    "}\n",
    "\n",
    "masks = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'mask_conv_1': tf.Variable(tf.ones([5, 5, 1, 6]), trainable=False),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'mask_conv_2': tf.Variable(tf.ones([5, 5, 6, 16]), trainable=False),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'mask_conv_3': tf.Variable(tf.ones([5, 5, 16, 120]), trainable=False),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'mask_dense_1': tf.Variable(tf.ones([5*5*16, 120])),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'mask_dense_2': tf.Variable(tf.ones([120, 84])),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'mask_dense_3': tf.Variable(tf.ones([84, 10])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    #output depth\n",
    "    'bias_conv_1': tf.Variable(tf.random.normal([6])),\n",
    "    'bias_conv_2': tf.Variable(tf.random.normal([16])),\n",
    "    'bias_dense_1': tf.Variable(tf.random.normal([120])),\n",
    "    'bias_dense_2': tf.Variable(tf.random.normal([84])),\n",
    "    'bias_dense_3': tf.Variable(tf.random.normal([10])),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_mask_variable(var, scope):\n",
    "\n",
    "    mask = tf.Variable(initial_value = tf.ones(var.shape),\n",
    "                       trainable=False\n",
    "                      )\n",
    "    return mask\n",
    "\n",
    "def apply_mask(x, scope=''):\n",
    "    #print(x.shape)\n",
    "    mask = weight_mask_variable(x, scope)\n",
    "    #threshold = weight_threshold_variable(x, scope)\n",
    "\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    masked_weights = tf.multiply(mask, x)\n",
    "    \n",
    "\n",
    "    return masked_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p)\n",
    "        \n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p)\n",
    "\n",
    "    \n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, weights, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        self.a = activation\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print(self.w)\n",
    "        #print(inputs)\n",
    "        x = tf.matmul(inputs, self.w)\n",
    "        #print(x)\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(weights['weights_conv_1'], masks['mask_conv_1'], biases['bias_conv_1'], 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(weights['weights_conv_2'], masks['mask_conv_2'], biases['bias_conv_2'], 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "        self.conv3 = CustomConvLayer(weights['weights_conv_3'], masks['mask_conv_3'], biases['bias_dense_1'], 1, 'VALID')\n",
    "        #self.dense1 = CustomDenseLayer(weights['weights_dense_1'], biases['bias_dense_1'], 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(weights['weights_dense_2'], biases['bias_dense_2'], 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(weights['weights_dense_3'], biases['bias_dense_3'], 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, shape=[-1, 28, 28, 1])\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.maxpool1(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        x = self.maxpool2(x)\n",
    "        #print('yo',x.shape)\n",
    "        #x = layers.Flatten()(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv3(x)\n",
    "        print(x.shape)\n",
    "        x = layers.Flatten()(x)\n",
    "        print(x.shape)\n",
    "        x =  self.dense2(x)\n",
    "        print(x.shape)\n",
    "        x =  self.dense3(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomConvModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 1)\n",
      "(None, 28, 28, 6)\n",
      "(None, 14, 14, 6)\n",
      "(None, 10, 10, 16)\n",
      "(None, 5, 5, 16)\n",
      "(None, 1, 1, 120)\n",
      "(None, 120)\n",
      "(None, 84)\n",
      "(None, 10)\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "30000/30000 [==============================] - 39s 1ms/sample - loss: 1.5956 - accuracy: 0.8667 - val_loss: 1.5886 - val_accuracy: 0.8732\n",
      "Epoch 2/2\n",
      "30000/30000 [==============================] - 35s 1ms/sample - loss: 1.5906 - accuracy: 0.8715 - val_loss: 1.5876 - val_accuracy: 0.8749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x650dbce50>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train[:30000],\n",
    "          y=y_train[:30000],\n",
    "          batch_size=64,\n",
    "          epochs=2,\n",
    "          validation_data=(x_test, y_test),\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 6)\n",
      "(6,)\n",
      "(5, 5, 1, 6)\n",
      "(5, 5, 6, 16)\n",
      "(16,)\n",
      "(5, 5, 6, 16)\n",
      "(5, 5, 16, 120)\n",
      "(120,)\n",
      "(5, 5, 16, 120)\n",
      "(120, 84)\n",
      "(84,)\n",
      "(84, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.get_weights():\n",
    "    print(layer.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 6)\n",
      "(6,)\n",
      "(5, 5, 1, 6)\n",
      "(5, 5, 6, 16)\n",
      "(16,)\n",
      "(5, 5, 6, 16)\n",
      "(5, 5, 16, 120)\n",
      "(120,)\n",
      "(5, 5, 16, 120)\n",
      "(120, 84)\n",
      "(84,)\n",
      "(84, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.get_weights():\n",
    "    print(layer.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.4772917 , -0.96927375,  1.0066881 ,  2.0744536 ,\n",
       "         -0.70605135,  1.3498781 ]],\n",
       "\n",
       "       [[-0.6492623 ,  1.1915262 ,  0.7286109 , -1.6436797 ,\n",
       "         -0.21559437,  0.06576186]],\n",
       "\n",
       "       [[-0.91879785, -0.564915  ,  0.03131934,  1.2240024 ,\n",
       "          0.8457885 ,  0.522353  ]],\n",
       "\n",
       "       [[ 0.9856671 , -0.5873115 ,  0.02142585,  1.065783  ,\n",
       "         -0.61659753, -0.8304464 ]],\n",
       "\n",
       "       [[-0.2127563 , -1.1773119 ,  0.35823378,  0.16824959,\n",
       "          1.0378606 ,  0.52482694]]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = tf.keras.Sequential()\n",
    "keras_model.add(layers.Reshape((28, 28,1)))\n",
    "#differences convolutional layer: \n",
    "#keras.layers.Conv2D uses 'glorot_uniform' initializer\n",
    "#keras.layers.Conv2D uses padding method 'valid' as default\n",
    "keras_model.add(layers.Conv2D(filters=6, kernel_size=(5,5), activation='tanh', padding='SAME',input_shape=(28,28,1)))\n",
    "#differences pooling layer: \n",
    "#keras.layers.AvgPooling2D uses padding method 'valid' (vs. 'SAME' in custom) as default\n",
    "keras_model.add(layers.AvgPool2D(padding='SAME'))\n",
    "keras_model.add(layers.Conv2D(filters=16, kernel_size=(5,5), activation='tanh'))\n",
    "keras_model.add(layers.AvgPool2D())\n",
    "keras_model.add(layers.Flatten())\n",
    "keras_model.add(layers.Dense(120, activation='tanh'))\n",
    "keras_model.add(layers.Dense(84, activation='tanh'))\n",
    "keras_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                    metrics=['accuracy'],\n",
    "                    experimental_run_tf_function=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.fit(x=x_train,\n",
    "                y=y_train,\n",
    "                batch_size=64,\n",
    "                epochs=2,\n",
    "                validation_data=(x_test, y_test),\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = map (lambda pred: np.argmax(pred), model.predict(x_test[:30]))\n",
    "preds = list(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    img = tf.reshape(x_test[i], shape=[28, 28])\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.xlabel(preds[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
