{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "tf.__version__\n",
    "#tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(name=\"imagenette\", with_info=True, split=[\"train\",\"validation\"])\n",
    "ds_train=ds[0][0]\n",
    "ds_test=ds[0][1]\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "\n",
    "def normalize(x):\n",
    "    y = {'image': tf.image.convert_image_dtype(x['image'], tf.float32), 'label': x['label']}\n",
    "    y = (tf.image.resize(y['image'], (224,224)), y['label'])\n",
    "    return y\n",
    "    \n",
    "ds_train = ds_train.map(lambda x: normalize(x))\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(100)\n",
    "ds_train = ds_train.batch(32, drop_remainder=True)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(32, drop_remainder=True)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c1df178a9526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/network-pruning/Pipelines/helpers/helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers'"
     ]
    }
   ],
   "source": [
    "import Pipelines.helpers.helpers as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('imagenette')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "\n",
    "    'weights_conv_1': tf.Variable(tf.initializers.GlorotUniform()([3, 3, 3, 64])),\n",
    "    'weights_conv_2': tf.Variable(tf.initializers.GlorotUniform()([3, 3, 64, 128])),\n",
    "    'weights_conv_3': tf.Variable(tf.initializers.GlorotUniform()([3, 3, 128, 256])),\n",
    "    'weights_conv_4': tf.Variable(tf.initializers.GlorotUniform()([3, 3, 256, 256])),\n",
    "    'weights_conv_5': tf.Variable(tf.initializers.GlorotUniform()([3, 3, 256, 512])),\n",
    "    'weights_conv_6': tf.Variable(tf.initializers.GlorotUniform()([3, 3, 512, 512])),\n",
    "    'weights_conv_7': tf.Variable(tf.initializers.GlorotUniform()([3, 3, 512, 512])),\n",
    "    'weights_conv_8': tf.Variable(tf.initializers.GlorotUniform()([3, 3, 512, 512])),\n",
    "    'weights_dense_1': tf.Variable(tf.initializers.GlorotUniform()([7*7*512, 4096])),\n",
    "    'weights_dense_2': tf.Variable(tf.initializers.GlorotUniform()([4096, 1024])),\n",
    "    'weights_dense_3': tf.Variable(tf.initializers.GlorotUniform()([1024, 10])),\n",
    "}\n",
    "\n",
    "\n",
    "masks = {\n",
    "    \n",
    "    'mask_conv_1': tf.Variable(tf.ones([3, 3, 3, 64]), trainable=False),\n",
    "    'mask_conv_2': tf.Variable(tf.ones([3, 3, 64, 128]), trainable=False),\n",
    "    'mask_conv_3': tf.Variable(tf.ones([3, 3, 128, 256]), trainable=False),\n",
    "    'mask_conv_4': tf.Variable(tf.ones([3, 3, 256, 256]), trainable=False),\n",
    "    'mask_conv_5': tf.Variable(tf.ones([3, 3, 256, 512]), trainable=False),\n",
    "    'mask_conv_6': tf.Variable(tf.ones([3, 3, 512, 512]), trainable=False),\n",
    "    'mask_conv_7': tf.Variable(tf.ones([3, 3, 512, 512]), trainable=False),\n",
    "    'mask_conv_8': tf.Variable(tf.ones([3, 3, 512, 512]), trainable=False),\n",
    "    # 224x224 input --> 5 maxpool layers --> \n",
    "    'mask_dense_1': tf.Variable(tf.ones([7*7*512, 4096]), trainable=False),\n",
    "    'mask_dense_2': tf.Variable(tf.ones([4096, 1024]), trainable=False),\n",
    "    'mask_dense_3': tf.Variable(tf.ones([1024, 10]), trainable=False),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    #output depth\n",
    "    'bias_conv_1': tf.Variable(tf.zeros([64])),\n",
    "    'bias_conv_2': tf.Variable(tf.zeros([128])),\n",
    "    'bias_conv_3': tf.Variable(tf.zeros([256])),\n",
    "    'bias_conv_4': tf.Variable(tf.zeros([256])),\n",
    "    'bias_conv_5': tf.Variable(tf.zeros([512])),\n",
    "    'bias_conv_6': tf.Variable(tf.zeros([512])),\n",
    "    'bias_conv_7': tf.Variable(tf.zeros([512])),\n",
    "    'bias_conv_8': tf.Variable(tf.zeros([512])),\n",
    "    \n",
    "    'bias_dense_1': tf.Variable(tf.zeros([4096])),\n",
    "    'bias_dense_2': tf.Variable(tf.zeros([1024])),\n",
    "    'bias_dense_3': tf.Variable(tf.zeros([10])),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "        #self.bn = layers.BatchNormalization()\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p)\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        #x = self.bn(x)\n",
    "        return tf.nn.relu(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='SAME'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.max_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p)\n",
    "    \n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, weights, mask, bias, activation = 'relu'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        self.a = activation\n",
    "        self.m = mask\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print('dense w',self.w)\n",
    "        #print('dense i',inputs)\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        #print('dense x',x)\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'relu':\n",
    "            return tf.nn.relu(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        if self.a == 'sigmoid':\n",
    "            return tf.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG11, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(weights['weights_conv_1'], masks['mask_conv_1'], biases['bias_conv_1'], 1)\n",
    "        self.maxpool1 = CustomPoolLayer(k=2)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = CustomConvLayer(weights['weights_conv_2'], masks['mask_conv_2'], biases['bias_conv_2'], 1)\n",
    "        self.maxpool2 = CustomPoolLayer(k=2)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.conv3 = CustomConvLayer(weights['weights_conv_3'], masks['mask_conv_3'], biases['bias_conv_3'], 1)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.conv4 = CustomConvLayer(weights['weights_conv_4'], masks['mask_conv_4'], biases['bias_conv_4'], 1)\n",
    "        self.maxpool3 = CustomPoolLayer(k=2)\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.conv5 = CustomConvLayer(weights['weights_conv_5'], masks['mask_conv_5'], biases['bias_conv_5'], 1)\n",
    "        self.bn5 = layers.BatchNormalization()\n",
    "        self.conv6 = CustomConvLayer(weights['weights_conv_6'], masks['mask_conv_6'], biases['bias_conv_6'], 1)\n",
    "        self.maxpool4 = CustomPoolLayer(k=2)\n",
    "        self.bn6 = layers.BatchNormalization()\n",
    "        self.conv7 = CustomConvLayer(weights['weights_conv_7'], masks['mask_conv_7'], biases['bias_conv_7'], 1)\n",
    "        self.bn7 = layers.BatchNormalization()\n",
    "        self.conv8 = CustomConvLayer(weights['weights_conv_8'], masks['mask_conv_8'], biases['bias_conv_8'], 1)\n",
    "        self.maxpool5 = CustomPoolLayer(k=2)\n",
    "        self.bn8 = layers.BatchNormalization()\n",
    "        self.dense1 = CustomDenseLayer(weights['weights_dense_1'], masks['mask_dense_1'], biases['bias_dense_1'], 'relu')\n",
    "        self.bn9 = layers.BatchNormalization()\n",
    "        self.dense2 = CustomDenseLayer(weights['weights_dense_2'], masks['mask_dense_2'], biases['bias_dense_2'], 'relu')\n",
    "        self.bn10 = layers.BatchNormalization()\n",
    "        self.dense3 = CustomDenseLayer(weights['weights_dense_3'], masks['mask_dense_3'], biases['bias_dense_3'], 'softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        #x = tf.reshape(inputs, shape=[-1, 28, 28, 1])\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.maxpool5(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.bn8(x)\n",
    "        x =  self.dense1(x)\n",
    "        x = self.bn9(x)\n",
    "        x =  self.dense2(x)\n",
    "        x = self.bn10(x)\n",
    "        x =  self.dense3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG11()\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.001, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "74/74 [==============================] - 36s 493ms/step - loss: 2.3012 - accuracy: 0.1432 - val_loss: 2.3004 - val_accuracy: 0.1101\n",
      "Epoch 2/20\n",
      "74/74 [==============================] - 28s 381ms/step - loss: 2.2978 - accuracy: 0.1401 - val_loss: 2.2974 - val_accuracy: 0.1085\n",
      "Epoch 3/20\n",
      "74/74 [==============================] - 28s 385ms/step - loss: 2.2930 - accuracy: 0.1389 - val_loss: 2.2919 - val_accuracy: 0.1116\n",
      "Epoch 4/20\n",
      "74/74 [==============================] - 28s 382ms/step - loss: 2.2815 - accuracy: 0.1579 - val_loss: 2.2748 - val_accuracy: 0.1327\n",
      "Epoch 5/20\n",
      "74/74 [==============================] - 29s 386ms/step - loss: 2.2189 - accuracy: 0.2270 - val_loss: 2.1357 - val_accuracy: 0.2548\n",
      "Epoch 6/20\n",
      "74/74 [==============================] - 29s 387ms/step - loss: 2.0795 - accuracy: 0.2733 - val_loss: 2.0227 - val_accuracy: 0.3065\n",
      "Epoch 7/20\n",
      "74/74 [==============================] - 28s 384ms/step - loss: 1.9742 - accuracy: 0.3175 - val_loss: 1.9106 - val_accuracy: 0.3595\n",
      "Epoch 8/20\n",
      "74/74 [==============================] - 29s 389ms/step - loss: 1.8643 - accuracy: 0.3621 - val_loss: 1.8131 - val_accuracy: 0.3852\n",
      "Epoch 9/20\n",
      "74/74 [==============================] - 28s 385ms/step - loss: 1.7780 - accuracy: 0.3899 - val_loss: 1.7718 - val_accuracy: 0.4048\n",
      "Epoch 10/20\n",
      "74/74 [==============================] - 29s 387ms/step - loss: 1.7013 - accuracy: 0.4217 - val_loss: 1.7148 - val_accuracy: 0.4214\n",
      "Epoch 11/20\n",
      "74/74 [==============================] - 28s 385ms/step - loss: 1.6193 - accuracy: 0.4541 - val_loss: 1.6583 - val_accuracy: 0.4474\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - 29s 387ms/step - loss: 1.5304 - accuracy: 0.4879 - val_loss: 1.5547 - val_accuracy: 0.4833\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - 29s 399ms/step - loss: 1.4644 - accuracy: 0.5080 - val_loss: 1.5197 - val_accuracy: 0.4920\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - 29s 389ms/step - loss: 1.3793 - accuracy: 0.5378 - val_loss: 1.4616 - val_accuracy: 0.5167\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - 29s 390ms/step - loss: 1.2725 - accuracy: 0.5743 - val_loss: 1.4623 - val_accuracy: 0.5294\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - 29s 390ms/step - loss: 1.1906 - accuracy: 0.6054 - val_loss: 1.3986 - val_accuracy: 0.5414\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - 29s 388ms/step - loss: 1.1232 - accuracy: 0.6202 - val_loss: 1.3932 - val_accuracy: 0.5462\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - 29s 392ms/step - loss: 1.0148 - accuracy: 0.6675 - val_loss: 1.3723 - val_accuracy: 0.5539\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - 29s 389ms/step - loss: 0.9314 - accuracy: 0.6870 - val_loss: 1.4080 - val_accuracy: 0.5501\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - 29s 390ms/step - loss: 0.8681 - accuracy: 0.7134 - val_loss: 1.4122 - val_accuracy: 0.5623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f25e811c4c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=ds_train,\n",
    "    #steps_per_epoch=1,\n",
    "    epochs=20,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "295/295 [==============================] - 36s 122ms/step - loss: 1.7225 - accuracy: 0.4881 - val_loss: 2.6725 - val_accuracy: 0.1632\n",
      "Epoch 2/20\n",
      "295/295 [==============================] - 34s 114ms/step - loss: 0.8737 - accuracy: 0.7210 - val_loss: 1.1939 - val_accuracy: 0.6242\n",
      "Epoch 3/20\n",
      "295/295 [==============================] - 34s 115ms/step - loss: 0.4729 - accuracy: 0.8532 - val_loss: 1.2329 - val_accuracy: 0.6424\n",
      "Epoch 4/20\n",
      "295/295 [==============================] - 34s 116ms/step - loss: 0.2273 - accuracy: 0.9383 - val_loss: 1.2132 - val_accuracy: 0.6506\n",
      "Epoch 5/20\n",
      "295/295 [==============================] - 34s 117ms/step - loss: 0.1194 - accuracy: 0.9717 - val_loss: 1.3458 - val_accuracy: 0.6478\n",
      "Epoch 6/20\n",
      "295/295 [==============================] - 35s 118ms/step - loss: 0.0668 - accuracy: 0.9861 - val_loss: 1.1540 - val_accuracy: 0.6865\n",
      "Epoch 7/20\n",
      "295/295 [==============================] - 35s 119ms/step - loss: 0.0393 - accuracy: 0.9940 - val_loss: 1.1702 - val_accuracy: 0.6965\n",
      "Epoch 8/20\n",
      "295/295 [==============================] - 35s 120ms/step - loss: 0.0261 - accuracy: 0.9975 - val_loss: 1.1077 - val_accuracy: 0.7106\n",
      "Epoch 9/20\n",
      "295/295 [==============================] - 36s 121ms/step - loss: 0.0172 - accuracy: 0.9988 - val_loss: 1.1324 - val_accuracy: 0.7016\n",
      "Epoch 10/20\n",
      "295/295 [==============================] - 36s 121ms/step - loss: 0.0139 - accuracy: 0.9989 - val_loss: 1.1278 - val_accuracy: 0.7093\n",
      "Epoch 11/20\n",
      "295/295 [==============================] - 36s 121ms/step - loss: 0.0112 - accuracy: 0.9994 - val_loss: 1.0815 - val_accuracy: 0.7152\n",
      "Epoch 12/20\n",
      "295/295 [==============================] - 36s 121ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 1.1071 - val_accuracy: 0.7118\n",
      "Epoch 13/20\n",
      "295/295 [==============================] - 36s 121ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 1.0913 - val_accuracy: 0.7170\n",
      "Epoch 14/20\n",
      "295/295 [==============================] - 36s 121ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0994 - val_accuracy: 0.7162\n",
      "Epoch 15/20\n",
      "295/295 [==============================] - 36s 121ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0867 - val_accuracy: 0.7252\n",
      "Epoch 16/20\n",
      "295/295 [==============================] - 36s 122ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 1.0750 - val_accuracy: 0.7262\n",
      "Epoch 17/20\n",
      "295/295 [==============================] - 35s 120ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0872 - val_accuracy: 0.7234\n",
      "Epoch 18/20\n",
      "295/295 [==============================] - 34s 115ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 1.0762 - val_accuracy: 0.7287\n",
      "Epoch 19/20\n",
      "295/295 [==============================] - 34s 115ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 1.0730 - val_accuracy: 0.7293\n",
      "Epoch 20/20\n",
      "295/295 [==============================] - 35s 119ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0771 - val_accuracy: 0.7310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7dd306fa0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=ds_train,\n",
    "    #steps_per_epoch=1,\n",
    "    epochs=20,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define helper functions for pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_hwio_to_iohw(weights_nchw):\n",
    "    return tf.transpose(weights_nchw, [2, 3, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "def convert_from_iohw_to_hwio(weights_nhwc):\n",
    "    return tf.transpose(weights_nhwc, [2, 3, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weights(model, pruning_ratio):\n",
    "    layer_to_prune = [24, 27, 30]\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        if index in layer_to_prune:\n",
    "            #print(weight.shape)\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index+2].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            flat_weights_to_prune_df = pd.DataFrame(flat_weights_to_prune)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            #print(no_of_weights_to_prune)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+2].shape\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            weights_to_prune[index+2] = weights_reshaped\n",
    "    #print(weights_to_prune)\n",
    "    return weights_to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_conv_layers(pruning_ratio):\n",
    "    layer_to_prune = [0, 3, 6, 9, 12, 15, 18, 21]\n",
    "    pruned_weights = model.get_weights()\n",
    "    \n",
    "    for layer in layer_to_prune:\n",
    "        print(layer)\n",
    "        #converted_weights = convert_from_hwio_to_iohw(model.get_weights()[layer])\n",
    "        converted_weights = model.get_weights()[layer]\n",
    "        #converted_mask = convert_from_hwio_to_iohw(model.get_weights()[layer + 2]).numpy()\n",
    "        converted_mask = model.get_weights()[layer + 2]\n",
    "        for input_index, input_layer in enumerate(converted_weights[:5]):\n",
    "            print(input_index)\n",
    "\n",
    "            for kernel_index, kernel in enumerate(input_layer[:5]):\n",
    "                print(kernel_index)\n",
    "                dims = kernel.shape\n",
    "                flat_weights = kernel.flatten()\n",
    "                flat_masks = converted_mask[input_index][kernel_index].flatten()\n",
    "                flat_weights_df = pd.DataFrame(flat_weights)\n",
    "                flat_mask_df = pd.DataFrame(flat_masks)\n",
    "                no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "                #print(no_of_weights_to_prune)\n",
    "                indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "                for idx_to_delete in indices_to_delete:\n",
    "                    flat_masks[idx_to_delete] = 0\n",
    "\n",
    "                converted_mask[input_index][kernel_index] = flat_masks.reshape(dims)\n",
    "        #back_converted_mask = convert_from_iohw_to_hwio(converted_mask)\n",
    "        back_converted_mask = converted_mask\n",
    "        pruned_weights[layer+2] = back_converted_mask\n",
    "    \n",
    "    return pruned_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "6\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "9\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "12\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "15\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "18\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "21\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Epoch 1/5\n",
      "101/101 [==============================] - 26s 262ms/step - loss: 0.6695 - accuracy: 0.7832 - val_loss: 1.3468 - val_accuracy: 0.5960\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 0.4502 - accuracy: 0.8533 - val_loss: 1.5548 - val_accuracy: 0.6080\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 0.3117 - accuracy: 0.9062 - val_loss: 1.7990 - val_accuracy: 0.5820\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 0.2356 - accuracy: 0.9299 - val_loss: 1.8764 - val_accuracy: 0.5860\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 27s 264ms/step - loss: 0.1818 - accuracy: 0.9457 - val_loss: 2.1436 - val_accuracy: 0.6040\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [03:31<07:03, 211.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "6\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "9\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "12\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "15\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "18\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "21\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Epoch 1/5\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 1.4185 - accuracy: 0.5373 - val_loss: 1.2466 - val_accuracy: 0.5920\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 0.9127 - accuracy: 0.6982 - val_loss: 1.2393 - val_accuracy: 0.6160\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 0.7054 - accuracy: 0.7691 - val_loss: 1.2746 - val_accuracy: 0.5940\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 27s 264ms/step - loss: 0.5441 - accuracy: 0.8254 - val_loss: 1.3556 - val_accuracy: 0.6120\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 27s 264ms/step - loss: 0.4078 - accuracy: 0.8752 - val_loss: 1.5409 - val_accuracy: 0.5840\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [07:25<03:38, 218.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "6\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "9\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "12\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "15\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "18\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "21\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Epoch 1/5\n",
      "101/101 [==============================] - 26s 261ms/step - loss: 3.2905 - accuracy: 0.2870 - val_loss: 2.0391 - val_accuracy: 0.2880\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 26s 262ms/step - loss: 1.9508 - accuracy: 0.3359 - val_loss: 1.8189 - val_accuracy: 0.3920\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 27s 262ms/step - loss: 1.7254 - accuracy: 0.4362 - val_loss: 1.6024 - val_accuracy: 0.4660\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 1.4923 - accuracy: 0.5077 - val_loss: 1.4086 - val_accuracy: 0.5320\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 27s 263ms/step - loss: 1.3021 - accuracy: 0.5716 - val_loss: 1.3025 - val_accuracy: 0.5760\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:22<00:00, 227.38s/it]\n"
     ]
    }
   ],
   "source": [
    "pruning_ratios = [.5, 0.8, 0.9]\n",
    "pre_pruning_weight_archive = []\n",
    "post_pruning_weight_archive = []\n",
    "post_fine_tune_weight_archive = []\n",
    "pre_fine_tune_results = []\n",
    "post_fine_tune_results = []\n",
    "\n",
    "for pruning_ratio in tqdm(pruning_ratios):\n",
    "    #pre_pruning_weight_archive.append(model.get_weights())\n",
    "    print('1')\n",
    "    pruned_weights = prune_conv_layers(pruning_ratio)\n",
    "    print('2')\n",
    "    model.set_weights(pruned_weights)\n",
    "    print('3')\n",
    "    pruned_weights = prune_weights(model, pruning_ratio)\n",
    "    print('4')\n",
    "    model.set_weights(pruned_weights)\n",
    "    print('5')\n",
    "    post_pruning_weight_archive.append(model.get_weights())\n",
    "    print('6')\n",
    "    pre_fine_tune_results.append(model.evaluate(ds_test, verbose=0))\n",
    "    print('7')\n",
    "    model.fit(\n",
    "        x=ds_train,\n",
    "        #steps_per_epoch=1,\n",
    "        epochs=5,\n",
    "        validation_data=ds_test,\n",
    "    )\n",
    "    print('8')\n",
    "    post_fine_tune_results.append(model.evaluate(ds_test, verbose=0))\n",
    "    #post_fine_tune_weight_archive.append(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | pre fine tuning acc: 0.468\n",
      " | pre fine tuning acc: 0.134\n",
      " | pre fine tuning acc: 0.104\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(post_fine_tune_results):\n",
    "    print(pruning_ratios[i] +' | pre fine tuning acc: '+ pre_fine_tune_results[i][1]+ ' | post fine tuning acc: ' + x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_set(PATH):\n",
    "    data_dir = pathlib.Path(PATH)\n",
    "    CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if (item.name != \"LICENSE.txt\" and item.name != '.DS_Store')])\n",
    "    image_count = len(list(data_dir.glob('*/*.JPEG')))\n",
    "    IMG_HEIGHT = 224\n",
    "dd    IMG_WIDTH = 224\n",
    "    \n",
    "    def get_label(file_path):\n",
    "        # convert the path to a list of path components\n",
    "        \n",
    "        parts = tf.strings.split(file_path, os.path.sep)\n",
    "        # The second to last is the class-directory\n",
    "        return parts[-2] == CLASS_NAMES\n",
    "\n",
    "    def decode_img(img):\n",
    "        # convert the compressed string to a 3D uint8 tensor\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        # resize the image to the desired size.\n",
    "        img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "        #print(img)\n",
    "        return img\n",
    "\n",
    "    def process_path(file_path):\n",
    "        label = get_label(file_path)\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(file_path)\n",
    "        #print(img)\n",
    "        img = decode_img(img)\n",
    "        #print(type(img))\n",
    "        return img, label\n",
    "    \n",
    "    list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.JPEG'))\n",
    "    print(list(list_ds))\n",
    "    labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    return labeled_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/Users/florianmerkle/tensorflow_datasets/downloads/extracted/TAR_GZ.s3_fast-ai-imageclas_imagenetteG9ZQvBaITKiOTw9TfthWmx-Neuhl0366js3YfZzZ3Po.tgz/imagenette/train'\n",
    "train_data = create_data_set(TRAIN_PATH)\n",
    "VAL_PATH = '/Users/florianmerkle/tensorflow_datasets/downloads/extracted/TAR_GZ.s3_fast-ai-imageclas_imagenetteG9ZQvBaITKiOTw9TfthWmx-Neuhl0366js3YfZzZ3Po.tgz/imagenette/val/'\n",
    "val_data = create_data_set(VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    #ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat(1)\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_ds = prepare_for_training(train_data)\n",
    "val_ds = prepare_for_training(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = list(val_ds)[0][0]\n",
    "y_train = list(val_ds)[0][1]\n",
    "#x_train = tf.expand_dims(x_train, axis=0)\n",
    "#y_train = tf.expand_dims(y_train, axis=0)\n",
    "print(y_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train,\n",
    "          y=labels,\n",
    "          epochs=5,\n",
    "          batch_size=4\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_eagerly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict_on_batch(val_ds)\n",
    "labels = np.asarray([np.argmax(x)for x in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        #print()\n",
    "        plt.title(CLASS_NAMES[np.argmax(label_batch[n])])\n",
    "        plt.axis('off')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "#show_batch(x_train[:25], y_train[:25])\n",
    "show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(TRAIN_PATH)\n",
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if (item.name != \"LICENSE.txt\" and item.name != '.DS_Store')])\n",
    "image_count = len(list(data_dir.glob('**/*.JPEG')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "STEPS_PER_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = '/Users/florianmerkle/tensorflow_datasets/downloads/extracted/TAR_GZ.s3_fast-ai-imageclas_imagenetteG9ZQvBaITKiOTw9TfthWmx-Neuhl0366js3YfZzZ3Po.tgz/imagenette/train/chain_saw/n03000684_1000.JPEG'\n",
    "def predict():\n",
    "    image = tf.io.read_file(IMG_PATH)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    print(image.shape)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    print(image.shape)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    print(image.shape)\n",
    "    print(model.predict(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_keras = tf.keras.applications.VGG16()\n",
    "\n",
    "vgg_keras.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True) ,\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = vgg_keras.predict(first_b[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
