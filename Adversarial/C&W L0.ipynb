{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "MAX_ITERATIONS = 1000   # number of iterations to perform gradient descent\n",
    "ABORT_EARLY = True      # abort gradient descent upon first valid solution\n",
    "LEARNING_RATE = 1e-2    # larger values converge faster to less accurate results\n",
    "INITIAL_CONST = 1e-3    # the first value of c to start at\n",
    "LARGEST_CONST = 2e6     # the largest value of c to go up to before giving up\n",
    "REDUCE_CONST = False    # try to lower c each iteration; faster to set to false\n",
    "TARGETED = True         # should we target one specific class? or just be wrong?\n",
    "CONST_FACTOR = 2.0      # f>1, rate at which we increase constant, smaller better\n",
    "\n",
    "class CarliniL0:\n",
    "    def __init__(self, sess, model,\n",
    "                 targeted = TARGETED, learning_rate = LEARNING_RATE,\n",
    "                 max_iterations = MAX_ITERATIONS, abort_early = ABORT_EARLY,\n",
    "                 initial_const = INITIAL_CONST, largest_const = LARGEST_CONST,\n",
    "                 reduce_const = REDUCE_CONST, const_factor = CONST_FACTOR,\n",
    "                 independent_channels = False):\n",
    "        \"\"\"\n",
    "        The L_0 optimized attack. \n",
    "        Returns adversarial examples for the supplied model.\n",
    "        targeted: True if we should perform a targetted attack, False otherwise.\n",
    "        learning_rate: The learning rate for the attack algorithm. Smaller values\n",
    "          produce better results but are slower to converge.\n",
    "        max_iterations: The maximum number of iterations. Larger values are more\n",
    "          accurate; setting too small will require a large learning rate and will\n",
    "          produce poor results.\n",
    "        abort_early: If true, allows early aborts if gradient descent gets stuck.\n",
    "        initial_const: The initial tradeoff-constant to use to tune the relative\n",
    "          importance of distance and confidence. Should be set to a very small\n",
    "          value (but positive).\n",
    "        largest_const: The largest constant to use until we report failure. Should\n",
    "          be set to a very large value.\n",
    "        const_factor: The rate at which we should increase the constant, when the\n",
    "          previous constant failed. Should be greater than one, smaller is better.\n",
    "        independent_channels: set to false optimizes for number of pixels changed,\n",
    "          set to true (not recommended) returns number of channels changed.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model = model\n",
    "        #self.sess = sess\n",
    "\n",
    "        self.TARGETED = targeted\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.MAX_ITERATIONS = max_iterations\n",
    "        self.ABORT_EARLY = abort_early\n",
    "        self.INITIAL_CONST = initial_const\n",
    "        self.LARGEST_CONST = largest_const\n",
    "        self.REDUCE_CONST = reduce_const\n",
    "        self.const_factor = const_factor\n",
    "        self.independent_channels = independent_channels\n",
    "\n",
    "        self.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK = False\n",
    "\n",
    "        #self.grad = self.gradient_descent(sess, model)\n",
    "        self.grad = self.gradient_descent(model)\n",
    "\n",
    "    def gradient_descent(self, model):\n",
    "        def compare(x,y):\n",
    "            if self.TARGETED:\n",
    "                return x == y\n",
    "            else:\n",
    "                return x != y\n",
    "        shape = (1,model.image_size,model.image_size,model.num_channels)\n",
    "        \n",
    "        # the variable to optimize over\n",
    "        modifier = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "\n",
    "        # the variables we're going to hold, use for efficiency\n",
    "        canchange = tf.Variable(np.zeros(shape),dtype=np.float32)\n",
    "        simg = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "        original = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "        timg = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "        tlab = tf.Variable(np.zeros((1,model.num_labels),dtype=np.float32))\n",
    "        const = tf.placeholder(tf.float32, [])\n",
    "\n",
    "        # and the assignment to set the variables\n",
    "        assign_modifier = tf.placeholder(np.float32,shape)\n",
    "        assign_canchange = tf.placeholder(np.float32,shape)\n",
    "        assign_simg = tf.placeholder(np.float32,shape)\n",
    "        assign_original = tf.placeholder(np.float32,shape)\n",
    "        assign_timg = tf.placeholder(np.float32,shape)\n",
    "        assign_tlab = tf.placeholder(np.float32,(1,self.model.num_labels))\n",
    "\n",
    "        # these are the variables to initialize when we run\n",
    "        set_modifier = tf.assign(modifier, assign_modifier)\n",
    "        setup = []\n",
    "        setup.append(tf.assign(canchange, assign_canchange))\n",
    "        setup.append(tf.assign(timg, assign_timg))\n",
    "        setup.append(tf.assign(original, assign_original))\n",
    "        setup.append(tf.assign(simg, assign_simg))\n",
    "        setup.append(tf.assign(tlab, assign_tlab))\n",
    "        \n",
    "        newimg = (tf.tanh(modifier + simg)/2)*canchange+(1-canchange)*original\n",
    "        \n",
    "        output = model.predict(newimg)\n",
    "        \n",
    "        real = tf.reduce_sum((tlab)*output,1)\n",
    "        other = tf.reduce_max((1-tlab)*output - (tlab*10000),1)\n",
    "        if self.TARGETED:\n",
    "            # if targetted, optimize for making the other class most likely\n",
    "            loss1 = tf.maximum(0.0, other-real+.01)\n",
    "        else:\n",
    "            # if untargeted, optimize for making this class least likely.\n",
    "            loss1 = tf.maximum(0.0, real-other+.01)\n",
    "\n",
    "        # sum up the losses\n",
    "        loss2 = tf.reduce_sum(tf.square(newimg-tf.tanh(timg)/2))\n",
    "        loss = const*loss1+loss2\n",
    "            \n",
    "        outgrad = tf.gradients(loss, [modifier])[0]\n",
    "        \n",
    "        # setup the adam optimizer and keep track of variables we're creating\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        optimizer = tf.train.AdamOptimizer(self.LEARNING_RATE)\n",
    "        train = optimizer.minimize(loss, var_list=[modifier])\n",
    "\n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "        init = tf.variables_initializer(var_list=[modifier,canchange,simg,\n",
    "                                                  original,timg,tlab]+new_vars)\n",
    "\n",
    "        \n",
    "        def doit(oimgs, labs, starts, valid, CONST):\n",
    "            # convert to tanh-space\n",
    "            imgs = np.arctanh(np.array(oimgs)*1.999999)\n",
    "            starts = np.arctanh(np.array(starts)*1.999999)\n",
    "\n",
    "            # initialize the variables\n",
    "            # todo what is sess.run doing?\n",
    "            sess.run(init)\n",
    "            sess.run(setup, {assign_timg: imgs, \n",
    "                                    assign_tlab:labs, \n",
    "                                    assign_simg: starts, \n",
    "                                    assign_original: oimgs,\n",
    "                                    assign_canchange: valid})\n",
    "\n",
    "            while CONST < self.LARGEST_CONST:\n",
    "                # try solving for each value of the constant\n",
    "                print('try const', CONST)\n",
    "                for step in range(self.MAX_ITERATIONS):\n",
    "                    feed_dict={const: CONST}\n",
    "\n",
    "                    # remember the old value\n",
    "                    oldmodifier = self.sess.run(modifier)\n",
    "\n",
    "                    if step%(self.MAX_ITERATIONS//10) == 0:\n",
    "                        print(step,*sess.run((loss1,loss2),feed_dict=feed_dict))\n",
    "\n",
    "                    # perform the update step\n",
    "                    _, works, scores = sess.run([train, loss1, output], feed_dict=feed_dict)\n",
    "\n",
    "                    if np.all(scores>=-.0001) and np.all(scores <= 1.0001):\n",
    "                        if np.allclose(np.sum(scores,axis=1), 1.0, atol=1e-3):\n",
    "                            if not self.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK:\n",
    "                                raise Exception(\"The output of model.predict should return the pre-softmax layer. It looks like you are returning the probability vector (post-softmax). If you are sure you want to do that, set attack.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK = True\")\n",
    "                    \n",
    "                    if works < .0001 and self.ABORT_EARLY:\n",
    "                        # it worked previously, restore the old value and finish\n",
    "                        self.sess.run(set_modifier, {assign_modifier: oldmodifier})\n",
    "                        grads, scores, nimg = sess.run((outgrad, output,newimg),\n",
    "                                                       feed_dict=feed_dict)\n",
    "\n",
    "                        l2s=np.square(nimg-np.tanh(imgs)/2).sum(axis=(1,2,3))\n",
    "                        return grads, scores, nimg, CONST\n",
    "\n",
    "                # we didn't succeed, increase constant and try again\n",
    "                CONST *= self.const_factor\n",
    "        return doit\n",
    "        \n",
    "    def attack(self, imgs, targets):\n",
    "        \"\"\"\n",
    "        Perform the L_0 attack on the given images for the given targets.\n",
    "        If self.targeted is true, then the targets represents the target labels.\n",
    "        If self.targeted is false, then targets are the original class labels.\n",
    "        \"\"\"\n",
    "        r = []\n",
    "        for i,(img,target) in enumerate(zip(imgs, targets)):\n",
    "            print(\"Attack iteration\",i)\n",
    "            r.extend(self.attack_single(img, target))\n",
    "        return np.array(r)\n",
    "\n",
    "    def attack_single(self, img, target):\n",
    "        \"\"\"\n",
    "        Run the attack on a single image and label\n",
    "        \"\"\"\n",
    "\n",
    "        # the pixels we can change\n",
    "        valid = np.ones((1,self.model.image_size,self.model.image_size,self.model.num_channels))\n",
    "\n",
    "        # the previous image\n",
    "        prev = np.copy(img).reshape((1,self.model.image_size,self.model.image_size,\n",
    "                                     self.model.num_channels))\n",
    "\n",
    "        # initially set the solution to None, if we can't find an adversarial\n",
    "        # example then we will return None as the solution.\n",
    "        last_solution = None\n",
    "        const = self.INITIAL_CONST\n",
    "\n",
    "        equal_count = None\n",
    "    \n",
    "        while True:\n",
    "            # try to solve given this valid map\n",
    "            res = self.grad([np.copy(img)], [target], np.copy(prev), \n",
    "                       valid, const)\n",
    "            if res == None:\n",
    "                # the attack failed, we return this as our final answer\n",
    "                print(\"Final answer\",equal_count)\n",
    "                return last_solution\n",
    "    \n",
    "            # the attack succeeded, now we pick new pixels to set to 0\n",
    "            restarted = False\n",
    "            gradientnorm, scores, nimg, const = res\n",
    "            if self.REDUCE_CONST: const /= 2\n",
    "    \n",
    "            equal_count = self.model.image_size**2-np.sum(np.all(np.abs(img-nimg[0])<.0001,axis=2))\n",
    "            print(\"Forced equal:\",np.sum(1-valid),\n",
    "                  \"Equal count:\",equal_count)\n",
    "            if np.sum(valid) == 0:\n",
    "                # if no pixels changed, return \n",
    "                return [img]\n",
    "    \n",
    "            if self.independent_channels:\n",
    "                # we are allowed to change each channel independently\n",
    "                valid = valid.flatten()\n",
    "                totalchange = abs(nimg[0]-img)*np.abs(gradientnorm[0])\n",
    "            else:\n",
    "                # we care only about which pixels change, not channels independently\n",
    "                # compute total change as sum of change for each channel\n",
    "                valid = valid.reshape((self.model.image_size**2,self.model.num_channels))\n",
    "                totalchange = abs(np.sum(nimg[0]-img,axis=2))*np.sum(np.abs(gradientnorm[0]),axis=2)\n",
    "            totalchange = totalchange.flatten()\n",
    "\n",
    "            # set some of the pixels to 0 depending on their total change\n",
    "            did = 0\n",
    "            for e in np.argsort(totalchange):\n",
    "                if np.all(valid[e]):\n",
    "                    did += 1\n",
    "                    valid[e] = 0\n",
    "\n",
    "                    if totalchange[e] > .01:\n",
    "                        # if this pixel changed a lot, skip\n",
    "                        break\n",
    "                    if did >= .3*equal_count**.5:\n",
    "                        # if we changed too many pixels, skip\n",
    "                        break\n",
    "\n",
    "            valid = np.reshape(valid,(1,self.model.image_size,self.model.image_size,-1))\n",
    "            print(\"Now forced equal:\",np.sum(1-valid))\n",
    "    \n",
    "            last_solution = prev = nimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_single(self, img, target):\n",
    "        \"\"\"\n",
    "        Run the attack on a single image and label\n",
    "        \"\"\"\n",
    "        i=1\n",
    "        # the pixels we can change\n",
    "        valid = np.ones((1,self.model.image_size,self.model.image_size,self.model.num_channels))\n",
    "        print(i)\n",
    "        i=i+1\n",
    "        # the previous image\n",
    "        prev = np.copy(img).reshape((1,self.model.image_size,self.model.image_size,\n",
    "                                     self.model.num_channels))\n",
    "        print(i)\n",
    "        i=i+1\n",
    "        # initially set the solution to None, if we can't find an adversarial\n",
    "        # example then we will return None as the solution.\n",
    "        last_solution = None\n",
    "        print(i)\n",
    "        i=i+1\n",
    "        const = self.INITIAL_CONST\n",
    "        print(i)\n",
    "        i=i+1\n",
    "        equal_count = None\n",
    "        print(i)\n",
    "        i=i+1\n",
    "        while True:\n",
    "            # try to solve given this valid map\n",
    "            res = self.grad([np.copy(img)], [target], np.copy(prev), \n",
    "                       valid, const)\n",
    "            print(i)\n",
    "            i=i+1\n",
    "            if res == None:\n",
    "                # the attack failed, we return this as our final answer\n",
    "                print(i)\n",
    "                i=i+1\n",
    "                print(\"Final answer\",equal_count)\n",
    "                return last_solution\n",
    "            print(i)\n",
    "            i=i+1\n",
    "            # the attack succeeded, now we pick new pixels to set to 0\n",
    "            restarted = False\n",
    "            gradientnorm, scores, nimg, const = res\n",
    "            print(i)\n",
    "            i=i+1\n",
    "            if self.REDUCE_CONST: const /= 2\n",
    "            print(i)\n",
    "            i=i+1\n",
    "            equal_count = self.model.image_size**2-np.sum(np.all(np.abs(img-nimg[0])<.0001,axis=2))\n",
    "            print(\"Forced equal:\",np.sum(1-valid),\n",
    "                  \"Equal count:\",equal_count)\n",
    "            print(i)\n",
    "            i=i+1\n",
    "            if np.sum(valid) == 0:\n",
    "                # if no pixels changed, return \n",
    "                return [img]\n",
    "    \n",
    "            if self.independent_channels:\n",
    "                # we are allowed to change each channel independently\n",
    "                valid = valid.flatten()\n",
    "                totalchange = abs(nimg[0]-img)*np.abs(gradientnorm[0])\n",
    "            else:\n",
    "                # we care only about which pixels change, not channels independently\n",
    "                # compute total change as sum of change for each channel\n",
    "                valid = valid.reshape((self.model.image_size**2,self.model.num_channels))\n",
    "                totalchange = abs(np.sum(nimg[0]-img,axis=2))*np.sum(np.abs(gradientnorm[0]),axis=2)\n",
    "            totalchange = totalchange.flatten()\n",
    "\n",
    "            # set some of the pixels to 0 depending on their total change\n",
    "            did = 0\n",
    "            for e in np.argsort(totalchange):\n",
    "                if np.all(valid[e]):\n",
    "                    did += 1\n",
    "                    valid[e] = 0\n",
    "\n",
    "                    if totalchange[e] > .01:\n",
    "                        # if this pixel changed a lot, skip\n",
    "                        break\n",
    "                    if did >= .3*equal_count**.5:\n",
    "                        # if we changed too many pixels, skip\n",
    "                        break\n",
    "\n",
    "            valid = np.reshape(valid,(1,self.model.image_size,self.model.image_size,-1))\n",
    "            print(\"Now forced equal:\",np.sum(1-valid))\n",
    "    \n",
    "            last_solution = prev = nimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
