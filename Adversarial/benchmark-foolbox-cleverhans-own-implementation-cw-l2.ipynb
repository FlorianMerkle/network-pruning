{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from absl import app, flags\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox as fb\n",
    "#rom foolbox import TensorFlowModel, accuracy, samples\n",
    "#mport foolbox.attacks as fa\n",
    "from cleverhans.future.tf2.attacks import projected_gradient_descent, fast_gradient_method, carlini_wagner_l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = fb.models.TensorFlowModel(model, bounds=(0,1))\n",
    "attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps = 10,\n",
    "        steps = 10000,\n",
    "        stepsize = 0.03,\n",
    "        confidence = 0,\n",
    "        initial_const = .1,\n",
    "        abort_early = False)\n",
    "adv_foolbox, clipped_adversarials, success = attack(\n",
    "    fmodel,\n",
    "    x_to_attack,\n",
    "    y_to_attack,\n",
    "    epsilons=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleverhans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_inputs = tf.reshape(x_to_attack, [10,28,28,1]);\n",
    "\n",
    "adv_cleverhans = carlini_wagner_l2(model,clean_inputs,y=None,\n",
    "               batch_size=10,\n",
    "               clip_min=0.,\n",
    "               clip_max=1.,\n",
    "               binary_search_steps=10,\n",
    "               max_iterations=10000,\n",
    "               abort_early=False,\n",
    "               confidence=0.,\n",
    "               initial_const=.1,\n",
    "               learning_rate=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigene Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 63.81it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 66.16it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 66.19it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 65.22it/s]\n",
      "100%|██████████| 2000/2000 [00:29<00:00, 67.99it/s]\n",
      "100%|██████████| 2000/2000 [00:31<00:00, 63.71it/s]\n",
      "100%|██████████| 2000/2000 [00:33<00:00, 58.89it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 65.81it/s]\n",
      "100%|██████████| 2000/2000 [00:29<00:00, 68.13it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 65.58it/s]\n"
     ]
    }
   ],
   "source": [
    "adv_eigene = cw_2_eigene_implementierung(model,x_to_attack, steps=2000, const=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für Foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7419422,\n",
       " 1.966244,\n",
       " 1.9235889,\n",
       " 3.2785335,\n",
       " 0.6592007,\n",
       " 1.5094974,\n",
       " 1.3925312,\n",
       " 5.2131157,\n",
       " 0.78277963,\n",
       " 4.7382717]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_fb = [tf.norm(adv_foolbox[i]-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für Cleverhans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1152284,\n",
       " 2.717452,\n",
       " 2.6317878,\n",
       " 3.5959022,\n",
       " 0.6593815,\n",
       " 1.5495269,\n",
       " 1.6927584,\n",
       " 5.25638,\n",
       " 1.1933846,\n",
       " 3.9722528]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_ch = [tf.norm(adv_cleverhans[i].flatten()-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für eigene Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4702856,\n",
       " 1.0739771,\n",
       " 1.1837275,\n",
       " 0.56394136,\n",
       " 0.50728613,\n",
       " 0.81255347,\n",
       " 0.39085,\n",
       " 1.4712592,\n",
       " 0.42529005,\n",
       " 1.7937897]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_ei = [tf.norm(adv_eigene[i]-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = [x -.3 for x in range(10)]\n",
    "y = [x +.3 for x in range(10)]\n",
    "ax = plt.subplot(111)\n",
    "w = 0.3\n",
    "ax.bar(range(10),l2_ch,width=w, color='b', align='center',label='Cleverhans')\n",
    "ax.bar(y,l2_ei, width=w, color='g', align='center',label='eigene Implementierung')\n",
    "ax.bar(z,l2_fb, width=w, color='r', align='center', label='foolbox')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(labels )#loc='upper center')\n",
    "ax.set(title='CW2 Implementation Benchmark',ylabel='L2 Distance', xlabel='Sample No')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n",
      "[5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n",
      "[3, 2, 7, 8, 4, 8, 8, 7, 4, 7]\n",
      "[3, 2, 1, 8, 4, 8, 8, 7, 4, 7]\n",
      "[3, 2, 1, 8, 8, 8, 8, 7, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "res = fmodel(x_to_attack[:10])\n",
    "adv_fb_res = fmodel(adv_foolbox)\n",
    "adv_ch_res = fmodel(adv_cleverhans)\n",
    "adv_eigen_res = fmodel(np.array(adv_eigene))\n",
    "\n",
    "print(y_to_attack.numpy().tolist())\n",
    "print([np.argmax(x) for x in res])\n",
    "print([np.argmax(x) for x in adv_fb_res])\n",
    "print([np.argmax(x) for x in adv_ch_res])\n",
    "print([np.argmax(x) for x in adv_eigen_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-5 Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'conv_1': (5, 5, 1, 6),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'conv_2': (5, 5, 6, 16),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'conv_3': (1, 1, 16, 120),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'dense_1': (5*5*16, 120),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'dense_2': (120, 84),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'dense_3': (84, 10),\n",
    "}\n",
    "bias_shapes = {\n",
    "    #output depth\n",
    "    'conv_1': (6),\n",
    "    'conv_2': (16),\n",
    "    'dense_1': (120),\n",
    "    'dense_2': (84),\n",
    "    'dense_3': (10),\n",
    "}\n",
    "\n",
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='valid'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "#        return tf.keras.layers.AveragePooling2D(pool_size=(self.k, self.k), strides=None, padding=self.p, data_format='channels_first')(inputs)\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p,)# data_format='NCHW')\n",
    "    \n",
    "\n",
    "        \n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, shape, bias, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape=shape,\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "            name='w'\n",
    "        )\n",
    "        self.m = self.add_weight(\n",
    "            shape=shape,\n",
    "            initializer='ones',\n",
    "            trainable=False,\n",
    "            name='m'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape = (shape[-1]),\n",
    "            initializer = 'zeros',\n",
    "            trainable = True,\n",
    "            name='b'\n",
    "        )\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "\n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    def __init__(self, shape, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape = shape,\n",
    "            initializer='random_normal',\n",
    "            trainable = True,\n",
    "            name='w'\n",
    "        )\n",
    "        self.m = self.add_weight(\n",
    "            shape = shape,\n",
    "            initializer='ones',\n",
    "            trainable = False,\n",
    "            name='m'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape = (shape[-1]),\n",
    "            initializer = 'zeros',\n",
    "            trainable = True,\n",
    "            name='b'\n",
    "        )\n",
    "        self.a = activation\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        if self.a == None:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(shapes['conv_1'], True, 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(shapes['conv_2'], True, 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "\n",
    "        self.dense1 = CustomDenseLayer(shapes['dense_1'], True, 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(shapes['dense_2'], True, 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(shapes['dense_3'], True, None)\n",
    "        self.pre_softmax = None\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, shape=[-1,28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x =  self.dense3(x)\n",
    "        self.pre_softmax = x\n",
    "        return tf.nn.softmax(x)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=500,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=100,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "def initialize_base_model(index, experiment_name, save_weights=False):\n",
    "\n",
    "    model = CustomConvModel()\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "                 )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=x_train,\n",
    "              y=y_train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n",
    "    if save_weights == True:\n",
    "        model.save_weights(f'./saved-weights/{experiment_name}-{index}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x_to_attack = tf.convert_to_tensor(x_train[:10].reshape(10,28*28))\n",
    "y_to_attack = tf.convert_to_tensor([y_train[:10]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5936 - accuracy: 0.8896 - val_loss: 1.5150 - val_accuracy: 0.9503\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5053 - accuracy: 0.9592 - val_loss: 1.5026 - val_accuracy: 0.9622\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4934 - accuracy: 0.9695 - val_loss: 1.4900 - val_accuracy: 0.9729\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4865 - accuracy: 0.9761 - val_loss: 1.4857 - val_accuracy: 0.9770\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4828 - accuracy: 0.9798 - val_loss: 1.4853 - val_accuracy: 0.9771\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4798 - accuracy: 0.9824 - val_loss: 1.4812 - val_accuracy: 0.9803\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4777 - accuracy: 0.9845 - val_loss: 1.4807 - val_accuracy: 0.9815\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4770 - accuracy: 0.9848 - val_loss: 1.4811 - val_accuracy: 0.9809\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4752 - accuracy: 0.9868 - val_loss: 1.4778 - val_accuracy: 0.9840\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4735 - accuracy: 0.9883 - val_loss: 1.4777 - val_accuracy: 0.9845\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4730 - accuracy: 0.9888 - val_loss: 1.4762 - val_accuracy: 0.9852\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4726 - accuracy: 0.9892 - val_loss: 1.4759 - val_accuracy: 0.9860\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4720 - accuracy: 0.9895 - val_loss: 1.4794 - val_accuracy: 0.9820\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4711 - accuracy: 0.9906 - val_loss: 1.4809 - val_accuracy: 0.9812\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4706 - accuracy: 0.9911 - val_loss: 1.4755 - val_accuracy: 0.9861\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4704 - accuracy: 0.9912 - val_loss: 1.4751 - val_accuracy: 0.9864\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4700 - accuracy: 0.9918 - val_loss: 1.4747 - val_accuracy: 0.9870\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 1.4694 - accuracy: 0.9922 - val_loss: 1.4753 - val_accuracy: 0.9863\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4693 - accuracy: 0.9923 - val_loss: 1.4749 - val_accuracy: 0.9863\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4686 - accuracy: 0.9929 - val_loss: 1.4741 - val_accuracy: 0.9875\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4685 - accuracy: 0.9930 - val_loss: 1.4765 - val_accuracy: 0.9848\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4687 - accuracy: 0.9928 - val_loss: 1.4765 - val_accuracy: 0.9847\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4685 - accuracy: 0.9929 - val_loss: 1.4743 - val_accuracy: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CustomConvModel at 0x7f3dac6b1700>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initialize_base_model(999,'')\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigene Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_2_eigene_implementierung(model, xs, const=1, steps=1000, learning_rate=.03, ):\n",
    "    xa=[]\n",
    "    \n",
    "    for x in xs:\n",
    "        w = tf.Variable(initial_value=tf.zeros(x.shape))\n",
    "        \n",
    "        show_adv = []\n",
    "        optimizer = tf.keras.optimizers.Adam(.03)\n",
    "        target = find_second_most_probable_class(get_logits(model,x))\n",
    "        adv_image = .5 * (tf.tanh(w) + 1)\n",
    "        best_adv_image = adv_image\n",
    "        best_l2_dist = tf.norm(adv_image - x).numpy()\n",
    "        for i in tqdm(range(steps)):\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                adv_image = .5 * (tf.tanh(w) + 1)\n",
    "                preds = model(adv_image)\n",
    "                #const= CONST\n",
    "                loss = loss_function(model= model, x=x, adv_image=adv_image, const=const, target=target)\n",
    "                l2_distance = tf.norm(adv_image - x).numpy()\n",
    "                if l2_distance < best_l2_dist and np.argmax(preds) == target:\n",
    "                    best_adv_image = adv_image\n",
    "                    best_l2_dist = l2_distance\n",
    "                grads = tape.gradient(loss, w)\n",
    "                optimizer.apply_gradients([(grads, w)])\n",
    "                #print('l2 dist:', l2_distance)\n",
    "                #print('target class: ',target)\n",
    "                #print('pred of adv ex: ',np.argmax(model(adv_image)))\n",
    "                #plt.figure()\n",
    "                #plt.imshow(tf.reshape(adv_image, (28,28)))\n",
    "                #plt.show()\n",
    "                \n",
    "        xa.append(best_adv_image)\n",
    "    return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(model, x, adv_image, const, target):\n",
    "    l1 = tf.square(tf.norm(adv_image - x))\n",
    "    logit_of_best_other = get_logit_of_best_except_target(model, adv_image, target)\n",
    "    logit_of_target = get_logit_of_target(model, adv_image,target)\n",
    "    l2 = const * tf.math.maximum(\n",
    "        logit_of_best_other\n",
    "        - logit_of_target\n",
    "        , 0 )\n",
    "    return l1 + l2\n",
    "\n",
    "\n",
    "def find_second_most_probable_class(logits):\n",
    "    logits = logits.numpy().flatten()\n",
    "    return np.argpartition(logits,len(logits)-2)[len(logits)-2]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def get_logit_of_best_except_target(model, adv_x, target):\n",
    "    all_logits = get_logits(model, adv_x)\n",
    "    #print('all_logits', all_logits)\n",
    "    most_probable_class = tf.math.argmax(all_logits)\n",
    "    second_most_probable_class = find_second_most_probable_class(all_logits)\n",
    "    if target == most_probable_class: \n",
    "        return all_logits[second_most_probable_class ]\n",
    "    if target != most_probable_class: \n",
    "        return all_logits[most_probable_class ]\n",
    "\n",
    "def get_logit_of_target(model, adv_x, target):\n",
    "    all_logits = get_logits(model, adv_x)\n",
    "    return all_logits[target]\n",
    "\n",
    "def get_logits(model, x):\n",
    "    model(x)\n",
    "    return model.pre_softmax[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't use all available GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * x of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 1)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
