{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from absl import app, flags\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox as fb\n",
    "#rom foolbox import TensorFlowModel, accuracy, samples\n",
    "#mport foolbox.attacks as fa\n",
    "from cleverhans.future.tf2.attacks import projected_gradient_descent, fast_gradient_method, carlini_wagner_l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = fb.models.TensorFlowModel(model, bounds=(0,1))\n",
    "attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps = 10,\n",
    "        steps = 10000,\n",
    "        stepsize = 0.03,\n",
    "        confidence = 0,\n",
    "        initial_const = .1,\n",
    "        abort_early = True)\n",
    "adv_foolbox, clipped_adversarials, success = attack(\n",
    "    fmodel,\n",
    "    x_to_attack,\n",
    "    y_to_attack,\n",
    "    epsilons=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleverhans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_inputs = tf.reshape(x_to_attack, [10,28,28,1]);\n",
    "\n",
    "adv_cleverhans = carlini_wagner_l2(model,clean_inputs,y=None,\n",
    "               batch_size=10,\n",
    "               clip_min=0.,\n",
    "               clip_max=1.,\n",
    "               binary_search_steps=10,\n",
    "               max_iterations=10000,\n",
    "               abort_early=False,\n",
    "               confidence=0.,\n",
    "               initial_const=.1,\n",
    "               learning_rate=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigene Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 63.52it/s]\n",
      "100%|██████████| 2000/2000 [00:32<00:00, 62.40it/s]\n",
      "100%|██████████| 2000/2000 [00:32<00:00, 62.01it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 65.06it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 65.84it/s]\n",
      "100%|██████████| 2000/2000 [00:29<00:00, 67.60it/s]\n",
      "100%|██████████| 2000/2000 [00:28<00:00, 69.54it/s]\n",
      "100%|██████████| 2000/2000 [00:29<00:00, 68.51it/s]\n",
      "100%|██████████| 2000/2000 [00:29<00:00, 67.17it/s]\n",
      "100%|██████████| 2000/2000 [00:32<00:00, 61.93it/s]\n"
     ]
    }
   ],
   "source": [
    "adv_eigene = cw_2_eigene_implementierung(model,x_to_attack, steps=2000, const=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für Foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27698365,\n",
       " 4.467263,\n",
       " 3.0980809,\n",
       " 1.4680731,\n",
       " 0.52765006,\n",
       " 2.3055704,\n",
       " 1.6391438,\n",
       " 4.9969068,\n",
       " 3.2843807,\n",
       " 1.7282153]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_fb = [tf.norm(adv_foolbox[i]-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für Cleverhans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41441822,\n",
       " 3.494786,\n",
       " 3.8353348,\n",
       " 2.3682518,\n",
       " 0.80121773,\n",
       " 2.360535,\n",
       " 1.9128388,\n",
       " 5.1769786,\n",
       " 1.7254946,\n",
       " 1.8560805]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_ch = [tf.norm(adv_cleverhans[i].flatten()-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für eigene Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36972156,\n",
       " 1.0551662,\n",
       " 0.88235486,\n",
       " 0.42711136,\n",
       " 0.39737734,\n",
       " 0.96320105,\n",
       " 0.4400873,\n",
       " 1.1267165,\n",
       " 0.53550375,\n",
       " 0.8555029]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_ei = [tf.norm(adv_eigene[i]-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = [x -.3 for x in range(10)]\n",
    "y = [x +.3 for x in range(10)]\n",
    "ax = plt.subplot(111)\n",
    "w = 0.3\n",
    "ax.bar(range(10),l2_ch,width=w, color='b', align='center',label='foolbox')\n",
    "ax.bar(y,l2_ei, width=w, color='g', align='center',label='cleverhans')\n",
    "ax.bar(z,l2_fb, width=w, color='r', align='center', label='eigene implementierung')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(labels )#loc='upper center')\n",
    "ax.set(title='CW2 Implementation Benchmark',ylabel='L2 Distance', xlabel='Sample No')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n",
      "[5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n",
      "[3, 2, 7, 8, 4, 8, 8, 7, 4, 7]\n",
      "[3, 2, 1, 8, 4, 8, 8, 7, 4, 7]\n",
      "[3, 2, 1, 8, 8, 8, 8, 7, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "res = fmodel(x_to_attack[:10])\n",
    "adv_fb_res = fmodel(adv_foolbox)\n",
    "adv_ch_res = fmodel(adv_cleverhans)\n",
    "adv_eigen_res = fmodel(np.array(adv_eigene))\n",
    "\n",
    "print(y_to_attack.numpy().tolist())\n",
    "print([np.argmax(x) for x in res])\n",
    "print([np.argmax(x) for x in adv_fb_res])\n",
    "print([np.argmax(x) for x in adv_ch_res])\n",
    "print([np.argmax(x) for x in adv_eigen_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-5 Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'conv_1': (5, 5, 1, 6),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'conv_2': (5, 5, 6, 16),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'conv_3': (1, 1, 16, 120),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'dense_1': (5*5*16, 120),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'dense_2': (120, 84),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'dense_3': (84, 10),\n",
    "}\n",
    "bias_shapes = {\n",
    "    #output depth\n",
    "    'conv_1': (6),\n",
    "    'conv_2': (16),\n",
    "    'dense_1': (120),\n",
    "    'dense_2': (84),\n",
    "    'dense_3': (10),\n",
    "}\n",
    "\n",
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='valid'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "#        return tf.keras.layers.AveragePooling2D(pool_size=(self.k, self.k), strides=None, padding=self.p, data_format='channels_first')(inputs)\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p,)# data_format='NCHW')\n",
    "    \n",
    "\n",
    "        \n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, shape, bias, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape=shape,\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "            name='w'\n",
    "        )\n",
    "        self.m = self.add_weight(\n",
    "            shape=shape,\n",
    "            initializer='ones',\n",
    "            trainable=False,\n",
    "            name='m'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape = (shape[-1]),\n",
    "            initializer = 'zeros',\n",
    "            trainable = True,\n",
    "            name='b'\n",
    "        )\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "\n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    def __init__(self, shape, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape = shape,\n",
    "            initializer='random_normal',\n",
    "            trainable = True,\n",
    "            name='w'\n",
    "        )\n",
    "        self.m = self.add_weight(\n",
    "            shape = shape,\n",
    "            initializer='ones',\n",
    "            trainable = False,\n",
    "            name='m'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape = (shape[-1]),\n",
    "            initializer = 'zeros',\n",
    "            trainable = True,\n",
    "            name='b'\n",
    "        )\n",
    "        self.a = activation\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        if self.a == None:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(shapes['conv_1'], True, 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(shapes['conv_2'], True, 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "\n",
    "        self.dense1 = CustomDenseLayer(shapes['dense_1'], True, 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(shapes['dense_2'], True, 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(shapes['dense_3'], True, None)\n",
    "        self.pre_softmax = None\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, shape=[-1,28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x =  self.dense3(x)\n",
    "        self.pre_softmax = x\n",
    "        return tf.nn.softmax(x)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=500,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=100,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "def initialize_base_model(index, experiment_name, save_weights=False):\n",
    "\n",
    "    model = CustomConvModel()\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "                 )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=x_train,\n",
    "              y=y_train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n",
    "    if save_weights == True:\n",
    "        model.save_weights(f'./saved-weights/{experiment_name}-{index}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x_to_attack = tf.convert_to_tensor(x_train[:10].reshape(10,28*28))\n",
    "y_to_attack = tf.convert_to_tensor([y_train[:10]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5928 - accuracy: 0.8909 - val_loss: 1.5168 - val_accuracy: 0.9490\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5051 - accuracy: 0.9595 - val_loss: 1.4944 - val_accuracy: 0.9686\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4917 - accuracy: 0.9718 - val_loss: 1.4897 - val_accuracy: 0.9729\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4859 - accuracy: 0.9770 - val_loss: 1.4828 - val_accuracy: 0.9800\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4821 - accuracy: 0.9803 - val_loss: 1.4837 - val_accuracy: 0.9782\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4794 - accuracy: 0.9830 - val_loss: 1.4802 - val_accuracy: 0.9810\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4769 - accuracy: 0.9852 - val_loss: 1.4813 - val_accuracy: 0.9804\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4757 - accuracy: 0.9862 - val_loss: 1.4806 - val_accuracy: 0.9811\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4744 - accuracy: 0.9876 - val_loss: 1.4781 - val_accuracy: 0.9833\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4726 - accuracy: 0.9893 - val_loss: 1.4765 - val_accuracy: 0.9848\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4721 - accuracy: 0.9898 - val_loss: 1.4766 - val_accuracy: 0.9849\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4713 - accuracy: 0.9904 - val_loss: 1.4771 - val_accuracy: 0.9840\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4710 - accuracy: 0.9906 - val_loss: 1.4764 - val_accuracy: 0.9847\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4705 - accuracy: 0.9911 - val_loss: 1.4774 - val_accuracy: 0.9837\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4702 - accuracy: 0.9915 - val_loss: 1.4755 - val_accuracy: 0.9860\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4691 - accuracy: 0.9924 - val_loss: 1.4769 - val_accuracy: 0.9845\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4690 - accuracy: 0.9926 - val_loss: 1.4756 - val_accuracy: 0.9857\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4687 - accuracy: 0.9930 - val_loss: 1.4752 - val_accuracy: 0.9861\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4684 - accuracy: 0.9932 - val_loss: 1.4757 - val_accuracy: 0.9860\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4687 - accuracy: 0.9929 - val_loss: 1.4761 - val_accuracy: 0.9853\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4689 - accuracy: 0.9926 - val_loss: 1.4735 - val_accuracy: 0.9878\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4672 - accuracy: 0.9943 - val_loss: 1.4775 - val_accuracy: 0.9837\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4674 - accuracy: 0.9941 - val_loss: 1.4741 - val_accuracy: 0.9869\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4671 - accuracy: 0.9944 - val_loss: 1.4756 - val_accuracy: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CustomConvModel at 0x7f277e60e0d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initialize_base_model(999,'')\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigene Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_2_eigene_implementierung(model, xs, const=1, steps=1000, learning_rate=.03, ):\n",
    "    xa=[]\n",
    "    \n",
    "    for x in xs:\n",
    "        w = tf.Variable(initial_value=tf.zeros(x.shape))\n",
    "        \n",
    "        show_adv = []\n",
    "        optimizer = tf.keras.optimizers.Adam(.03)\n",
    "        target = find_second_most_probable_class(get_logits(model,x))\n",
    "        adv_image = .5 * (tf.tanh(w) + 1)\n",
    "        best_adv_image = adv_image\n",
    "        best_l2_dist = tf.norm(adv_image - x).numpy()\n",
    "        for i in tqdm(range(steps)):\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                adv_image = .5 * (tf.tanh(w) + 1)\n",
    "                preds = model(adv_image)\n",
    "                #const= CONST\n",
    "                loss = loss_function(model= model, x=x, adv_image=adv_image, const=const, target=target)\n",
    "                l2_distance = tf.norm(adv_image - x).numpy()\n",
    "                if l2_distance < best_l2_dist and np.argmax(preds) == target:\n",
    "                    best_adv_image = adv_image\n",
    "                    best_l2_dist = l2_distance\n",
    "                grads = tape.gradient(loss, w)\n",
    "                optimizer.apply_gradients([(grads, w)])\n",
    "                #print('l2 dist:', l2_distance)\n",
    "                #print('target class: ',target)\n",
    "                #print('pred of adv ex: ',np.argmax(model(adv_image)))\n",
    "                #plt.figure()\n",
    "                #plt.imshow(tf.reshape(adv_image, (28,28)))\n",
    "                #plt.show()\n",
    "                \n",
    "        xa.append(best_adv_image)\n",
    "    return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(model, x, adv_image, const, target):\n",
    "    l1 = tf.square(tf.norm(adv_image - x))\n",
    "    logit_of_best_other = get_logit_of_best_except_target(model, adv_image, target)\n",
    "    logit_of_target = get_logit_of_target(model, adv_image,target)\n",
    "    l2 = const * tf.math.maximum(\n",
    "        logit_of_best_other\n",
    "        - logit_of_target\n",
    "        , 0 )\n",
    "    return l1 + l2\n",
    "\n",
    "\n",
    "def find_second_most_probable_class(logits):\n",
    "    logits = logits.numpy().flatten()\n",
    "    return np.argpartition(logits,len(logits)-2)[len(logits)-2]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def get_logit_of_best_except_target(model, adv_x, target):\n",
    "    all_logits = get_logits(model, adv_x)\n",
    "    #print('all_logits', all_logits)\n",
    "    most_probable_class = tf.math.argmax(all_logits)\n",
    "    second_most_probable_class = find_second_most_probable_class(all_logits)\n",
    "    if target == most_probable_class: \n",
    "        return all_logits[second_most_probable_class ]\n",
    "    if target != most_probable_class: \n",
    "        return all_logits[most_probable_class ]\n",
    "\n",
    "def get_logit_of_target(model, adv_x, target):\n",
    "    all_logits = get_logits(model, adv_x)\n",
    "    return all_logits[target]\n",
    "\n",
    "def get_logits(model, x):\n",
    "    model(x)\n",
    "    return model.pre_softmax[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't use all available GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * x of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 4)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
