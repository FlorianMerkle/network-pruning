{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from absl import app, flags\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox as fb\n",
    "#rom foolbox import TensorFlowModel, accuracy, samples\n",
    "#mport foolbox.attacks as fa\n",
    "from cleverhans.future.tf2.attacks import projected_gradient_descent, fast_gradient_method, carlini_wagner_l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = fb.models.TensorFlowModel(model, bounds=(0,1))\n",
    "attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps = 10,\n",
    "        steps = 10000,\n",
    "        stepsize = 0.03,\n",
    "        confidence = 0,\n",
    "        initial_const = .1,\n",
    "        abort_early = True)\n",
    "adv_foolbox, clipped_adversarials, success = attack(\n",
    "    fmodel,\n",
    "    x_to_attack,\n",
    "    y_to_attack,\n",
    "    epsilons=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleverhans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_inputs = tf.reshape(x_to_attack, [10,28,28,1]);\n",
    "\n",
    "adv_cleverhans = carlini_wagner_l2(model,clean_inputs,y=None,\n",
    "               batch_size=10,\n",
    "               clip_min=0.,\n",
    "               clip_max=1.,\n",
    "               binary_search_steps=10,\n",
    "               max_iterations=10000,\n",
    "               abort_early=False,\n",
    "               confidence=0.,\n",
    "               initial_const=.1,\n",
    "               learning_rate=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigene Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 63.52it/s]\n",
      "100%|██████████| 2000/2000 [00:32<00:00, 62.40it/s]\n",
      "100%|██████████| 2000/2000 [00:32<00:00, 62.01it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 65.06it/s]\n",
      "100%|██████████| 2000/2000 [00:30<00:00, 65.84it/s]\n",
      "100%|██████████| 2000/2000 [00:29<00:00, 67.60it/s]\n",
      "100%|██████████| 2000/2000 [00:28<00:00, 69.54it/s]\n",
      "100%|██████████| 2000/2000 [00:29<00:00, 68.51it/s]\n",
      "100%|██████████| 2000/2000 [00:29<00:00, 67.17it/s]\n",
      "100%|██████████| 2000/2000 [00:32<00:00, 61.93it/s]\n"
     ]
    }
   ],
   "source": [
    "adv_eigene = cw_2_eigene_implementierung(model,x_to_attack, steps=2000, const=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für Foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27698365,\n",
       " 4.467263,\n",
       " 3.0980809,\n",
       " 1.4680731,\n",
       " 0.52765006,\n",
       " 2.3055704,\n",
       " 1.6391438,\n",
       " 4.9969068,\n",
       " 3.2843807,\n",
       " 1.7282153]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_fb = [tf.norm(adv_foolbox[i]-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für Cleverhans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41441822,\n",
       " 3.494786,\n",
       " 3.8353348,\n",
       " 2.3682518,\n",
       " 0.80121773,\n",
       " 2.360535,\n",
       " 1.9128388,\n",
       " 5.1769786,\n",
       " 1.7254946,\n",
       " 1.8560805]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_ch = [tf.norm(adv_cleverhans[i].flatten()-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Distance für eigene Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36972156,\n",
       " 1.0551662,\n",
       " 0.88235486,\n",
       " 0.42711136,\n",
       " 0.39737734,\n",
       " 0.96320105,\n",
       " 0.4400873,\n",
       " 1.1267165,\n",
       " 0.53550375,\n",
       " 0.8555029]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_ei = [tf.norm(adv_eigene[i]-x_to_attack[i]).numpy() for i in range(len(x_to_attack))]\n",
    "l2_ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-160-dcb0fbad8106>:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax = plt.subplot(111)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = [x -.3 for x in range(10)]\n",
    "y = [x +.3 for x in range(10)]\n",
    "ax = plt.subplot(111)\n",
    "w = 0.3\n",
    "ax.bar(range(10),l2_ch,width=w, color='b', align='center',label='foolbox')\n",
    "ax.bar(y,l2_ei, width=w, color='g', align='center',label='cleverhans')\n",
    "ax.bar(z,l2_fb, width=w, color='r', align='center', label='eigene implementierung')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, )#loc='upper center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n",
      "[5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n",
      "[3, 2, 7, 8, 4, 8, 8, 7, 4, 7]\n",
      "[3, 2, 1, 8, 4, 8, 8, 7, 4, 7]\n",
      "[3, 2, 1, 8, 8, 8, 8, 7, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "res = fmodel(x_to_attack[:10])\n",
    "adv_fb_res = fmodel(adv_foolbox)\n",
    "adv_ch_res = fmodel(adv_cleverhans)\n",
    "adv_eigen_res = fmodel(np.array(adv_eigene))\n",
    "\n",
    "print(y_to_attack.numpy().tolist())\n",
    "print([np.argmax(x) for x in res])\n",
    "print([np.argmax(x) for x in adv_fb_res])\n",
    "print([np.argmax(x) for x in adv_ch_res])\n",
    "print([np.argmax(x) for x in adv_eigen_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-5 Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    # 5x5 conv, 1 input, 6 outputs\n",
    "    'conv_1': (5, 5, 1, 6),\n",
    "    # 5x5 conv, 6 inputs, 16 outputs\n",
    "    'conv_2': (5, 5, 6, 16),\n",
    "    #5x5 conv as in paper, 16 inputs, 120 outputs\n",
    "    'conv_3': (1, 1, 16, 120),\n",
    "    # fully connected, 5*5*16 inputs, 120 outputs\n",
    "    'dense_1': (5*5*16, 120),\n",
    "    # fully connected, 120 inputs, 84 outputs\n",
    "    'dense_2': (120, 84),\n",
    "    # 84 inputs, 10 outputs (class prediction)\n",
    "    'dense_3': (84, 10),\n",
    "}\n",
    "bias_shapes = {\n",
    "    #output depth\n",
    "    'conv_1': (6),\n",
    "    'conv_2': (16),\n",
    "    'dense_1': (120),\n",
    "    'dense_2': (84),\n",
    "    'dense_3': (10),\n",
    "}\n",
    "\n",
    "#conv2D with bias and relu activation\n",
    "\n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, weights, mask, biases, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = weights\n",
    "        self.m = mask\n",
    "        self.b = biases\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "#Average Pooling Layer\n",
    "class CustomPoolLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, k=2, padding='valid'):#padding='VALID'):\n",
    "        super(CustomPoolLayer, self).__init__()\n",
    "        self.k = k\n",
    "        self.p = padding\n",
    "    \n",
    "    def call(self, inputs):\n",
    "#        return tf.keras.layers.AveragePooling2D(pool_size=(self.k, self.k), strides=None, padding=self.p, data_format='channels_first')(inputs)\n",
    "        return tf.nn.avg_pool2d(inputs, ksize=[1, self.k, self.k,1], strides=[1, self.k, self.k, 1], padding=self.p,)# data_format='NCHW')\n",
    "    \n",
    "\n",
    "        \n",
    "class CustomConvLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, shape, bias, strides, padding='SAME'):\n",
    "        \n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape=shape,\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "            name='w'\n",
    "        )\n",
    "        self.m = self.add_weight(\n",
    "            shape=shape,\n",
    "            initializer='ones',\n",
    "            trainable=False,\n",
    "            name='m'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape = (shape[-1]),\n",
    "            initializer = 'zeros',\n",
    "            trainable = True,\n",
    "            name='b'\n",
    "        )\n",
    "        self.s = strides\n",
    "        self.p = padding\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, tf.multiply(self.w, self.m), strides=[1, self.s, self.s, 1], padding=self.p,)# data_format='NCHW')\n",
    "        x = tf.nn.bias_add(x, self.b,)# 'NC...')\n",
    "        return tf.nn.tanh(x)\n",
    "\n",
    "#Dense Layer with Bias\n",
    "class CustomDenseLayer(layers.Layer):\n",
    "    def __init__(self, shape, bias, activation = 'tanh'):\n",
    "        super(CustomDenseLayer, self).__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape = shape,\n",
    "            initializer='random_normal',\n",
    "            trainable = True,\n",
    "            name='w'\n",
    "        )\n",
    "        self.m = self.add_weight(\n",
    "            shape = shape,\n",
    "            initializer='ones',\n",
    "            trainable = False,\n",
    "            name='m'\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape = (shape[-1]),\n",
    "            initializer = 'zeros',\n",
    "            trainable = True,\n",
    "            name='b'\n",
    "        )\n",
    "        self.a = activation\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, tf.multiply(self.w, self.m))\n",
    "        x = tf.nn.bias_add(x, self.b)\n",
    "        if self.a == 'tanh':\n",
    "            return tf.nn.tanh(x)\n",
    "        if self.a == 'softmax':\n",
    "            return tf.nn.softmax(x)\n",
    "        if self.a == None:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class CustomConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvModel, self).__init__()\n",
    "        self.conv1 = CustomConvLayer(shapes['conv_1'], True, 1, 'SAME')#'VALID')\n",
    "        self.maxpool1 = CustomPoolLayer(k=2, padding='SAME')\n",
    "        self.conv2 = CustomConvLayer(shapes['conv_2'], True, 1, 'VALID')\n",
    "        self.maxpool2 = CustomPoolLayer(k=2, padding='VALID')\n",
    "\n",
    "        self.dense1 = CustomDenseLayer(shapes['dense_1'], True, 'tanh')\n",
    "        self.dense2 = CustomDenseLayer(shapes['dense_2'], True, 'tanh')\n",
    "        self.dense3 = CustomDenseLayer(shapes['dense_3'], True, None)\n",
    "        self.pre_softmax = None\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, shape=[-1,28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x =  self.dense3(x)\n",
    "        self.pre_softmax = x\n",
    "        return tf.nn.softmax(x)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, to_convergence=True):\n",
    "    if to_convergence == True:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=500,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    if to_convergence == False:\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=100,\n",
    "            callbacks=[callback],\n",
    "            validation_data=(x_test, y_test),\n",
    "            )\n",
    "    return model\n",
    "def initialize_base_model(index, experiment_name, save_weights=False):\n",
    "\n",
    "    model = CustomConvModel()\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "                 )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=x_train,\n",
    "              y=y_train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n",
    "    if save_weights == True:\n",
    "        model.save_weights(f'./saved-weights/{experiment_name}-{index}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "x_to_attack = tf.convert_to_tensor(x_train[:10].reshape(10,28*28))\n",
    "y_to_attack = tf.convert_to_tensor([y_train[:10]])[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5928 - accuracy: 0.8909 - val_loss: 1.5168 - val_accuracy: 0.9490\n",
      "Epoch 1/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.5051 - accuracy: 0.9595 - val_loss: 1.4944 - val_accuracy: 0.9686\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4917 - accuracy: 0.9718 - val_loss: 1.4897 - val_accuracy: 0.9729\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4859 - accuracy: 0.9770 - val_loss: 1.4828 - val_accuracy: 0.9800\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4821 - accuracy: 0.9803 - val_loss: 1.4837 - val_accuracy: 0.9782\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4794 - accuracy: 0.9830 - val_loss: 1.4802 - val_accuracy: 0.9810\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4769 - accuracy: 0.9852 - val_loss: 1.4813 - val_accuracy: 0.9804\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4757 - accuracy: 0.9862 - val_loss: 1.4806 - val_accuracy: 0.9811\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4744 - accuracy: 0.9876 - val_loss: 1.4781 - val_accuracy: 0.9833\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4726 - accuracy: 0.9893 - val_loss: 1.4765 - val_accuracy: 0.9848\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4721 - accuracy: 0.9898 - val_loss: 1.4766 - val_accuracy: 0.9849\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4713 - accuracy: 0.9904 - val_loss: 1.4771 - val_accuracy: 0.9840\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4710 - accuracy: 0.9906 - val_loss: 1.4764 - val_accuracy: 0.9847\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4705 - accuracy: 0.9911 - val_loss: 1.4774 - val_accuracy: 0.9837\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4702 - accuracy: 0.9915 - val_loss: 1.4755 - val_accuracy: 0.9860\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4691 - accuracy: 0.9924 - val_loss: 1.4769 - val_accuracy: 0.9845\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4690 - accuracy: 0.9926 - val_loss: 1.4756 - val_accuracy: 0.9857\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4687 - accuracy: 0.9930 - val_loss: 1.4752 - val_accuracy: 0.9861\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4684 - accuracy: 0.9932 - val_loss: 1.4757 - val_accuracy: 0.9860\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4687 - accuracy: 0.9929 - val_loss: 1.4761 - val_accuracy: 0.9853\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4689 - accuracy: 0.9926 - val_loss: 1.4735 - val_accuracy: 0.9878\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4672 - accuracy: 0.9943 - val_loss: 1.4775 - val_accuracy: 0.9837\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4674 - accuracy: 0.9941 - val_loss: 1.4741 - val_accuracy: 0.9869\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4671 - accuracy: 0.9944 - val_loss: 1.4756 - val_accuracy: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CustomConvModel at 0x7f277e60e0d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initialize_base_model(999,'')\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigene Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_2_eigene_implementierung(model, xs, const=1, steps=1000, learning_rate=.03, ):\n",
    "    xa=[]\n",
    "    \n",
    "    for x in xs:\n",
    "        w = tf.Variable(initial_value=tf.zeros(x.shape))\n",
    "        \n",
    "        show_adv = []\n",
    "        optimizer = tf.keras.optimizers.Adam(.03)\n",
    "        target = find_second_most_probable_class(get_logits(model,x))\n",
    "        adv_image = .5 * (tf.tanh(w) + 1)\n",
    "        best_adv_image = adv_image\n",
    "        best_l2_dist = tf.norm(adv_image - x).numpy()\n",
    "        for i in tqdm(range(steps)):\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                adv_image = .5 * (tf.tanh(w) + 1)\n",
    "                preds = model(adv_image)\n",
    "                #const= CONST\n",
    "                loss = loss_function(model= model, x=x, adv_image=adv_image, const=const, target=target)\n",
    "                l2_distance = tf.norm(adv_image - x).numpy()\n",
    "                if l2_distance < best_l2_dist and np.argmax(preds) == target:\n",
    "                    best_adv_image = adv_image\n",
    "                    best_l2_dist = l2_distance\n",
    "                grads = tape.gradient(loss, w)\n",
    "                optimizer.apply_gradients([(grads, w)])\n",
    "                #print('l2 dist:', l2_distance)\n",
    "                #print('target class: ',target)\n",
    "                #print('pred of adv ex: ',np.argmax(model(adv_image)))\n",
    "                #plt.figure()\n",
    "                #plt.imshow(tf.reshape(adv_image, (28,28)))\n",
    "                #plt.show()\n",
    "                \n",
    "        xa.append(best_adv_image)\n",
    "    return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(model, x, adv_image, const, target):\n",
    "    l1 = tf.square(tf.norm(adv_image - x))\n",
    "    logit_of_best_other = get_logit_of_best_except_target(model, adv_image, target)\n",
    "    logit_of_target = get_logit_of_target(model, adv_image,target)\n",
    "    l2 = const * tf.math.maximum(\n",
    "        logit_of_best_other\n",
    "        - logit_of_target\n",
    "        , 0 )\n",
    "    return l1 + l2\n",
    "\n",
    "\n",
    "def find_second_most_probable_class(logits):\n",
    "    logits = logits.numpy().flatten()\n",
    "    return np.argpartition(logits,len(logits)-2)[len(logits)-2]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def get_logit_of_best_except_target(model, adv_x, target):\n",
    "    all_logits = get_logits(model, adv_x)\n",
    "    #print('all_logits', all_logits)\n",
    "    most_probable_class = tf.math.argmax(all_logits)\n",
    "    second_most_probable_class = find_second_most_probable_class(all_logits)\n",
    "    if target == most_probable_class: \n",
    "        return all_logits[second_most_probable_class ]\n",
    "    if target != most_probable_class: \n",
    "        return all_logits[most_probable_class ]\n",
    "\n",
    "def get_logit_of_target(model, adv_x, target):\n",
    "    all_logits = get_logits(model, adv_x)\n",
    "    return all_logits[target]\n",
    "\n",
    "def get_logits(model, x):\n",
    "    model(x)\n",
    "    return model.pre_softmax[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't use all available GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * x of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 4)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
