{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3cf4807c2ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import app, flags\n",
    "from easydict import EasyDict\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dense, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cleverhans.future.tf2.attacks import projected_gradient_descent, fast_gradient_method\n",
    "\n",
    "import foolbox as fb\n",
    "import eagerpy as ep\n",
    "from foolbox import TensorFlowModel, accuracy, samples\n",
    "import foolbox.attacks as fa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, activation='relu'):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #print(input_shape)\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.mask = self.add_weight(shape=(self.w.shape),\n",
    "                                    initializer='ones',\n",
    "                                    trainable=False)\n",
    "        self.pruned_w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='ones',\n",
    "                                 trainable=False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #self.mask_2 = tf.multiply(self.mask, self.mask_2)\n",
    "        self.pruned_w = tf.multiply(self.w, self.mask)\n",
    "        #print('layer inputy', inputs.shape)\n",
    "        x = tf.matmul(inputs, self.pruned_w)\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return tf.keras.activations.relu(x)\n",
    "        if self.activation == 'softmax':\n",
    "            return tf.keras.activations.softmax(x)\n",
    "        raise ValueError('Activation function not implemented')\n",
    "\n",
    "\n",
    "class LeNet300_100(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet300_100, self).__init__()\n",
    "        self.dense1 = CustomLayer(300)\n",
    "        self.dense2 = CustomLayer(100)\n",
    "        self.dense3 = CustomLayer(10, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print('NN call',inputs.shape)\n",
    "        x = tf.keras.layers.Flatten()(inputs)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        #print(x.shape)\n",
    "        return self.dense3(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ld_mnist():\n",
    "    \"\"\"Load training and test data.\"\"\"\n",
    "\n",
    "    def convert_types(image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255\n",
    "        return image, label\n",
    "\n",
    "    dataset, info = tfds.load('mnist', \n",
    "                              data_dir='gs://tfds-data/datasets', \n",
    "                              with_info=True,\n",
    "                              as_supervised=True)\n",
    "    mnist_train, mnist_test = dataset['train'], dataset['test']\n",
    "    mnist_train = mnist_train.map(convert_types).shuffle(10000).batch(128)\n",
    "    mnist_test = mnist_test.map(convert_types).batch(128)\n",
    "    return EasyDict(train=mnist_train, test=mnist_test)\n",
    "data = ld_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = LeNet300_100()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                  metrics=['accuracy'],\n",
    "                  experimental_run_tf_function=False\n",
    "                 )\n",
    "    return model\n",
    "\n",
    "def train_model(model):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(x=data.train,\n",
    "              #batch_size=64,\n",
    "              epochs=5000,\n",
    "              callbacks=[callback],\n",
    "              validation_data=(x_test, y_test),\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "Epoch 1/5000\n",
      "    469/Unknown - 11s 24ms/step - loss: 1.4667 - accuracy: 0.9946- 11s 24ms/step - loss: 1.4667 - accuracy: 0.Epoch 1/5000\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 1.4667 - accuracy: 0.9946 - val_loss: 1.4805 - val_accuracy: 0.9804\n",
      "Epoch 2/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4664 - accuracy: 0.9950Epoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 1.4664 - accuracy: 0.9950 - val_loss: 1.4805 - val_accuracy: 0.9809\n",
      "Epoch 3/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4660 - accuracy: 0.9952Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4661 - accuracy: 0.9952 - val_loss: 1.4792 - val_accuracy: 0.9824\n",
      "Epoch 4/5000\n",
      "466/469 [============================>.] - ETA: 0s - loss: 1.4662 - accuracy: 0.9952Epoch 1/5000\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 1.4662 - accuracy: 0.9952 - val_loss: 1.4810 - val_accuracy: 0.9799\n",
      "Epoch 5/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4664 - accuracy: 0.9950Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4665 - accuracy: 0.9949 - val_loss: 1.4804 - val_accuracy: 0.9816\n",
      "Epoch 6/5000\n",
      "465/469 [============================>.] - ETA: 0s - loss: 1.4662 - accuracy: 0.9951Epoch 1/5000\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 1.4662 - accuracy: 0.9951 - val_loss: 1.4805 - val_accuracy: 0.9808\n",
      "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
      "   [0.98 0.97 0.97 0.27 0.09 0.02 0.   0.   0.   0.   0.   0.   0.  ]\n",
      "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
      "   [0.98 0.97 0.97 0.16 0.02 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "Epoch 1/5000\n",
      "    469/Unknown - 11s 24ms/step - loss: 1.4660 - accuracy: 0.9954- 11s 25ms/step - loss: 1.4660 - accurEpoch 1/5000\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 1.4660 - accuracy: 0.9954 - val_loss: 1.4793 - val_accuracy: 0.9819\n",
      "Epoch 2/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4657 - accuracy: 0.9955Epoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 1.4658 - accuracy: 0.9955 - val_loss: 1.4829 - val_accuracy: 0.9782\n",
      "Epoch 3/5000\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.4655 - accuracy: 0.9957Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4655 - accuracy: 0.9958 - val_loss: 1.4804 - val_accuracy: 0.9806\n",
      "Epoch 4/5000\n",
      "462/469 [============================>.] - ETA: 0s - loss: 1.4653 - accuracy: 0.9959Epoch 1/5000\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 1.4653 - accuracy: 0.9959 - val_loss: 1.4795 - val_accuracy: 0.9814\n",
      "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
      "   [0.98 0.98 0.98 0.33 0.06 0.03 0.   0.   0.   0.   0.   0.   0.  ]\n",
      "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
      "   [0.98 0.98 0.98 0.16 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "Epoch 1/5000\n",
      "    469/Unknown - 11s 23ms/step - loss: 1.4710 - accuracy: 0.9930Epoch 1/5000\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 1.4710 - accuracy: 0.9930 - val_loss: 1.4810 - val_accuracy: 0.9808\n",
      "Epoch 2/5000\n",
      "466/469 [============================>.] - ETA: 0s - loss: 1.4662 - accuracy: 0.9957Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4662 - accuracy: 0.9957 - val_loss: 1.4800 - val_accuracy: 0.9819\n",
      "Epoch 3/5000\n",
      "462/469 [============================>.] - ETA: 0s - loss: 1.4655 - accuracy: 0.9960Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4655 - accuracy: 0.9960 - val_loss: 1.4795 - val_accuracy: 0.9827\n",
      "Epoch 4/5000\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.4653 - accuracy: 0.9961Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4653 - accuracy: 0.9961 - val_loss: 1.4797 - val_accuracy: 0.9820\n",
      "Epoch 5/5000\n",
      "466/469 [============================>.] - ETA: 0s - loss: 1.4650 - accuracy: 0.9962Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4650 - accuracy: 0.9962 - val_loss: 1.4800 - val_accuracy: 0.9815\n",
      "Epoch 6/5000\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.4649 - accuracy: 0.9963Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4649 - accuracy: 0.9963 - val_loss: 1.4795 - val_accuracy: 0.9814\n",
      "Epoch 7/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4649 - accuracy: 0.9964Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4649 - accuracy: 0.9964 - val_loss: 1.4792 - val_accuracy: 0.9822\n",
      "Epoch 8/5000\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.9964Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4648 - accuracy: 0.9964 - val_loss: 1.4789 - val_accuracy: 0.9823\n",
      "Epoch 9/5000\n",
      "465/469 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.9964Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4649 - accuracy: 0.9964 - val_loss: 1.4792 - val_accuracy: 0.9819\n",
      "Epoch 10/5000\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.9964Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4648 - accuracy: 0.9965 - val_loss: 1.4799 - val_accuracy: 0.9814\n",
      "Epoch 11/5000\n",
      "465/469 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.9965Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4648 - accuracy: 0.9965 - val_loss: 1.4794 - val_accuracy: 0.9821\n",
      "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
      "   [0.98 0.98 0.97 0.36 0.06 0.01 0.01 0.   0.   0.   0.   0.   0.  ]\n",
      "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
      "   [0.98 0.98 0.97 0.13 0.01 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "Epoch 1/5000\n",
      "    469/Unknown - 11s 23ms/step - loss: 1.4803 - accuracy: 0.9848- 11s 23ms/step - loss: 1.4807Epoch 1/5000\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 1.4802 - accuracy: 0.9848 - val_loss: 1.4834 - val_accuracy: 0.9804\n",
      "Epoch 2/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4701 - accuracy: 0.9934Epoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 1.4701 - accuracy: 0.9934 - val_loss: 1.4825 - val_accuracy: 0.9806\n",
      "Epoch 3/5000\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.4681 - accuracy: 0.9949Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4681 - accuracy: 0.9949 - val_loss: 1.4816 - val_accuracy: 0.9802\n",
      "Epoch 4/5000\n",
      "465/469 [============================>.] - ETA: 0s - loss: 1.4670 - accuracy: 0.9955Epoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 1.4670 - accuracy: 0.9955 - val_loss: 1.4815 - val_accuracy: 0.9802\n",
      "Epoch 5/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4662 - accuracy: 0.9960Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4662 - accuracy: 0.9960 - val_loss: 1.4813 - val_accuracy: 0.9804\n",
      "Epoch 6/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4657 - accuracy: 0.9963Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4657 - accuracy: 0.9963 - val_loss: 1.4810 - val_accuracy: 0.9807\n",
      "Epoch 7/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4654 - accuracy: 0.9964Epoch 1/5000\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 1.4653 - accuracy: 0.9965 - val_loss: 1.4809 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4651 - accuracy: 0.9966Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4651 - accuracy: 0.9966 - val_loss: 1.4803 - val_accuracy: 0.9818\n",
      "Epoch 9/5000\n",
      "466/469 [============================>.] - ETA: 0s - loss: 1.4649 - accuracy: 0.9966Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4649 - accuracy: 0.9966 - val_loss: 1.4806 - val_accuracy: 0.9811\n",
      "Epoch 10/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.9967Epoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 1.4648 - accuracy: 0.9967 - val_loss: 1.4801 - val_accuracy: 0.9811\n",
      "Epoch 11/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4646 - accuracy: 0.9968Epoch 1/5000\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 1.4646 - accuracy: 0.9968 - val_loss: 1.4802 - val_accuracy: 0.9808\n",
      "Epoch 12/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.9969Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4645 - accuracy: 0.9969 - val_loss: 1.4809 - val_accuracy: 0.9804\n",
      "Epoch 13/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4644 - accuracy: 0.9969Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4644 - accuracy: 0.9969 - val_loss: 1.4801 - val_accuracy: 0.9812\n",
      "Epoch 14/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4643 - accuracy: 0.9970Epoch 1/5000\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 1.4643 - accuracy: 0.9970 - val_loss: 1.4799 - val_accuracy: 0.9817\n",
      "Epoch 15/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.9970Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4805 - val_accuracy: 0.9807\n",
      "Epoch 16/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.9970Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4798 - val_accuracy: 0.9813\n",
      "Epoch 17/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.9970Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4800 - val_accuracy: 0.9812\n",
      "Epoch 18/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4796 - val_accuracy: 0.9813\n",
      "Epoch 19/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4642 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4642 - accuracy: 0.9970 - val_loss: 1.4798 - val_accuracy: 0.9816\n",
      "Epoch 20/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4641 - accuracy: 0.9971 - val_loss: 1.4794 - val_accuracy: 0.9821\n",
      "Epoch 21/5000\n",
      "467/469 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4641 - accuracy: 0.9971 - val_loss: 1.4798 - val_accuracy: 0.9815\n",
      "Epoch 22/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4640 - accuracy: 0.9971 - val_loss: 1.4793 - val_accuracy: 0.9821\n",
      "Epoch 23/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 1.4640 - accuracy: 0.9971 - val_loss: 1.4794 - val_accuracy: 0.9821\n",
      "Epoch 24/5000\n",
      "463/469 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4640 - accuracy: 0.9971 - val_loss: 1.4792 - val_accuracy: 0.9822\n",
      "Epoch 25/5000\n",
      "467/469 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4640 - accuracy: 0.9971 - val_loss: 1.4793 - val_accuracy: 0.9818\n",
      "Epoch 26/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4641 - accuracy: 0.9971Epoch 1/5000\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 1.4641 - accuracy: 0.9971 - val_loss: 1.4791 - val_accuracy: 0.9824\n",
      "Epoch 27/5000\n",
      "467/469 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9972Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4640 - accuracy: 0.9972 - val_loss: 1.4793 - val_accuracy: 0.9821\n",
      "Epoch 28/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9972Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4640 - accuracy: 0.9972 - val_loss: 1.4796 - val_accuracy: 0.9813\n",
      "Epoch 29/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4640 - accuracy: 0.9972Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4640 - accuracy: 0.9972 - val_loss: 1.4793 - val_accuracy: 0.9822\n",
      "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
      "   [0.98 0.98 0.98 0.4  0.07 0.02 0.01 0.   0.   0.   0.   0.   0.  ]\n",
      "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
      "   [0.98 0.98 0.98 0.11 0.01 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "Epoch 1/5000\n",
      "    469/Unknown - 10s 22ms/step - loss: 1.4995 - accuracy: 0.9684Epoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 1.4994 - accuracy: 0.9684 - val_loss: 1.4941 - val_accuracy: 0.9710\n",
      "Epoch 2/5000\n",
      "466/469 [============================>.] - ETA: 0s - loss: 1.4793 - accuracy: 0.9857Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4792 - accuracy: 0.9858 - val_loss: 1.4899 - val_accuracy: 0.9733\n",
      "Epoch 3/5000\n",
      "459/469 [============================>.] - ETA: 0s - loss: 1.4754 - accuracy: 0.9893Epoch 1/5000\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 1.4755 - accuracy: 0.9892 - val_loss: 1.4883 - val_accuracy: 0.9749\n",
      "Epoch 4/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4735 - accuracy: 0.9908Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4734 - accuracy: 0.9909 - val_loss: 1.4872 - val_accuracy: 0.9752\n",
      "Epoch 5/5000\n",
      "459/469 [============================>.] - ETA: 0s - loss: 1.4721 - accuracy: 0.9918Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4721 - accuracy: 0.9919 - val_loss: 1.4868 - val_accuracy: 0.9756\n",
      "Epoch 6/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4710 - accuracy: 0.9926Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 1.4710 - accuracy: 0.9926 - val_loss: 1.4862 - val_accuracy: 0.9757\n",
      "Epoch 7/5000\n",
      "466/469 [============================>.] - ETA: 0s - loss: 1.4701 - accuracy: 0.9932Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4701 - accuracy: 0.9932 - val_loss: 1.4858 - val_accuracy: 0.9755\n",
      "Epoch 8/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4693 - accuracy: 0.9939Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4693 - accuracy: 0.9939 - val_loss: 1.4858 - val_accuracy: 0.9759\n",
      "Epoch 9/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4687 - accuracy: 0.9943Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4687 - accuracy: 0.9943 - val_loss: 1.4851 - val_accuracy: 0.9767\n",
      "Epoch 10/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4681 - accuracy: 0.9949Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4681 - accuracy: 0.9948 - val_loss: 1.4849 - val_accuracy: 0.9768\n",
      "Epoch 11/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4676 - accuracy: 0.9950Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4676 - accuracy: 0.9950 - val_loss: 1.4846 - val_accuracy: 0.9774\n",
      "Epoch 12/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.4671 - accuracy: 0.9955Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4672 - accuracy: 0.9954 - val_loss: 1.4847 - val_accuracy: 0.9768\n",
      "Epoch 13/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4668 - accuracy: 0.9955Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 1.4668 - accuracy: 0.9956 - val_loss: 1.4849 - val_accuracy: 0.9767\n",
      "Epoch 14/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.4664 - accuracy: 0.9958Epoch 1/5000\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 1.4665 - accuracy: 0.9958 - val_loss: 1.4847 - val_accuracy: 0.9765\n",
      "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
      "   [0.98 0.98 0.95 0.3  0.1  0.02 0.02 0.02 0.01 0.01 0.02 0.01 0.01]\n",
      "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
      "   [0.98 0.98 0.95 0.1  0.03 0.01 0.   0.   0.   0.   0.   0.   0.  ]\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "yoyoyo <class 'numpy.ndarray'>\n",
      "Epoch 1/5000\n",
      "    469/Unknown - 10s 22ms/step - loss: 2.2346 - accuracy: 0.1985- 10s 22ms/step - loss: 2.2353 - acEpoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 2.2345 - accuracy: 0.1985 - val_loss: 2.2067 - val_accuracy: 0.2473\n",
      "Epoch 2/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.2017 - accuracy: 0.2781Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.2017 - accuracy: 0.2786 - val_loss: 2.1945 - val_accuracy: 0.3159\n",
      "Epoch 3/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1945 - accuracy: 0.3204Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1945 - accuracy: 0.3205 - val_loss: 2.1903 - val_accuracy: 0.3332\n",
      "Epoch 4/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1914 - accuracy: 0.3297Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1913 - accuracy: 0.3301 - val_loss: 2.1882 - val_accuracy: 0.3418\n",
      "Epoch 5/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1891 - accuracy: 0.3384Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1892 - accuracy: 0.3385 - val_loss: 2.1866 - val_accuracy: 0.3506\n",
      "Epoch 6/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1877 - accuracy: 0.3446Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1876 - accuracy: 0.3444 - val_loss: 2.1855 - val_accuracy: 0.3494\n",
      "Epoch 7/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1863 - accuracy: 0.3463Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1863 - accuracy: 0.3463 - val_loss: 2.1843 - val_accuracy: 0.3529\n",
      "Epoch 8/5000\n",
      "468/469 [============================>.] - ETA: 0s - loss: 2.1851 - accuracy: 0.3480Epoch 1/5000\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 2.1851 - accuracy: 0.3482 - val_loss: 2.1836 - val_accuracy: 0.3556\n",
      "Epoch 9/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1842 - accuracy: 0.3505Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1842 - accuracy: 0.3502 - val_loss: 2.1829 - val_accuracy: 0.3570\n",
      "Epoch 10/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1835 - accuracy: 0.3509Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1834 - accuracy: 0.3508 - val_loss: 2.1823 - val_accuracy: 0.3535\n",
      "Epoch 11/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1828 - accuracy: 0.3522Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1828 - accuracy: 0.3523 - val_loss: 2.1817 - val_accuracy: 0.3597\n",
      "Epoch 12/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1822 - accuracy: 0.3528Epoch 1/5000\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 2.1823 - accuracy: 0.3529 - val_loss: 2.1813 - val_accuracy: 0.3608\n",
      "Epoch 13/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1818 - accuracy: 0.3540Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1818 - accuracy: 0.3539 - val_loss: 2.1809 - val_accuracy: 0.3606\n",
      "Epoch 14/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1815 - accuracy: 0.3534Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1814 - accuracy: 0.3538 - val_loss: 2.1805 - val_accuracy: 0.3607\n",
      "Epoch 15/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1811 - accuracy: 0.3546Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1811 - accuracy: 0.3548 - val_loss: 2.1802 - val_accuracy: 0.3621\n",
      "Epoch 16/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1808 - accuracy: 0.3553Epoch 1/5000\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 2.1807 - accuracy: 0.3547 - val_loss: 2.1800 - val_accuracy: 0.3619\n",
      "Epoch 17/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1801 - accuracy: 0.3565Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1801 - accuracy: 0.3558 - val_loss: 2.1793 - val_accuracy: 0.3627\n",
      "Epoch 18/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1796 - accuracy: 0.3560Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1796 - accuracy: 0.3562 - val_loss: 2.1790 - val_accuracy: 0.3626\n",
      "Epoch 19/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1793 - accuracy: 0.3560Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1792 - accuracy: 0.3561 - val_loss: 2.1786 - val_accuracy: 0.3617\n",
      "Epoch 20/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1790 - accuracy: 0.3561Epoch 1/5000\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 2.1789 - accuracy: 0.3557 - val_loss: 2.1784 - val_accuracy: 0.3617\n",
      "Epoch 21/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1786 - accuracy: 0.3586Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1786 - accuracy: 0.3588 - val_loss: 2.1778 - val_accuracy: 0.3662\n",
      "Epoch 22/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1783 - accuracy: 0.3612Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1782 - accuracy: 0.3608 - val_loss: 2.1774 - val_accuracy: 0.3687\n",
      "Epoch 23/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1779 - accuracy: 0.3616Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1779 - accuracy: 0.3618 - val_loss: 2.1773 - val_accuracy: 0.3669\n",
      "Epoch 24/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1776 - accuracy: 0.3622Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1777 - accuracy: 0.3625 - val_loss: 2.1771 - val_accuracy: 0.3674\n",
      "Epoch 25/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1775 - accuracy: 0.3630Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1775 - accuracy: 0.3632 - val_loss: 2.1769 - val_accuracy: 0.3584\n",
      "Epoch 26/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1772 - accuracy: 0.3640Epoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 2.1774 - accuracy: 0.3638 - val_loss: 2.1768 - val_accuracy: 0.3683\n",
      "Epoch 27/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1771 - accuracy: 0.3652Epoch 1/5000\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 2.1772 - accuracy: 0.3650 - val_loss: 2.1768 - val_accuracy: 0.3686\n",
      "Epoch 28/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/469 [============================>.] - ETA: 0s - loss: 2.1771 - accuracy: 0.3653Epoch 1/5000\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 2.1770 - accuracy: 0.3654 - val_loss: 2.1766 - val_accuracy: 0.3705\n",
      "Epoch 29/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1768 - accuracy: 0.3657Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1769 - accuracy: 0.3656 - val_loss: 2.1764 - val_accuracy: 0.3709\n",
      "Epoch 30/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1768 - accuracy: 0.3661Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1767 - accuracy: 0.3664 - val_loss: 2.1764 - val_accuracy: 0.3701\n",
      "Epoch 31/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1766 - accuracy: 0.3657Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1766 - accuracy: 0.3663 - val_loss: 2.1762 - val_accuracy: 0.3705\n",
      "Epoch 32/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1765 - accuracy: 0.3660Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1765 - accuracy: 0.3663 - val_loss: 2.1761 - val_accuracy: 0.3704\n",
      "Epoch 33/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1764 - accuracy: 0.3669Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1764 - accuracy: 0.3671 - val_loss: 2.1761 - val_accuracy: 0.3709\n",
      "Epoch 34/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1762 - accuracy: 0.3673Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1762 - accuracy: 0.3672 - val_loss: 2.1760 - val_accuracy: 0.3720\n",
      "Epoch 35/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1762 - accuracy: 0.3688Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1762 - accuracy: 0.3691 - val_loss: 2.1760 - val_accuracy: 0.3725\n",
      "Epoch 36/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1760 - accuracy: 0.3693Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1761 - accuracy: 0.3690 - val_loss: 2.1759 - val_accuracy: 0.3717\n",
      "Epoch 37/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1759 - accuracy: 0.3697Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1760 - accuracy: 0.3693 - val_loss: 2.1759 - val_accuracy: 0.3719\n",
      "Epoch 38/5000\n",
      "459/469 [============================>.] - ETA: 0s - loss: 2.1760 - accuracy: 0.3696Epoch 1/5000\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 2.1759 - accuracy: 0.3695 - val_loss: 2.1759 - val_accuracy: 0.3714\n",
      "Epoch 39/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1759 - accuracy: 0.3695Epoch 1/5000\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 2.1759 - accuracy: 0.3696 - val_loss: 2.1759 - val_accuracy: 0.3723\n",
      "Epoch 40/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1758 - accuracy: 0.3700Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1758 - accuracy: 0.3700 - val_loss: 2.1758 - val_accuracy: 0.3737\n",
      "Epoch 41/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1757 - accuracy: 0.3708Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1757 - accuracy: 0.3704 - val_loss: 2.1758 - val_accuracy: 0.3730\n",
      "Epoch 42/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1757 - accuracy: 0.3701Epoch 1/5000\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 2.1757 - accuracy: 0.3703 - val_loss: 2.1757 - val_accuracy: 0.3734\n",
      "Epoch 43/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1757 - accuracy: 0.3701Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1756 - accuracy: 0.3701 - val_loss: 2.1757 - val_accuracy: 0.3735\n",
      "Epoch 44/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1756 - accuracy: 0.3708Epoch 1/5000\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 2.1756 - accuracy: 0.3706 - val_loss: 2.1758 - val_accuracy: 0.3740\n",
      "Epoch 45/5000\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.1756 - accuracy: 0.3704Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1756 - accuracy: 0.3704 - val_loss: 2.1756 - val_accuracy: 0.3741\n",
      "Epoch 46/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1756 - accuracy: 0.3711 ETA: 2sEpoch 1/5000\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 2.1755 - accuracy: 0.3710 - val_loss: 2.1757 - val_accuracy: 0.3739\n",
      "Epoch 47/5000\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.1754 - accuracy: 0.3705Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1755 - accuracy: 0.3706 - val_loss: 2.1758 - val_accuracy: 0.3741\n",
      "Epoch 48/5000\n",
      "459/469 [============================>.] - ETA: 0s - loss: 2.1754 - accuracy: 0.3706Epoch 1/5000\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.1755 - accuracy: 0.3708 - val_loss: 2.1757 - val_accuracy: 0.3740\n",
      "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
      "   [0.31 0.28 0.28 0.22 0.18 0.16 0.15 0.12 0.12 0.1  0.1  0.1  0.09]\n",
      "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
      "   [0.31 0.22 0.22 0.13 0.05 0.02 0.02 0.01 0.03 0.01 0.02 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "pruning_ratios=[0,0.5,.8,.9,.95,.99]\n",
    "for pruning_ratio in pruning_ratios:\n",
    "    pruned_model = prune(model, pruning_ratio)\n",
    "    train_model(pruned_model)\n",
    "    attack(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(model):\n",
    "    fmodel = fb.models.TensorFlowModel(model, bounds=(0,1))\n",
    "    images_from_ds, labels_from_ds = get_mnist_data()\n",
    "    attacks = [\n",
    "        fa.FGSM(),\n",
    "        fa.LinfPGD(),\n",
    "    ]\n",
    "    epsilons = [\n",
    "        0.0,\n",
    "        0.001,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        .2,\n",
    "        .3,\n",
    "        .4,\n",
    "        .5,\n",
    "        .6,\n",
    "        .7,\n",
    "        .8,\n",
    "        .9,\n",
    "        1.0,\n",
    "    ]\n",
    "    attack_success = np.zeros((len(attacks), len(epsilons), len(images_from_ds)), dtype=np.bool)\n",
    "    for i, attack in enumerate(attacks):\n",
    "        _, _, success = attack(fmodel, images_from_ds, labels_from_ds, epsilons=epsilons)\n",
    "        assert success.shape == (len(epsilons), len(images_from_ds))\n",
    "        success_ = success.numpy()\n",
    "        assert success_.dtype == np.bool\n",
    "        attack_success[i] = success_\n",
    "        print(attack)\n",
    "        print(\"  \", 1.0 - success_.mean(axis=-1).round(2))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = fb.models.TensorFlowModel(model, bounds=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data():\n",
    "    data = ld_mnist()\n",
    "    images_from_ds=[]\n",
    "    labels_from_ds=[]\n",
    "    for z in data.test.take(1):\n",
    "        images_from_ds=z[0] \n",
    "        labels_from_ds=z[1]\n",
    "    return images_from_ds, labels_from_ds\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.96875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "print(\"accuracy\")\n",
    "print(accuracy(fmodel, images_from_ds, labels_from_ds))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = [\n",
    "        fa.FGSM(),\n",
    "        fa.LinfPGD(),\n",
    "    ]\n",
    "epsilons = [\n",
    "    0.0,\n",
    "    0.001,\n",
    "    0.01,\n",
    "    0.1,\n",
    "    .2,\n",
    "    .3,\n",
    "    .4,\n",
    "    .5,\n",
    "    .6,\n",
    "    .7,\n",
    "    .8,\n",
    "    .9,\n",
    "    1.0,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
      "   [0.97 0.97 0.95 0.3  0.04 0.01 0.01 0.01 0.   0.   0.   0.   0.  ]\n",
      "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
      "   [0.97 0.97 0.95 0.15 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "attack_success = np.zeros((len(attacks), len(epsilons), len(images_from_ds)), dtype=np.bool)\n",
    "for i, attack in enumerate(attacks):\n",
    "    _, _, success = attack(fmodel, images_from_ds, labels_from_ds, epsilons=epsilons)\n",
    "    assert success.shape == (len(epsilons), len(images_from_ds))\n",
    "    success_ = success.numpy()\n",
    "    assert success_.dtype == np.bool\n",
    "    attack_success[i] = success_\n",
    "    print(attack)\n",
    "    print(\"  \", 1.0 - success_.mean(axis=-1).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1, res2, res3 = fa.FGSM()(fmodel, images_from_ds, labels_from_ds, epsilons=[.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(28, 28, 1), dtype=float32, numpy=\n",
       "array([[[0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.10392157],\n",
       "        [0.24901962],\n",
       "        [0.37058824],\n",
       "        [0.47254905],\n",
       "        [0.47254905],\n",
       "        [0.7980392 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8176471 ],\n",
       "        [0.67254907],\n",
       "        [0.18627451],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.7196079 ],\n",
       "        [0.19803922],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.30392158],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8882353 ],\n",
       "        [0.845098  ],\n",
       "        [0.9196079 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.40196082],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.11176471],\n",
       "        [0.75098044],\n",
       "        [0.7235294 ],\n",
       "        [0.70392156],\n",
       "        [0.3       ],\n",
       "        [0.16666669],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.13529412],\n",
       "        [0.82156867],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.68039215],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.75490195],\n",
       "        [0.89215684],\n",
       "        [1.        ],\n",
       "        [0.38627452],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.50784314],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.68039215],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.28431374],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.28431374],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.58235294],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.31176472],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.48823532],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.7078431 ],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.40196082],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.7745098 ],\n",
       "        [0.89215684],\n",
       "        [0.80196077],\n",
       "        [0.20588236],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.35490197],\n",
       "        [0.89215684],\n",
       "        [1.        ],\n",
       "        [0.8019608 ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.77843136],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.34313726],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.53137255],\n",
       "        [1.        ],\n",
       "        [0.89215684],\n",
       "        [0.82549024],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.29607844],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.51960784],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.5745098 ],\n",
       "        [1.        ],\n",
       "        [0.89215684],\n",
       "        [0.7941176 ],\n",
       "        [0.13137256],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.45294118],\n",
       "        [1.        ],\n",
       "        [0.89215684],\n",
       "        [1.        ],\n",
       "        [0.35882354],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.11176471],\n",
       "        [0.782353  ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8647059 ],\n",
       "        [0.10392157],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.16666667],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.6607843 ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.4058824 ],\n",
       "        [0.89215684],\n",
       "        [0.83725494],\n",
       "        [0.21372549],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.1       ],\n",
       "        [0.        ],\n",
       "        [0.1       ]]], dtype=float32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1[0][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(28, 28, 1), dtype=float32, numpy=\n",
       "array([[[0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.10392155],\n",
       "        [0.2490196 ],\n",
       "        [0.37058827],\n",
       "        [0.47254908],\n",
       "        [0.47254908],\n",
       "        [0.7980392 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8176471 ],\n",
       "        [0.67254907],\n",
       "        [0.1862745 ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.00000001],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.7196079 ],\n",
       "        [0.1980392 ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.30392155],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8882353 ],\n",
       "        [0.845098  ],\n",
       "        [0.9196079 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.40196085],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.11176468],\n",
       "        [0.75098044],\n",
       "        [0.7235294 ],\n",
       "        [0.70392156],\n",
       "        [0.30000004],\n",
       "        [0.16666672],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.13529411],\n",
       "        [0.82156867],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.68039215],\n",
       "        [0.00000001],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.00000001],\n",
       "        [0.75490195],\n",
       "        [0.89215684],\n",
       "        [1.        ],\n",
       "        [0.38627455],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.50784314],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.68039215],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.28431377],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.00000001],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.28431377],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.58235294],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.31176475],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.48823535],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.7078431 ],\n",
       "        [0.89215684],\n",
       "        [0.89215684],\n",
       "        [0.40196085],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.00000002],\n",
       "        [0.7745098 ],\n",
       "        [0.89215684],\n",
       "        [0.80196077],\n",
       "        [0.20588234],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.354902  ],\n",
       "        [0.89215684],\n",
       "        [1.        ],\n",
       "        [0.8019608 ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00000001],\n",
       "        [0.77843136],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.34313723],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.53137255],\n",
       "        [1.        ],\n",
       "        [0.89215684],\n",
       "        [0.82549024],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.2960784 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.51960784],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.5745098 ],\n",
       "        [1.        ],\n",
       "        [0.89215684],\n",
       "        [0.7941176 ],\n",
       "        [0.13137254],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.45294115],\n",
       "        [1.        ],\n",
       "        [0.89215684],\n",
       "        [1.        ],\n",
       "        [0.3588235 ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.11176468],\n",
       "        [0.782353  ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8647059 ],\n",
       "        [0.10392155],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.16666666],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.6607843 ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.40588242],\n",
       "        [0.89215684],\n",
       "        [0.83725494],\n",
       "        [0.21372548],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09999998],\n",
       "        [0.        ],\n",
       "        [0.09999998]]], dtype=float32)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "res2[0][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=bool, numpy=\n",
       "array([False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True, False, False, False,  True,\n",
       "       False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True, False, False,  True, False,  True,\n",
       "       False,  True, False, False,  True, False,  True,  True,  True,\n",
       "        True, False,  True,  True, False,  True,  True,  True, False,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True, False,  True,  True,\n",
       "       False, False,  True,  True, False,  True,  True, False,  True,\n",
       "        True, False])>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weights(model, pruning_ratio):\n",
    "    weights = model.get_weights()\n",
    "    weights_to_prune = model.get_weights()\n",
    "    for index, weight in enumerate(weights):\n",
    "        if (index == 0) or (index == 2) or (index == 4):\n",
    "            flat_weights = weight.flatten()\n",
    "            flat_weights_to_prune = weights_to_prune[index+1].flatten()\n",
    "            #print (flat_weights_to_prune.shape, flat_weights.shape)\n",
    "            flat_weights_df = pd.DataFrame(flat_weights)\n",
    "            flat_weights_to_prune_df = pd.DataFrame(flat_weights_to_prune)\n",
    "            no_of_weights_to_prune = int(len(flat_weights)*pruning_ratio)\n",
    "            #print(no_of_weights_to_prune)\n",
    "            indices_to_delete = flat_weights_df.abs().values.argsort(0)[:no_of_weights_to_prune]\n",
    "            for idx_to_delete in indices_to_delete:\n",
    "                flat_weights_to_prune[idx_to_delete] = 0\n",
    "            dims = weights_to_prune[index+1].shape\n",
    "            weights_reshaped = flat_weights_to_prune.reshape(dims)\n",
    "            print('yoyoyo',type(weights_to_prune[index+1]))\n",
    "            weights_to_prune[index+1] = weights_reshaped\n",
    "    #print(weights_to_prune)\n",
    "    return weights_to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(model, pruning_ratio):\n",
    "    pruned_weights = prune_weights(model, pruning_ratio)\n",
    "    model.set_weights(pruned_weights)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_fgm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fdc61b2cfbbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_fgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_fgm' is not defined"
     ]
    }
   ],
   "source": [
    "def show_batch(image_batch,label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(10):\n",
    "        img = tf.reshape(image_batch[n], (28,28))\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(np.argmax(label_batch[n]))\n",
    "        plt.axis('off')\n",
    "show_batch( x_fgm, adv_preds)\n",
    "show_batch(clean_inputs,clean_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont need this now hopefully - just for debugging reasons\n",
    "def accuracy(fmodel, inputs, labels):\n",
    "    inputs_, labels_ = ep.astensors(inputs, labels)\n",
    "    del inputs, labels\n",
    "\n",
    "    predictions = fmodel(inputs_).argmax(axis=-1)\n",
    "\n",
    "    accuracy = (predictions == labels_).float32().mean()\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: 1.4662 - accuracy: 0.9951 - val_loss: 1.4805 - val_accuracy: 0.9808\n",
    "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
    "   [0.98 0.97 0.97 0.27 0.09 0.02 0.   0.   0.   0.   0.   0.   0.  ]\n",
    "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
    "   [0.98 0.97 0.97 0.16 0.02 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
    "   \n",
    "   \n",
    "   \n",
    "loss: 1.4653 - accuracy: 0.9959 - val_loss: 1.4795 - val_accuracy: 0.9814\n",
    "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
    "   [0.98 0.98 0.98 0.33 0.06 0.03 0.   0.   0.   0.   0.   0.   0.  ]\n",
    "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
    "   [0.98 0.98 0.98 0.16 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
    "\n",
    "\n",
    "\n",
    "loss: 1.4648 - accuracy: 0.9965 - val_loss: 1.4794 - val_accuracy: 0.9821\n",
    "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
    "   [0.98 0.98 0.97 0.36 0.06 0.01 0.01 0.   0.   0.   0.   0.   0.  ]\n",
    "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
    "   [0.98 0.98 0.97 0.13 0.01 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
    "\n",
    "\n",
    "\n",
    "loss: 1.4640 - accuracy: 0.9972 - val_loss: 1.4793 - val_accuracy: 0.9822\n",
    "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
    "   [0.98 0.98 0.98 0.4  0.07 0.02 0.01 0.   0.   0.   0.   0.   0.  ]\n",
    "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
    "   [0.98 0.98 0.98 0.11 0.01 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
    "\n",
    "\n",
    "\n",
    "loss: 1.4665 - accuracy: 0.9958 - val_loss: 1.4847 - val_accuracy: 0.9765\n",
    "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
    "   [0.98 0.98 0.95 0.3  0.1  0.02 0.02 0.02 0.01 0.01 0.02 0.01 0.01]\n",
    "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
    "   [0.98 0.98 0.95 0.1  0.03 0.01 0.   0.   0.   0.   0.   0.   0.  ]\n",
    "\n",
    "\n",
    "\n",
    "loss: 2.1755 - accuracy: 0.3708 - val_loss: 2.1757 - val_accuracy: 0.3740\n",
    "LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False)\n",
    "   [0.31 0.28 0.28 0.22 0.18 0.16 0.15 0.12 0.12 0.1  0.1  0.1  0.09]\n",
    "LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True)\n",
    "   [0.31 0.22 0.22 0.13 0.05 0.02 0.02 0.01 0.03 0.01 0.02 0.01 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
